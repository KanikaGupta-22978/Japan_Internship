{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'participant2'\n",
    "frequency = '15min' # 15min | 15s\n",
    "dataset_type = '' # ''\n",
    "\n",
    "if frequency == '15min':\n",
    "    record_size_per_day = 96\n",
    "elif frequency == '15s':\n",
    "    record_size_per_day = 5760\n",
    "\n",
    "# Columns to include    \n",
    "if dataset_type == '':\n",
    "    columns = [ 'timestamp', 'heart_rate', 'steps', 'stress_score',\n",
    "            'awake', 'deep', 'light', 'rem', 'nonrem_total', 'total', 'nonrem_percentage', 'sleep_efficiency',\n",
    "            'time_from_last_drug_taken', 'wearing_off' ]\n",
    "\n",
    "metrics = {\n",
    "    'balanced_accuracy': 'Bal. Acc.',\n",
    "    'f1_score': 'F1 Score',\n",
    "    'accuracy': 'Acc.',\n",
    "    'precision': 'Precision',\n",
    "    'sensitivity': 'Recall / Sn',\n",
    "    'specificity': 'Sp',\n",
    "    'auc': 'AUC'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from typing import Union, Generator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning, ConvergenceWarning\n",
    "\n",
    "import sklearn\n",
    "from photonai.base import Hyperpipe, PipelineElement, Stack, Switch\n",
    "from photonai.optimization import FloatRange, IntegerRange, Categorical, BooleanSwitch, PhotonHyperparam\n",
    "from photonai.optimization import Categorical as PhotonCategorical\n",
    "from photonai.optimization import MinimumPerformanceConstraint, DummyPerformanceConstraint, BestPerformanceConstraint\n",
    "from photonai.optimization.base_optimizer import PhotonSlaveOptimizer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tabulate import tabulate\n",
    "\n",
    "from skopt import Optimizer\n",
    "from skopt.space import Real, Integer, Dimension\n",
    "from skopt.space import Categorical as skoptCategorical\n",
    "from photonai.photonlogger.logger import logger\n",
    "from photonai.optimization.scikit_optimize.sk_opt import SkOptOptimizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "from photonai.base import Hyperpipe\n",
    "from photonai.optimization import MinimumPerformanceConstraint\n",
    "from photonai.photonlogger import logger \n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_excel(f'./data/combined_data/{dataset_type}combined_data_{user}_{frequency}.xlsx',\n",
    "                              index_col=\"timestamp\",\n",
    "                              usecols=columns,\n",
    "                              engine='openpyxl')\n",
    "if dataset_type == '':\n",
    "    # Define prediction horizon\n",
    "    predict_ahead = pd.Timedelta(minutes=60)  # <- change to 2 or pd.Timedelta(seconds=15) as needed\n",
    "\n",
    "    # Ensure datetime index\n",
    "    combined_data = combined_data.sort_index()\n",
    "    combined_data.index = pd.to_datetime(combined_data.index)\n",
    "\n",
    "    # Estimate time delta between rows (assumes regular sampling)\n",
    "    median_step = combined_data.index.to_series().diff().median()\n",
    "\n",
    "    # How many steps to shift based on prediction horizon\n",
    "    steps_ahead = int(predict_ahead / median_step)\n",
    "\n",
    "    # Shift labels backward to align X at time t with y at t + n\n",
    "    combined_data['wearing_off_future'] = combined_data['wearing_off'].shift(-steps_ahead)\n",
    "\n",
    "    # Drop rows with NaNs from shifting\n",
    "    combined_data = combined_data.dropna(subset=['wearing_off_future'])\n",
    "\n",
    "    # Define X and y (keep X as DataFrame for .iloc to work)\n",
    "    X = combined_data.loc[:, columns[1:-1]]  # or X = combined_data[feature_cols]\n",
    "    y = combined_data['wearing_off_future'].astype(int).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Show feature importances\n",
    "def print_feature_importances(pipeline):\n",
    "    output = ''\n",
    "    if pipeline.optimum_pipe.feature_importances_ is None:\n",
    "        output = 'Best Hyperparameter Configuration is a non-linear SVM, thus feature importances cannot be retrieved'\n",
    "    else:\n",
    "        output = 'Feature Importances using the Best Hyperparameter Config'\n",
    "        if not [value.base_element.support_.tolist() for key, value in pipeline.optimum_pipe.elements if key == 'RFE']:\n",
    "            if len(pipeline.optimum_pipe.feature_importances_) == 1:\n",
    "                feature_importances = pipeline.optimum_pipe.feature_importances_[0]\n",
    "            else:\n",
    "                feature_importances = pipeline.optimum_pipe.feature_importances_\n",
    "            output += '\\n'\n",
    "            output += tabulate(\n",
    "                pd.DataFrame(\n",
    "                    [np.around(feature_importances, decimals=4)],\n",
    "                    columns=np.array(columns[1:-1])\n",
    "                ).transpose().sort_values(by=[0], ascending=False, key=abs),\n",
    "                tablefmt='psql', floatfmt=\".4f\", headers=['Features', 'Values']\n",
    "            )\n",
    "        else:\n",
    "            mask = [value.base_element.support_.tolist() for key, value in pipeline.optimum_pipe.elements if key == 'RFE'][0]\n",
    "            if len(pipeline.optimum_pipe.feature_importances_) == 1:\n",
    "                feature_importances = pipeline.optimum_pipe.feature_importances_[0]\n",
    "            else:\n",
    "                feature_importances = pipeline.optimum_pipe.feature_importances_\n",
    "            output += '\\n'\n",
    "            output += tabulate(\n",
    "                pd.DataFrame(\n",
    "                    [np.around(feature_importances, decimals=4)],\n",
    "                    columns=np.array(columns[1:-1])[mask]\n",
    "                ).transpose().sort_values(by=[0], ascending=False, key=abs),\n",
    "                tablefmt='psql', floatfmt=\".4f\", headers=['Features', 'Values']\n",
    "            )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, X, y, ax, n_splits=0, lw=20):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                    c=indices, marker='_', lw=lw, cmap=plt.cm.coolwarm,\n",
    "                    vmin=-.2, vmax=1.2)\n",
    "\n",
    "    n_splits = ii + 1\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X), c=y, marker='_', lw=lw, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['wearing-off']\n",
    "    ax.set(yticks=np.arange(n_splits+1) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Records\\'s Index', ylabel=\"Folds\",\n",
    "           ylim=[n_splits+1.2, -.2], xlim=[0, len(X)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_from_pipeline(pipeline):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    cm = confusion_matrix(\n",
    "        pipeline.results_handler.get_test_predictions()['y_true'],\n",
    "        pipeline.results_handler.get_test_predictions()['y_pred'],\n",
    "        labels=[0,1], normalize=None)\n",
    "    ax = plt.subplot()\n",
    "    sns.set(font_scale=3.0) # Adjust to fit\n",
    "    sns.heatmap(cm, annot=True, ax=ax, cmap=\"Blues\", fmt=\"g\");  \n",
    "\n",
    "    # Labels, title and ticks\n",
    "    label_font = {'size':'25'}  # Adjust to fit\n",
    "    ax.set_xlabel('Predicted labels', fontdict=label_font);\n",
    "    ax.set_ylabel('Observed labels', fontdict=label_font);\n",
    "\n",
    "    # title_font = {'size':'21'}  # Adjust to fit\n",
    "    # ax.set_title('Confusion Matrix', fontdict=title_font);\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=25)  # Adjust to fit\n",
    "    ax.xaxis.set_ticklabels(['Good', 'Wearing-Off']);\n",
    "    ax.yaxis.set_ticklabels(['Good', 'Wearing-Off']);\n",
    "    plt.rc('text') # , usetex=False)\n",
    "    plt.rc('font', family='serif')\n",
    "    # plt.savefig('./participant2-downsampling-confusionmatrix-real.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write other reports to summary file\n",
    "def add_other_report_to_summary(pipeline, with_estimator_comparison=True):\n",
    "    with open(f'{pipeline.output_settings.results_folder}/photon_summary.txt', \"a+\") as summary_file:\n",
    "        # 1. Write comparison of learning algorithms\n",
    "        if with_estimator_comparison:\n",
    "            summary_file.write(\"\\n\\n\")\n",
    "            summary_file.write(\"Comparison on learning algorithms on validation set\")\n",
    "            summary_file.write(\"\\n\")\n",
    "            summary_file.write(str(pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator()))\n",
    "\n",
    "        # 2. Write feature importance\n",
    "        summary_file.write(\"\\n\\n\")\n",
    "        summary_file.write(\"Feature Importance\")\n",
    "        summary_file.write(print_feature_importances(pipeline))\n",
    "        \n",
    "        # 3. Write beautified average test performance across outer folds\n",
    "        # a. Get Average Test Performance Across Outer Folds\n",
    "        test_metric_result = pipeline.results.get_test_metric_dict()\n",
    "        \n",
    "        # b. Replace display metric name\n",
    "        #   Reference: https://stackoverflow.com/a/55250496/2303766\n",
    "        test_metric_result = { metrics[metric]: test_metric_result[metric]\n",
    "                                  for metric, metric_name in metrics.items() if metric in test_metric_result\n",
    "                             }\n",
    "        \n",
    "        # c. Add beautified average test performance across outer folds to file \n",
    "        summary_file.write(\"\\n\\n\")\n",
    "        summary_file.write(\"Average Test Performance Across Outer Folds\")\n",
    "        summary_file.write(\"\\n\")\n",
    "        summary_file.write(\n",
    "            tabulate(\n",
    "                pd.DataFrame(\n",
    "                    test_metric_result\n",
    "                ).round(4).transpose(),\n",
    "                tablefmt='psql', floatfmt=\".4f\", headers='keys'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 4. Write outer fold results\n",
    "        summary_file.write(\"\\n\\n\")\n",
    "        summary_file.write(\"Outer Fold Best Estimators' Performance\")\n",
    "        summary_file.write(\"\\n\")\n",
    "        handler = pipeline.results_handler\n",
    "        performance_table = handler.get_performance_table()\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "            summary_file.write(\n",
    "                tabulate(\n",
    "                    performance_table.loc[:, ['fold', 'best_config', 'n_train', 'n_validation']].transpose(),\n",
    "                    tablefmt='psql', headers='keys'\n",
    "                )\n",
    "            )\n",
    "            summary_file.write(\"\\n\")\n",
    "            summary_file.write(\n",
    "                tabulate(\n",
    "                    performance_table.loc[:, ['fold'] + list(metrics.keys())].round(4).transpose(),\n",
    "                    tablefmt='psql', floatfmt=\".4f\", headers='keys'\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        outer_fold_performance = {}\n",
    "        config_evals = handler.get_config_evaluations()\n",
    "        for metric in metrics.keys():\n",
    "            # print(f'{metric}')\n",
    "            for i, j in enumerate(config_evals[metric]):\n",
    "                if f'{metric}_mean' in outer_fold_performance:\n",
    "                    # outer_fold_performance[f'{metric}_max'].append(np.max(j))\n",
    "                    outer_fold_performance[f'{metric}_mean'].append(np.mean(j))\n",
    "                    outer_fold_performance[f'{metric}_std'].append(np.std(j))\n",
    "                else:\n",
    "                    # outer_fold_performance[f'{metric}_max'] = [np.max(j)]\n",
    "                    outer_fold_performance[f'{metric}_mean'] = [np.mean(j)]\n",
    "                    outer_fold_performance[f'{metric}_std'] = [np.std(j)]\n",
    "        summary_file.write(\"\\n\")\n",
    "        summary_file.write(\n",
    "            tabulate(\n",
    "                pd.DataFrame(outer_fold_performance).round(4).transpose(),\n",
    "                tablefmt='psql', floatfmt=\".4f\", headers='keys'\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhotonAI Optimize Monkey-patch\n",
    "#     Added random_state for Optimize for result replicability\n",
    "def prepare(self, pipeline_elements: list, maximize_metric: bool) -> None:\n",
    "    \"\"\"\n",
    "    Initializes hyperparameter search with scikit-optimize.\n",
    "\n",
    "    Assembles all hyperparameters of the list of PipelineElements\n",
    "    in order to prepare the hyperparameter space.\n",
    "    Hyperparameters can be accessed via pipe_element.hyperparameters.\n",
    "\n",
    "    Parameters:\n",
    "        pipeline_elements:\n",
    "            List of all PipelineElements to create the hyperparameter space.\n",
    "\n",
    "        maximize_metric:\n",
    "            Boolean to distinguish between score and error.\n",
    "\n",
    "    \"\"\"\n",
    "    self.start_time = None\n",
    "    self.optimizer = None\n",
    "    self.hyperparameter_list = []\n",
    "    self.maximize_metric = maximize_metric\n",
    "\n",
    "    # build skopt space\n",
    "    space = []\n",
    "    for pipe_element in pipeline_elements:\n",
    "        if pipe_element.__class__.__name__ == 'Switch':\n",
    "            error_msg = 'Scikit-Optimize cannot operate in the specified hyperparameter space with a Switch ' \\\n",
    "                        'element. We recommend the use of SMAC.'\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if hasattr(pipe_element, 'hyperparameters'):\n",
    "            for name, value in pipe_element.hyperparameters.items():\n",
    "                # if we only have one value we do not need to optimize\n",
    "                if isinstance(value, list) and len(value) < 2:\n",
    "                    self.constant_dictionary[name] = value[0]\n",
    "                    continue\n",
    "                if isinstance(value, PhotonCategorical) and len(value.values) < 2:\n",
    "                    self.constant_dictionary[name] = value.values[0]\n",
    "                    continue\n",
    "                skopt_param = self._convert_photonai_to_skopt_space(value, name)\n",
    "                if skopt_param is not None:\n",
    "                    space.append(skopt_param)\n",
    "\n",
    "    if self.constant_dictionary:\n",
    "        msg = \"PHOTONAI has detected some one-valued params in your hyperparameters. Pleas use the kwargs for \" \\\n",
    "              \"constant values. This run ignores following settings: \" + str(self.constant_dictionary.keys())\n",
    "        logger.warning(msg)\n",
    "        warnings.warn(msg)\n",
    "\n",
    "    if len(space) == 0:\n",
    "        msg = \"Did not find any hyperparameter to convert into skopt space.\"\n",
    "        logger.warning(msg)\n",
    "        warnings.warn(msg)\n",
    "    else:\n",
    "        self.optimizer = Optimizer(space,\n",
    "                                   base_estimator=self.base_estimator,\n",
    "                                   n_initial_points=self.n_initial_points,\n",
    "                                   initial_point_generator=self.initial_point_generator,\n",
    "                                   acq_func=self.acq_func,\n",
    "                                   acq_func_kwargs=self.acq_func_kwargs,\n",
    "                                   random_state=4\n",
    "                                  )\n",
    "    self.ask = self.ask_generator()\n",
    "    \n",
    "#    Monkey patched new prepare function\n",
    "SkOptOptimizer.prepare = prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set for Outer Fold 0\n",
      "[ 508  509  510 ... 2873 2874 2875]\n",
      "\n",
      "Train Set for Outer Fold 1\n",
      "[   0    1    2 ... 2873 2874 2875]\n",
      "\n",
      "Train Set for Outer Fold 2\n",
      "[   0    1    2 ... 2873 2874 2875]\n",
      "\n",
      "Train Set for Outer Fold 3\n",
      "[   0    1    2 ... 2873 2874 2875]\n",
      "\n",
      "Train Set for Outer Fold 4\n",
      "[   0    1    2 ... 2310 2311 2312]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Outer CV\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "plot_cv_indices(cv, X, y, ax)\n",
    "plt.rc('text') # , usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "plt.title('Outer Folds')\n",
    "# Save as file\n",
    "# plt.savefig('./blockingtimeseriessplit.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "training_folds = []\n",
    "for train, test in cv.split(X, y):\n",
    "    print(f'Train Set for Outer Fold {len(training_folds)}')\n",
    "    print(train)\n",
    "    training_folds.append(train)\n",
    "    # print(\"Test\")\n",
    "    # print(test[0], test[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sets for Outer Fold 0\n",
      "Train Set for Inner Fold 0\n",
      "[  54   62   66 ... 2297 2298 2299]\n",
      "\n",
      "Train Set for Inner Fold 1\n",
      "[   0    1    2 ... 2297 2298 2299]\n",
      "\n",
      "Train Set for Inner Fold 2\n",
      "[   0    1    2 ... 1546 1547 1548]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inner CV\n",
    "outer_fold_number = 0\n",
    "\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "plot_cv_indices(cv, X.iloc[training_folds[outer_fold_number]], y[training_folds[outer_fold_number]], ax)\n",
    "plt.rc('text') # , usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "plt.title(f'Inner Fold for Outer Fold {outer_fold_number}')\n",
    "# Save as file\n",
    "# plt.savefig('./blockingtimeseriessplit.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "inner_training_folds = []\n",
    "print(f'Train Sets for Outer Fold {outer_fold_number}')\n",
    "for train, test in cv.split(X.iloc[training_folds[outer_fold_number]], y[training_folds[outer_fold_number]]):\n",
    "    print(f'Train Set for Inner Fold {len(inner_training_folds)}')\n",
    "    print(train)\n",
    "    inner_training_folds.append(train)\n",
    "    # print(\"Test\")\n",
    "    # print(test[0], test[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photonai import PipelineElement, Switch\n",
    "from photonai.optimization import IntegerRange, FloatRange\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "estimator_selection = Switch('estimators')\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"LogisticRegression\",\n",
    "    base_element=LogisticRegression(class_weight='balanced', random_state=4),\n",
    "    hyperparameters={\n",
    "        'C': FloatRange(1, 10)\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"DecisionTreeClassifier\",\n",
    "    base_element=DecisionTreeClassifier(random_state=4, criterion='gini'),\n",
    "    hyperparameters={\n",
    "        'min_samples_split': IntegerRange(2, 30),\n",
    "        'min_samples_leaf': IntegerRange(2, 30)\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"LinearSVC\",\n",
    "    base_element=LinearSVC(class_weight='balanced', random_state=4),\n",
    "    hyperparameters={\n",
    "        'C': FloatRange(1, 25)\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"RandomForestClassifier\",\n",
    "    base_element=RandomForestClassifier(random_state=4, criterion='gini', bootstrap=True),\n",
    "    hyperparameters={\n",
    "        'min_samples_split': IntegerRange(2, 30),\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"GradientBoostingClassifier\",\n",
    "    base_element=GradientBoostingClassifier(random_state=4),\n",
    "    hyperparameters={\n",
    "        'loss': ['log_loss', 'exponential'],\n",
    "        'learning_rate': FloatRange(0.001, 1, 'logspace')\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add LGBMClassifier\n",
    "estimator_selection += PipelineElement(\n",
    "    \"LGBMClassifier\",\n",
    "    base_element=LGBMClassifier(random_state=4),\n",
    "    hyperparameters={\n",
    "        \"n_estimators\": IntegerRange(50, 150, step=10, range_type=\"range\"),\n",
    "        \"learning_rate\": FloatRange(0.01, 0.3, range_type=\"logspace\"),\n",
    "        \"max_depth\": IntegerRange(3, 10, step=1, range_type=\"range\")\n",
    "    }\n",
    ")\n",
    "# estimator_selection += PipelineElement(\n",
    "#     \"LGBMClassifier\",\n",
    "#     base_element=LGBMClassifier(random_state=4),\n",
    "#     hyperparameters={\n",
    "#         \"n_estimators\": IntegerRange(50, 150, step=10, range_type=\"range\"),\n",
    "#         \"learning_rate\": FloatRange(0.01, 0.3, range_type=\"logspace\"),\n",
    "#         \"max_depth\": IntegerRange(3, 10, step=1, range_type=\"range\")\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     16,
     20,
     25,
     29
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initial_pipeline = Hyperpipe('1 - Initial Pipeline',\n",
    "#                      outer_cv = StratifiedKFold(n_splits=5, shuffle=False),\n",
    "#                      inner_cv = StratifiedKFold(n_splits=3, shuffle=False),\n",
    "#                      use_test_set = False,\n",
    "#                      metrics = list(metrics.keys()),\n",
    "#                      best_config_metric='balanced_accuracy',\n",
    "#                      optimizer='switch',\n",
    "#                      optimizer_params={'name': 'sk_opt', 'n_configurations': 30},\n",
    "#                      project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "#                      cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "#                      verbosity=1,\n",
    "#                      performance_constraints=[MinimumPerformanceConstraint('balanced_accuracy', 0.75, 'mean')])\n",
    "\n",
    "# # Add learning algorithms to compare\n",
    "# initial_pipeline += estimator_selection\n",
    "\n",
    "# # Fit hyperpipe\n",
    "# initial_pipeline.fit(X, y)\n",
    "\n",
    "# # Show learning algorithms mean validation results\n",
    "# # print(\"Comparison on learning algorithms on validation set\")\n",
    "# # print(initial_pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# # # Show feature importances\n",
    "# # print_feature_importances(initial_pipeline)\n",
    "\n",
    "# # # View CV splits for debugging\n",
    "# # for k,v in initial_pipeline.cross_validation.outer_folds.items():\n",
    "# #     print(v.train_indices)\n",
    "# #     print(v.test_indices)\n",
    "# #     print(len(v.train_indices), len(v.test_indices))\n",
    "# #     print()\n",
    "\n",
    "# # Write other reports to summary file\n",
    "# add_other_report_to_summary(initial_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classifier = LogisticRegression(random_state=4).fit(X, y)\n",
    "\n",
    "# feature_selection_pipeline = Hyperpipe('2 - Feature Selection Pipline',\n",
    "#                      outer_cv = StratifiedKFold(n_splits=5, shuffle=False),\n",
    "#                      inner_cv = StratifiedKFold(n_splits=3, shuffle=False),\n",
    "#                      use_test_set = False,\n",
    "#                      metrics = list(metrics.keys()),\n",
    "#                      best_config_metric='balanced_accuracy',\n",
    "#                      optimizer='switch',\n",
    "#                      optimizer_params={'name': 'sk_opt', 'n_configurations': 30},\n",
    "#                      project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "#                      cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "#                      verbosity=1,\n",
    "#                      performance_constraints=[MinimumPerformanceConstraint('balanced_accuracy', 0.75, 'mean')])\n",
    "\n",
    "# feature_selection_pipeline += PipelineElement('RFE', \n",
    "#                            hyperparameters={\n",
    "#                                'n_features_to_select': IntegerRange(2, (len(columns) - 2))\n",
    "#                            }, estimator=classifier)\n",
    "\n",
    "# feature_selection_pipeline += estimator_selection\n",
    "\n",
    "# # Fit hyperpipe\n",
    "# feature_selection_pipeline.fit(X, y)\n",
    "\n",
    "# # Show learning algorithms mean validation results\n",
    "# # print(\"Comparison on learning algorithms on validation set\")\n",
    "# # print(feature_selection_pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# # # Show feature importances\n",
    "# # print_feature_importances(feature_selection_pipeline)\n",
    "\n",
    "# # # View CV splits for debugging\n",
    "# # for k,v in feature_selection_pipeline.cross_validation.outer_folds.items():\n",
    "# #     print(v.train_indices)\n",
    "# #     print(v.test_indices)\n",
    "# #     print(len(v.train_indices), len(v.test_indices))\n",
    "# #     print()\n",
    "\n",
    "# # Write other reports to summary file\n",
    "# add_other_report_to_summary(feature_selection_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalanced Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_imbalanced_pipeline = Hyperpipe('3 - Class Imbalanced Pipline',\n",
    "#                      outer_cv = StratifiedKFold(n_splits=5, shuffle=False),\n",
    "#                      inner_cv = StratifiedKFold(n_splits=3, shuffle=False),\n",
    "#                      use_test_set = False,\n",
    "#                      metrics = list(metrics.keys()),\n",
    "#                      best_config_metric='balanced_accuracy',\n",
    "#                      optimizer='switch',\n",
    "#                      optimizer_params={'name': 'sk_opt', 'n_configurations': 30},\n",
    "#                      project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "#                      cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "#                      verbosity=1,\n",
    "#                      performance_constraints=[MinimumPerformanceConstraint('balanced_accuracy', 0.75, 'mean')])\n",
    "\n",
    "# tested_methods = Categorical(['RandomUnderSampler', 'RandomOverSampler', 'SMOTE', 'BorderlineSMOTE'])\n",
    "# class_imbalanced_pipeline += PipelineElement('ImbalancedDataTransformer',\n",
    "#                            hyperparameters={ 'method_name': tested_methods })\n",
    "\n",
    "# class_imbalanced_pipeline += estimator_selection\n",
    "\n",
    "# # Fit hyperpipe\n",
    "# class_imbalanced_pipeline.fit(X, y)\n",
    "\n",
    "# # Show learning algorithms mean validation results\n",
    "# # print(\"Comparison on learning algorithms on validation set\")\n",
    "# # print(class_imbalanced_pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# # # Show feature importances\n",
    "# # print_feature_importances(class_imbalanced_pipeline)\n",
    "\n",
    "# # # View CV splits for debugging\n",
    "# # for k,v in class_imbalanced_pipeline.cross_validation.outer_folds.items():\n",
    "# #     print(v.train_indices)\n",
    "# #     print(v.test_indices)\n",
    "# #     print(len(v.train_indices), len(v.test_indices))\n",
    "# #     print()\n",
    "\n",
    "# # Write other reports to summary file\n",
    "# add_other_report_to_summary(class_imbalanced_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "737f77f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from photonai.base.hyperpipe import OutputSettings\n",
    "\n",
    "# Save original method\n",
    "original_update_settings = OutputSettings.update_settings\n",
    "\n",
    "def patched_update_settings(self, name, timestamp):\n",
    "    max_retries = 5\n",
    "    delay = 1  # seconds\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            original_update_settings(self, name, timestamp)\n",
    "            break  # success, exit retry loop\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError on attempt {attempt+1}/{max_retries} when updating settings: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(\"Max retries reached. Raising the PermissionError.\")\n",
    "                raise\n",
    "\n",
    "# Apply monkey patch\n",
    "OutputSettings.update_settings = patched_update_settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalanced + Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = LogisticRegression(random_state=4).fit(X, y)\n",
    "\n",
    "# class_imbalanced_feature_selection_pipeline = Hyperpipe('4 - CI and FS Pipeline',\n",
    "#                      outer_cv = StratifiedKFold(n_splits=5, shuffle=False),\n",
    "#                      inner_cv = StratifiedKFold(n_splits=3, shuffle=False),\n",
    "#                      use_test_set = False,\n",
    "#                      metrics = list(metrics.keys()),\n",
    "#                      best_config_metric='balanced_accuracy',\n",
    "#                      optimizer='switch',\n",
    "#                      optimizer_params={'name': 'sk_opt', 'n_configurations': 30},\n",
    "#                      project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "#                      cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "#                      verbosity=1,\n",
    "#                      performance_constraints=[MinimumPerformanceConstraint('balanced_accuracy', 0.75, 'mean')])\n",
    "\n",
    "\n",
    "# tested_methods = Categorical(['RandomUnderSampler', 'RandomOverSampler', 'SMOTE', 'BorderlineSMOTE'])\n",
    "# class_imbalanced_feature_selection_pipeline += PipelineElement('ImbalancedDataTransformer',\n",
    "#                            hyperparameters={ 'method_name': tested_methods })\n",
    "\n",
    "# class_imbalanced_feature_selection_pipeline += PipelineElement('RFE', \n",
    "#                            hyperparameters={\n",
    "#                                'n_features_to_select': IntegerRange(2, (len(columns) - 2))\n",
    "#                            }, estimator=classifier)\n",
    "\n",
    "# class_imbalanced_feature_selection_pipeline += estimator_selection\n",
    "\n",
    "# # Fit hyperpipe\n",
    "# class_imbalanced_feature_selection_pipeline.fit(X, y)\n",
    "\n",
    "# # Show learning algorithms mean validation results\n",
    "\n",
    "# # print(\"Comparison on learning algorithms on validation set\")\n",
    "# # print(class_imbalanced_feature_selection_pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# # # Show feature importances\n",
    "# # print_feature_importances(class_imbalanced_feature_selection_pipeline)\n",
    "\n",
    "# # # View CV splits for debugging\n",
    "# # for k,v in class_imbalanced_feature_selection_pipeline.cross_validation.outer_folds.items():\n",
    "# #     print(v.train_indices)\n",
    "# #     print(v.test_indices)\n",
    "# #     print(len(v.train_indices), len(v.test_indices))\n",
    "# #     print()\n",
    "\n",
    "# # Write other reports to summary file\n",
    "# add_other_report_to_summary(class_imbalanced_feature_selection_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CI GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:07:57 | Output Folder: ./analysis/participant2_15min\\5FinalPipelineCIFSGB_results_2025-06-25_15-07-57\n",
      "=====================================================================================================\n",
      "PHOTONAI ANALYSIS: 5FinalPipelineCIFSGB\n",
      "=====================================================================================================\n",
      "25/06/2025-15:07:57 | Preparing data and PHOTONAI objects for analysis...\n",
      "25/06/2025-15:07:57 | Checking input data...\n",
      "25/06/2025-15:07:57 | Running analysis with 2876 samples.\n",
      "Found 2 target classes: [0 1]\n",
      "Target classes are imbalanced: 96.55771905424201% belongs to 0\n",
      "25/06/2025-15:07:57 | Removing cache files...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 1\n",
      "*****************************************************************************************************\n",
      "25/06/2025-15:07:57 | Preparing data for outer fold 1...\n",
      "25/06/2025-15:07:57 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-15:07:57 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.9653 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:07:59 | Computed configuration 2/30 in 0:00:01.687261\n",
      "25/06/2025-15:07:59 | Performance:             balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "25/06/2025-15:07:59 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:07:59 | Computed configuration 3/30 in 0:00:00.298556\n",
      "25/06/2025-15:07:59 | Performance:             balanced_accuracy - Train: 1.0000, Validation: 0.5045\n",
      "25/06/2025-15:07:59 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:08:00 | Computed configuration 5/30 in 0:00:01.103363\n",
      "25/06/2025-15:08:00 | Performance:             balanced_accuracy - Train: 0.9674, Validation: 0.5350\n",
      "25/06/2025-15:08:00 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:02 | Computed configuration 6/30 in 0:00:01.959597\n",
      "25/06/2025-15:08:02 | Performance:             balanced_accuracy - Train: 0.9498, Validation: 0.5472\n",
      "25/06/2025-15:08:02 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:04 | Computed configuration 7/30 in 0:00:01.653190\n",
      "25/06/2025-15:08:04 | Performance:             balanced_accuracy - Train: 0.9448, Validation: 0.5743\n",
      "25/06/2025-15:08:04 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:04 | Computed configuration 8/30 in 0:00:00.312102\n",
      "25/06/2025-15:08:04 | Performance:             balanced_accuracy - Train: 0.9906, Validation: 0.5638\n",
      "25/06/2025-15:08:04 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:08:06 | Computed configuration 10/30 in 0:00:01.947520\n",
      "25/06/2025-15:08:06 | Performance:             balanced_accuracy - Train: 0.9997, Validation: 0.3384\n",
      "25/06/2025-15:08:06 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002049128507720536\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:07 | Computed configuration 11/30 in 0:00:01.038616\n",
      "25/06/2025-15:08:07 | Performance:             balanced_accuracy - Train: 0.9369, Validation: 0.5418\n",
      "25/06/2025-15:08:07 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.27747856055598813\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:10 | Computed configuration 12/30 in 0:00:01.727517\n",
      "25/06/2025-15:08:10 | Performance:             balanced_accuracy - Train: 0.9955, Validation: 0.3245\n",
      "25/06/2025-15:08:10 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0011227188841179657\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:12 | Computed configuration 13/30 in 0:00:01.603096\n",
      "25/06/2025-15:08:12 | Performance:             balanced_accuracy - Train: 0.9448, Validation: 0.5743\n",
      "25/06/2025-15:08:12 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.01908612990479662\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:14 | Computed configuration 14/30 in 0:00:01.677877\n",
      "25/06/2025-15:08:14 | Performance:             balanced_accuracy - Train: 0.9710, Validation: 0.5062\n",
      "25/06/2025-15:08:14 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0011178249558918643\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:16 | Computed configuration 15/30 in 0:00:01.714560\n",
      "25/06/2025-15:08:16 | Performance:             balanced_accuracy - Train: 0.9448, Validation: 0.5743\n",
      "25/06/2025-15:08:16 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0010161834279487567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:18 | Computed configuration 16/30 in 0:00:01.660783\n",
      "25/06/2025-15:08:18 | Performance:             balanced_accuracy - Train: 0.9448, Validation: 0.5743\n",
      "25/06/2025-15:08:18 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.03926033341026757\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:20 | Computed configuration 17/30 in 0:00:01.603225\n",
      "25/06/2025-15:08:20 | Performance:             balanced_accuracy - Train: 0.9768, Validation: 0.4310\n",
      "25/06/2025-15:08:20 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0011257788368034514\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:22 | Computed configuration 18/30 in 0:00:01.604986\n",
      "25/06/2025-15:08:22 | Performance:             balanced_accuracy - Train: 0.9448, Validation: 0.5743\n",
      "25/06/2025-15:08:22 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0030186414568050043\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:24 | Computed configuration 19/30 in 0:00:01.589109\n",
      "25/06/2025-15:08:24 | Performance:             balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "25/06/2025-15:08:24 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.004705856717464809\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:26 | Computed configuration 20/30 in 0:00:01.734927\n",
      "25/06/2025-15:08:26 | Performance:             balanced_accuracy - Train: 0.9465, Validation: 0.5707\n",
      "25/06/2025-15:08:26 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.009849160105442399\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:28 | Computed configuration 21/30 in 0:00:01.638157\n",
      "25/06/2025-15:08:28 | Performance:             balanced_accuracy - Train: 0.9549, Validation: 0.5194\n",
      "25/06/2025-15:08:28 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0011851221847615407\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:30 | Computed configuration 22/30 in 0:00:01.586294\n",
      "25/06/2025-15:08:30 | Performance:             balanced_accuracy - Train: 0.9448, Validation: 0.5743\n",
      "25/06/2025-15:08:30 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.06134773806807077\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:30 | Computed configuration 23/30 in 0:00:00.316441\n",
      "25/06/2025-15:08:30 | Performance:             balanced_accuracy - Train: 1.0000, Validation: 0.5302\n",
      "25/06/2025-15:08:30 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001170074112966362\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:32 | Computed configuration 24/30 in 0:00:01.575832\n",
      "25/06/2025-15:08:32 | Performance:             balanced_accuracy - Train: 0.9448, Validation: 0.5743\n",
      "25/06/2025-15:08:32 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.07875069407640296\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:33 | Computed configuration 25/30 in 0:00:00.310883\n",
      "25/06/2025-15:08:33 | Performance:             balanced_accuracy - Train: 1.0000, Validation: 0.5378\n",
      "25/06/2025-15:08:33 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.16014952756787257\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:34 | Computed configuration 26/30 in 0:00:00.368024\n",
      "25/06/2025-15:08:34 | Performance:             balanced_accuracy - Train: 1.0000, Validation: 0.5358\n",
      "25/06/2025-15:08:34 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0011711004112511022\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:36 | Computed configuration 27/30 in 0:00:01.537623\n",
      "25/06/2025-15:08:36 | Performance:             balanced_accuracy - Train: 0.9448, Validation: 0.5743\n",
      "25/06/2025-15:08:36 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.21536385609224884\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:36 | Computed configuration 28/30 in 0:00:00.337524\n",
      "25/06/2025-15:08:36 | Performance:             balanced_accuracy - Train: 1.0000, Validation: 0.5124\n",
      "25/06/2025-15:08:36 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0010649318235442715\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:38 | Computed configuration 29/30 in 0:00:01.790863\n",
      "25/06/2025-15:08:38 | Performance:             balanced_accuracy - Train: 0.9448, Validation: 0.5743\n",
      "25/06/2025-15:08:38 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.024899449797247626\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:41 | Computed configuration 30/30 in 0:00:01.897232\n",
      "25/06/2025-15:08:41 | Performance:             balanced_accuracy - Train: 0.9697, Validation: 0.5093\n",
      "25/06/2025-15:08:41 | Best Performance So Far: balanced_accuracy - Train: 0.9450, Validation: 0.5743\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-15:08:41 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-15:08:41 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9450      |      0.5743      |\n",
      "|      f1_score     |       0.9462      |      0.1393      |\n",
      "|      accuracy     |       0.9450      |      0.6175      |\n",
      "|     precision     |       0.9262      |      0.1197      |\n",
      "|    sensitivity    |       0.9683      |      0.5280      |\n",
      "|    specificity    |       0.9216      |      0.6206      |\n",
      "|        auc        |       0.9450      |      0.5743      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:08:42 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9167      |      0.5863      |\n",
      "|      f1_score     |       0.9188      |      0.0800      |\n",
      "|      accuracy     |       0.9167      |      0.2014      |\n",
      "|     precision     |       0.8960      |      0.0417      |\n",
      "|    sensitivity    |       0.9428      |      1.0000      |\n",
      "|    specificity    |       0.8906      |      0.1727      |\n",
      "|        auc        |       0.9167      |      0.5863      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:08:42 | Computations in outer fold 1 took 0.74559065 minutes.\n",
      "25/06/2025-15:08:42 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 2\n",
      "*****************************************************************************************************\n",
      "25/06/2025-15:08:43 | Preparing data for outer fold 2...\n",
      "25/06/2025-15:08:43 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-15:08:43 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.9670 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:08:44 | Computed configuration 2/30 in 0:00:01.901395\n",
      "25/06/2025-15:08:44 | Performance:             balanced_accuracy - Train: 0.9209, Validation: 0.6973\n",
      "25/06/2025-15:08:44 | Best Performance So Far: balanced_accuracy - Train: 0.9209, Validation: 0.6973\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:45 | Computed configuration 3/30 in 0:00:00.347674\n",
      "25/06/2025-15:08:45 | Performance:             balanced_accuracy - Train: 1.0000, Validation: 0.6075\n",
      "25/06/2025-15:08:45 | Best Performance So Far: balanced_accuracy - Train: 0.9209, Validation: 0.6973\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:08:46 | Computed configuration 5/30 in 0:00:01.116013\n",
      "25/06/2025-15:08:46 | Performance:             balanced_accuracy - Train: 0.9370, Validation: 0.6386\n",
      "25/06/2025-15:08:46 | Best Performance So Far: balanced_accuracy - Train: 0.9209, Validation: 0.6973\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:48 | Computed configuration 6/30 in 0:00:01.967877\n",
      "25/06/2025-15:08:48 | Performance:             balanced_accuracy - Train: 0.9306, Validation: 0.7178\n",
      "25/06/2025-15:08:48 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7178\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:50 | Computed configuration 7/30 in 0:00:01.809469\n",
      "25/06/2025-15:08:50 | Performance:             balanced_accuracy - Train: 0.9209, Validation: 0.6973\n",
      "25/06/2025-15:08:50 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7178\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:50 | Computed configuration 8/30 in 0:00:00.351536\n",
      "25/06/2025-15:08:50 | Performance:             balanced_accuracy - Train: 0.9686, Validation: 0.6101\n",
      "25/06/2025-15:08:50 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7178\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:08:52 | Computed configuration 10/30 in 0:00:01.946692\n",
      "25/06/2025-15:08:52 | Performance:             balanced_accuracy - Train: 0.9992, Validation: 0.6220\n",
      "25/06/2025-15:08:52 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7178\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002049128507720536\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:54 | Computed configuration 11/30 in 0:00:01.102666\n",
      "25/06/2025-15:08:54 | Performance:             balanced_accuracy - Train: 0.8981, Validation: 0.6615\n",
      "25/06/2025-15:08:54 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7178\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0027479153967228096\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:56 | Computed configuration 12/30 in 0:00:01.786922\n",
      "25/06/2025-15:08:56 | Performance:             balanced_accuracy - Train: 0.9209, Validation: 0.6973\n",
      "25/06/2025-15:08:56 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7178\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.08229530985262312\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:08:58 | Computed configuration 13/30 in 0:00:01.862996\n",
      "25/06/2025-15:08:58 | Performance:             balanced_accuracy - Train: 0.9802, Validation: 0.6505\n",
      "25/06/2025-15:08:58 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7178\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0017932219207202904\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:00 | Computed configuration 14/30 in 0:00:01.841914\n",
      "25/06/2025-15:09:00 | Performance:             balanced_accuracy - Train: 0.9120, Validation: 0.7080\n",
      "25/06/2025-15:09:00 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7178\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006166375906484462\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:02 | Computed configuration 15/30 in 0:00:01.878617\n",
      "25/06/2025-15:09:02 | Performance:             balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "25/06/2025-15:09:02 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.012039815915051787\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:05 | Computed configuration 16/30 in 0:00:01.847883\n",
      "25/06/2025-15:09:05 | Performance:             balanced_accuracy - Train: 0.9437, Validation: 0.6986\n",
      "25/06/2025-15:09:05 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.010426216388298654\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:07 | Computed configuration 17/30 in 0:00:01.865588\n",
      "25/06/2025-15:09:07 | Performance:             balanced_accuracy - Train: 0.9429, Validation: 0.6995\n",
      "25/06/2025-15:09:07 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0032557773941822364\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:09 | Computed configuration 18/30 in 0:00:01.826817\n",
      "25/06/2025-15:09:09 | Performance:             balanced_accuracy - Train: 0.9120, Validation: 0.7080\n",
      "25/06/2025-15:09:09 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.018662019439210965\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:11 | Computed configuration 19/30 in 0:00:01.935782\n",
      "25/06/2025-15:09:11 | Performance:             balanced_accuracy - Train: 0.9567, Validation: 0.6842\n",
      "25/06/2025-15:09:11 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.030249749599934445\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:13 | Computed configuration 20/30 in 0:00:01.939714\n",
      "25/06/2025-15:09:13 | Performance:             balanced_accuracy - Train: 0.9638, Validation: 0.6693\n",
      "25/06/2025-15:09:13 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.008020051989960319\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:16 | Computed configuration 21/30 in 0:00:01.872204\n",
      "25/06/2025-15:09:16 | Performance:             balanced_accuracy - Train: 0.9349, Validation: 0.7184\n",
      "25/06/2025-15:09:16 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.013554479124617973\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:18 | Computed configuration 22/30 in 0:00:01.839314\n",
      "25/06/2025-15:09:18 | Performance:             balanced_accuracy - Train: 0.9485, Validation: 0.6896\n",
      "25/06/2025-15:09:18 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.00696682897280837\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:20 | Computed configuration 23/30 in 0:00:01.815857\n",
      "25/06/2025-15:09:20 | Performance:             balanced_accuracy - Train: 0.9331, Validation: 0.7182\n",
      "25/06/2025-15:09:20 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.05524982221371206\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:22 | Computed configuration 24/30 in 0:00:01.948667\n",
      "25/06/2025-15:09:22 | Performance:             balanced_accuracy - Train: 0.9754, Validation: 0.6387\n",
      "25/06/2025-15:09:22 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.00633080946058198\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:25 | Computed configuration 25/30 in 0:00:01.885068\n",
      "25/06/2025-15:09:25 | Performance:             balanced_accuracy - Train: 0.9306, Validation: 0.7178\n",
      "25/06/2025-15:09:25 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006324970282728664\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:27 | Computed configuration 26/30 in 0:00:01.838261\n",
      "25/06/2025-15:09:27 | Performance:             balanced_accuracy - Train: 0.9306, Validation: 0.7178\n",
      "25/06/2025-15:09:27 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.00649810629677213\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:29 | Computed configuration 27/30 in 0:00:01.855984\n",
      "25/06/2025-15:09:29 | Performance:             balanced_accuracy - Train: 0.9318, Validation: 0.7178\n",
      "25/06/2025-15:09:29 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.007708881680669948\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:31 | Computed configuration 28/30 in 0:00:01.898540\n",
      "25/06/2025-15:09:31 | Performance:             balanced_accuracy - Train: 0.9335, Validation: 0.7182\n",
      "25/06/2025-15:09:31 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.008286433875861457\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:33 | Computed configuration 29/30 in 0:00:01.893945\n",
      "25/06/2025-15:09:33 | Performance:             balanced_accuracy - Train: 0.9349, Validation: 0.7182\n",
      "25/06/2025-15:09:33 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.01610629513829049\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:36 | Computed configuration 30/30 in 0:00:01.921380\n",
      "25/06/2025-15:09:36 | Performance:             balanced_accuracy - Train: 0.9523, Validation: 0.6839\n",
      "25/06/2025-15:09:36 | Best Performance So Far: balanced_accuracy - Train: 0.9306, Validation: 0.7250\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-15:09:36 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-15:09:36 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006166375906484462\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9306      |      0.7250      |\n",
      "|      f1_score     |       0.9330      |      0.1746      |\n",
      "|      accuracy     |       0.9306      |      0.6297      |\n",
      "|     precision     |       0.9024      |      0.1070      |\n",
      "|    sensitivity    |       0.9660      |      0.8272      |\n",
      "|    specificity    |       0.8951      |      0.6227      |\n",
      "|        auc        |       0.9306      |      0.7250      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:09:37 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9027      |      0.7743      |\n",
      "|      f1_score     |       0.9045      |      0.1315      |\n",
      "|      accuracy     |       0.9027      |      0.5635      |\n",
      "|     precision     |       0.8887      |      0.0704      |\n",
      "|    sensitivity    |       0.9208      |      1.0000      |\n",
      "|    specificity    |       0.8847      |      0.5486      |\n",
      "|        auc        |       0.9027      |      0.7743      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:09:37 | Computations in outer fold 2 took 0.9093177666666666 minutes.\n",
      "25/06/2025-15:09:37 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 3\n",
      "*****************************************************************************************************\n",
      "25/06/2025-15:09:38 | Preparing data for outer fold 3...\n",
      "25/06/2025-15:09:38 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-15:09:38 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.9652 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:09:40 | Computed configuration 2/30 in 0:00:01.800744\n",
      "25/06/2025-15:09:40 | Performance:             balanced_accuracy - Train: 0.8907, Validation: 0.5301\n",
      "25/06/2025-15:09:40 | Best Performance So Far: balanced_accuracy - Train: 0.8907, Validation: 0.5301\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:40 | Computed configuration 3/30 in 0:00:00.341283\n",
      "25/06/2025-15:09:40 | Performance:             balanced_accuracy - Train: 1.0000, Validation: 0.5116\n",
      "25/06/2025-15:09:40 | Best Performance So Far: balanced_accuracy - Train: 0.8907, Validation: 0.5301\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:09:42 | Computed configuration 5/30 in 0:00:01.050560\n",
      "25/06/2025-15:09:42 | Performance:             balanced_accuracy - Train: 0.9298, Validation: 0.4927\n",
      "25/06/2025-15:09:42 | Best Performance So Far: balanced_accuracy - Train: 0.8907, Validation: 0.5301\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:43 | Computed configuration 6/30 in 0:00:01.893741\n",
      "25/06/2025-15:09:43 | Performance:             balanced_accuracy - Train: 0.9237, Validation: 0.5058\n",
      "25/06/2025-15:09:43 | Best Performance So Far: balanced_accuracy - Train: 0.8907, Validation: 0.5301\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:45 | Computed configuration 7/30 in 0:00:01.742733\n",
      "25/06/2025-15:09:45 | Performance:             balanced_accuracy - Train: 0.8846, Validation: 0.5301\n",
      "25/06/2025-15:09:45 | Best Performance So Far: balanced_accuracy - Train: 0.8907, Validation: 0.5301\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:46 | Computed configuration 8/30 in 0:00:00.337813\n",
      "25/06/2025-15:09:46 | Performance:             balanced_accuracy - Train: 0.9556, Validation: 0.5048\n",
      "25/06/2025-15:09:46 | Best Performance So Far: balanced_accuracy - Train: 0.8907, Validation: 0.5301\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:09:48 | Computed configuration 10/30 in 0:00:01.973969\n",
      "25/06/2025-15:09:48 | Performance:             balanced_accuracy - Train: 0.9990, Validation: 0.4921\n",
      "25/06/2025-15:09:48 | Best Performance So Far: balanced_accuracy - Train: 0.8907, Validation: 0.5301\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002049128507720536\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:49 | Computed configuration 11/30 in 0:00:01.065197\n",
      "25/06/2025-15:09:49 | Performance:             balanced_accuracy - Train: 0.8902, Validation: 0.5484\n",
      "25/06/2025-15:09:49 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5484\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0014666036255122862\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:51 | Computed configuration 12/30 in 0:00:01.734882\n",
      "25/06/2025-15:09:51 | Performance:             balanced_accuracy - Train: 0.8846, Validation: 0.5301\n",
      "25/06/2025-15:09:51 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5484\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001014094466019487\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:52 | Computed configuration 13/30 in 0:00:00.317983\n",
      "25/06/2025-15:09:52 | Performance:             balanced_accuracy - Train: 0.9052, Validation: 0.5053\n",
      "25/06/2025-15:09:52 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5484\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0017932219207202904\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:54 | Computed configuration 14/30 in 0:00:01.835108\n",
      "25/06/2025-15:09:54 | Performance:             balanced_accuracy - Train: 0.8772, Validation: 0.4923\n",
      "25/06/2025-15:09:54 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5484\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0016872911623977912\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:54 | Computed configuration 15/30 in 0:00:00.296629\n",
      "25/06/2025-15:09:54 | Performance:             balanced_accuracy - Train: 0.9084, Validation: 0.5115\n",
      "25/06/2025-15:09:54 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5484\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0020039562505481177\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:56 | Computed configuration 16/30 in 0:00:01.049320\n",
      "25/06/2025-15:09:56 | Performance:             balanced_accuracy - Train: 0.8902, Validation: 0.5540\n",
      "25/06/2025-15:09:56 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5540\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0019331202433789183\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:57 | Computed configuration 17/30 in 0:00:01.032771\n",
      "25/06/2025-15:09:57 | Performance:             balanced_accuracy - Train: 0.8902, Validation: 0.5544\n",
      "25/06/2025-15:09:57 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5544\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002286005199655906\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:59 | Computed configuration 18/30 in 0:00:01.055554\n",
      "25/06/2025-15:09:59 | Performance:             balanced_accuracy - Train: 0.8902, Validation: 0.5540\n",
      "25/06/2025-15:09:59 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5544\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026291488026341904\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:00 | Computed configuration 19/30 in 0:00:01.020175\n",
      "25/06/2025-15:10:00 | Performance:             balanced_accuracy - Train: 0.8902, Validation: 0.5540\n",
      "25/06/2025-15:10:00 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5544\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.02933273623143572\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:02 | Computed configuration 20/30 in 0:00:01.060120\n",
      "25/06/2025-15:10:02 | Performance:             balanced_accuracy - Train: 0.9449, Validation: 0.5289\n",
      "25/06/2025-15:10:02 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5544\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0022634623115763957\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:03 | Computed configuration 21/30 in 0:00:01.106321\n",
      "25/06/2025-15:10:03 | Performance:             balanced_accuracy - Train: 0.8902, Validation: 0.5540\n",
      "25/06/2025-15:10:03 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5544\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.004386127752738684\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:04 | Computed configuration 22/30 in 0:00:01.067131\n",
      "25/06/2025-15:10:04 | Performance:             balanced_accuracy - Train: 0.8934, Validation: 0.5385\n",
      "25/06/2025-15:10:04 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5544\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0033137626573489292\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:06 | Computed configuration 23/30 in 0:00:01.034233\n",
      "25/06/2025-15:10:06 | Performance:             balanced_accuracy - Train: 0.8925, Validation: 0.5371\n",
      "25/06/2025-15:10:06 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5544\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0030277522211381064\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:07 | Computed configuration 24/30 in 0:00:01.003861\n",
      "25/06/2025-15:10:07 | Performance:             balanced_accuracy - Train: 0.8925, Validation: 0.5371\n",
      "25/06/2025-15:10:07 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5544\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0021547550304599427\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:09 | Computed configuration 25/30 in 0:00:01.045586\n",
      "25/06/2025-15:10:09 | Performance:             balanced_accuracy - Train: 0.8902, Validation: 0.5488\n",
      "25/06/2025-15:10:09 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5544\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.004146730344341844\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:10 | Computed configuration 26/30 in 0:00:01.029268\n",
      "25/06/2025-15:10:10 | Performance:             balanced_accuracy - Train: 0.8934, Validation: 0.5385\n",
      "25/06/2025-15:10:10 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5544\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0012961994828012274\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:12 | Computed configuration 27/30 in 0:00:01.025639\n",
      "25/06/2025-15:10:12 | Performance:             balanced_accuracy - Train: 0.8902, Validation: 0.5623\n",
      "25/06/2025-15:10:12 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5623\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.02621675927570768\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:13 | Computed configuration 28/30 in 0:00:01.132488\n",
      "25/06/2025-15:10:13 | Performance:             balanced_accuracy - Train: 0.9437, Validation: 0.5051\n",
      "25/06/2025-15:10:13 | Best Performance So Far: balanced_accuracy - Train: 0.8902, Validation: 0.5623\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006074810856240831\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:14 | Computed configuration 29/30 in 0:00:01.048013\n",
      "25/06/2025-15:10:14 | Performance:             balanced_accuracy - Train: 0.9131, Validation: 0.5651\n",
      "25/06/2025-15:10:14 | Best Performance So Far: balanced_accuracy - Train: 0.9131, Validation: 0.5651\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006817654224626131\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:16 | Computed configuration 30/30 in 0:00:01.047795\n",
      "25/06/2025-15:10:16 | Performance:             balanced_accuracy - Train: 0.9131, Validation: 0.5786\n",
      "25/06/2025-15:10:16 | Best Performance So Far: balanced_accuracy - Train: 0.9131, Validation: 0.5786\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-15:10:16 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-15:10:16 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006817654224626131\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9131      |      0.5786      |\n",
      "|      f1_score     |       0.9199      |      0.1460      |\n",
      "|      accuracy     |       0.9131      |      0.5958      |\n",
      "|     precision     |       0.8750      |      0.1118      |\n",
      "|    sensitivity    |       0.9764      |      0.5598      |\n",
      "|    specificity    |       0.8499      |      0.5974      |\n",
      "|        auc        |       0.9131      |      0.5786      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:10:17 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.8681      |      0.9250      |\n",
      "|      f1_score     |       0.8744      |      0.9189      |\n",
      "|      accuracy     |       0.8681      |      0.9948      |\n",
      "|     precision     |       0.8347      |      1.0000      |\n",
      "|    sensitivity    |       0.9181      |      0.8500      |\n",
      "|    specificity    |       0.8182      |      1.0000      |\n",
      "|        auc        |       0.8681      |      0.9250      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:10:17 | Computations in outer fold 3 took 0.64150865 minutes.\n",
      "25/06/2025-15:10:17 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 4\n",
      "*****************************************************************************************************\n",
      "25/06/2025-15:10:19 | Preparing data for outer fold 4...\n",
      "25/06/2025-15:10:19 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-15:10:19 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.9652 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:10:21 | Computed configuration 2/30 in 0:00:02.001086\n",
      "25/06/2025-15:10:21 | Performance:             balanced_accuracy - Train: 0.8900, Validation: 0.4880\n",
      "25/06/2025-15:10:21 | Best Performance So Far: balanced_accuracy - Train: 0.8900, Validation: 0.4880\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:21 | Computed configuration 3/30 in 0:00:00.443929\n",
      "25/06/2025-15:10:21 | Performance:             balanced_accuracy - Train: 1.0000, Validation: 0.4975\n",
      "25/06/2025-15:10:21 | Best Performance So Far: balanced_accuracy - Train: 1.0000, Validation: 0.4975\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:10:23 | Computed configuration 5/30 in 0:00:01.353079\n",
      "25/06/2025-15:10:23 | Performance:             balanced_accuracy - Train: 0.9379, Validation: 0.4514\n",
      "25/06/2025-15:10:23 | Best Performance So Far: balanced_accuracy - Train: 1.0000, Validation: 0.4975\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:25 | Computed configuration 6/30 in 0:00:01.964153\n",
      "25/06/2025-15:10:25 | Performance:             balanced_accuracy - Train: 0.9214, Validation: 0.4552\n",
      "25/06/2025-15:10:25 | Best Performance So Far: balanced_accuracy - Train: 1.0000, Validation: 0.4975\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:26 | Computed configuration 7/30 in 0:00:01.958162\n",
      "25/06/2025-15:10:26 | Performance:             balanced_accuracy - Train: 0.8876, Validation: 0.4880\n",
      "25/06/2025-15:10:26 | Best Performance So Far: balanced_accuracy - Train: 1.0000, Validation: 0.4975\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:27 | Computed configuration 8/30 in 0:00:00.413175\n",
      "25/06/2025-15:10:27 | Performance:             balanced_accuracy - Train: 0.9777, Validation: 0.4809\n",
      "25/06/2025-15:10:27 | Best Performance So Far: balanced_accuracy - Train: 1.0000, Validation: 0.4975\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:10:29 | Computed configuration 10/30 in 0:00:02.090314\n",
      "25/06/2025-15:10:29 | Performance:             balanced_accuracy - Train: 0.9974, Validation: 0.5036\n",
      "25/06/2025-15:10:29 | Best Performance So Far: balanced_accuracy - Train: 0.9974, Validation: 0.5036\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0844064265033311\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:30 | Computed configuration 11/30 in 0:00:00.421494\n",
      "25/06/2025-15:10:30 | Performance:             balanced_accuracy - Train: 1.0000, Validation: 0.4796\n",
      "25/06/2025-15:10:30 | Best Performance So Far: balanced_accuracy - Train: 0.9974, Validation: 0.5036\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.27747856055598813\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:32 | Computed configuration 12/30 in 0:00:02.028306\n",
      "25/06/2025-15:10:32 | Performance:             balanced_accuracy - Train: 0.9904, Validation: 0.4888\n",
      "25/06/2025-15:10:32 | Best Performance So Far: balanced_accuracy - Train: 0.9974, Validation: 0.5036\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.4140721970646941\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:34 | Computed configuration 13/30 in 0:00:01.412502\n",
      "25/06/2025-15:10:34 | Performance:             balanced_accuracy - Train: 0.9981, Validation: 0.5463\n",
      "25/06/2025-15:10:34 | Best Performance So Far: balanced_accuracy - Train: 0.9981, Validation: 0.5463\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.9678916409219159\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:36 | Computed configuration 14/30 in 0:00:01.489295\n",
      "25/06/2025-15:10:36 | Performance:             balanced_accuracy - Train: 0.9983, Validation: 0.4835\n",
      "25/06/2025-15:10:36 | Best Performance So Far: balanced_accuracy - Train: 0.9981, Validation: 0.5463\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.45897419917539495\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:38 | Computed configuration 15/30 in 0:00:01.404592\n",
      "25/06/2025-15:10:38 | Performance:             balanced_accuracy - Train: 0.9982, Validation: 0.5054\n",
      "25/06/2025-15:10:38 | Best Performance So Far: balanced_accuracy - Train: 0.9981, Validation: 0.5463\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.4221874350041114\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:40 | Computed configuration 16/30 in 0:00:01.363076\n",
      "25/06/2025-15:10:40 | Performance:             balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "25/06/2025-15:10:40 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.3482035851977699\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:41 | Computed configuration 17/30 in 0:00:01.355210\n",
      "25/06/2025-15:10:41 | Performance:             balanced_accuracy - Train: 0.9976, Validation: 0.5396\n",
      "25/06/2025-15:10:41 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.3508477553158079\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:43 | Computed configuration 18/30 in 0:00:01.289735\n",
      "25/06/2025-15:10:43 | Performance:             balanced_accuracy - Train: 0.9976, Validation: 0.4984\n",
      "25/06/2025-15:10:43 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.29488805579719474\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:45 | Computed configuration 19/30 in 0:00:01.198564\n",
      "25/06/2025-15:10:45 | Performance:             balanced_accuracy - Train: 0.9964, Validation: 0.5170\n",
      "25/06/2025-15:10:45 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.4109431649195514\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:46 | Computed configuration 20/30 in 0:00:01.123566\n",
      "25/06/2025-15:10:46 | Performance:             balanced_accuracy - Train: 0.9982, Validation: 0.5071\n",
      "25/06/2025-15:10:46 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.42183836207795944\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:48 | Computed configuration 21/30 in 0:00:01.143060\n",
      "25/06/2025-15:10:48 | Performance:             balanced_accuracy - Train: 0.9982, Validation: 0.5184\n",
      "25/06/2025-15:10:48 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.2724154483300238\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:49 | Computed configuration 22/30 in 0:00:01.177022\n",
      "25/06/2025-15:10:49 | Performance:             balanced_accuracy - Train: 0.9963, Validation: 0.5212\n",
      "25/06/2025-15:10:49 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.42693549693054444\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:51 | Computed configuration 23/30 in 0:00:01.113877\n",
      "25/06/2025-15:10:51 | Performance:             balanced_accuracy - Train: 0.9982, Validation: 0.5499\n",
      "25/06/2025-15:10:51 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.4320789057978471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:52 | Computed configuration 24/30 in 0:00:01.180430\n",
      "25/06/2025-15:10:52 | Performance:             balanced_accuracy - Train: 0.9982, Validation: 0.5322\n",
      "25/06/2025-15:10:52 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.418594585739365\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:54 | Computed configuration 25/30 in 0:00:01.163037\n",
      "25/06/2025-15:10:54 | Performance:             balanced_accuracy - Train: 0.9982, Validation: 0.5033\n",
      "25/06/2025-15:10:54 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.10187420784263203\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:55 | Computed configuration 26/30 in 0:00:01.112098\n",
      "25/06/2025-15:10:55 | Performance:             balanced_accuracy - Train: 0.9830, Validation: 0.5335\n",
      "25/06/2025-15:10:55 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.10084899979283231\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:57 | Computed configuration 27/30 in 0:00:01.134873\n",
      "25/06/2025-15:10:57 | Performance:             balanced_accuracy - Train: 0.9814, Validation: 0.5370\n",
      "25/06/2025-15:10:57 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.059863715146787295\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:10:58 | Computed configuration 28/30 in 0:00:01.127430\n",
      "25/06/2025-15:10:58 | Performance:             balanced_accuracy - Train: 0.9673, Validation: 0.5301\n",
      "25/06/2025-15:10:58 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.03926760002453936\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:00 | Computed configuration 29/30 in 0:00:01.193909\n",
      "25/06/2025-15:11:00 | Performance:             balanced_accuracy - Train: 0.9601, Validation: 0.5028\n",
      "25/06/2025-15:11:00 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.05902595652388195\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:01 | Computed configuration 30/30 in 0:00:01.163165\n",
      "25/06/2025-15:11:01 | Performance:             balanced_accuracy - Train: 0.9688, Validation: 0.5308\n",
      "25/06/2025-15:11:01 | Best Performance So Far: balanced_accuracy - Train: 0.9979, Validation: 0.5503\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-15:11:02 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-15:11:02 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.4221874350041114\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9979      |      0.5503      |\n",
      "|      f1_score     |       0.9979      |      0.0409      |\n",
      "|      accuracy     |       0.9979      |      0.8118      |\n",
      "|     precision     |       0.9958      |      0.0222      |\n",
      "|    sensitivity    |       1.0000      |      0.2692      |\n",
      "|    specificity    |       0.9957      |      0.8313      |\n",
      "|        auc        |       0.9979      |      0.5503      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:11:02 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9935      |      0.4721      |\n",
      "|      f1_score     |       0.9935      |      0.0000      |\n",
      "|      accuracy     |       0.9935      |      0.9113      |\n",
      "|     precision     |       0.9871      |      0.0000      |\n",
      "|    sensitivity    |       1.0000      |      0.0000      |\n",
      "|    specificity    |       0.9869      |      0.9441      |\n",
      "|        auc        |       0.9935      |      0.4721      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:11:02 | Computations in outer fold 4 took 0.7238937333333334 minutes.\n",
      "25/06/2025-15:11:02 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 5\n",
      "*****************************************************************************************************\n",
      "25/06/2025-15:11:04 | Preparing data for outer fold 5...\n",
      "25/06/2025-15:11:05 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-15:11:05 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.9652 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:11:06 | Computed configuration 2/30 in 0:00:01.659231\n",
      "25/06/2025-15:11:06 | Performance:             balanced_accuracy - Train: 0.9441, Validation: 0.6488\n",
      "25/06/2025-15:11:06 | Best Performance So Far: balanced_accuracy - Train: 0.9441, Validation: 0.6488\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:07 | Computed configuration 3/30 in 0:00:00.309069\n",
      "25/06/2025-15:11:07 | Performance:             balanced_accuracy - Train: 1.0000, Validation: 0.5456\n",
      "25/06/2025-15:11:07 | Best Performance So Far: balanced_accuracy - Train: 0.9441, Validation: 0.6488\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:11:08 | Computed configuration 5/30 in 0:00:01.020778\n",
      "25/06/2025-15:11:08 | Performance:             balanced_accuracy - Train: 0.9522, Validation: 0.5565\n",
      "25/06/2025-15:11:08 | Best Performance So Far: balanced_accuracy - Train: 0.9441, Validation: 0.6488\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:09 | Computed configuration 6/30 in 0:00:01.740975\n",
      "25/06/2025-15:11:09 | Performance:             balanced_accuracy - Train: 0.9437, Validation: 0.6587\n",
      "25/06/2025-15:11:09 | Best Performance So Far: balanced_accuracy - Train: 0.9437, Validation: 0.6587\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:11 | Computed configuration 7/30 in 0:00:01.563358\n",
      "25/06/2025-15:11:11 | Performance:             balanced_accuracy - Train: 0.9441, Validation: 0.6488\n",
      "25/06/2025-15:11:11 | Best Performance So Far: balanced_accuracy - Train: 0.9437, Validation: 0.6587\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:11 | Computed configuration 8/30 in 0:00:00.338763\n",
      "25/06/2025-15:11:11 | Performance:             balanced_accuracy - Train: 0.9810, Validation: 0.5243\n",
      "25/06/2025-15:11:11 | Best Performance So Far: balanced_accuracy - Train: 0.9437, Validation: 0.6587\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:11:13 | Computed configuration 10/30 in 0:00:01.598812\n",
      "25/06/2025-15:11:13 | Performance:             balanced_accuracy - Train: 0.9976, Validation: 0.5484\n",
      "25/06/2025-15:11:13 | Best Performance So Far: balanced_accuracy - Train: 0.9437, Validation: 0.6587\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002049128507720536\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:14 | Computed configuration 11/30 in 0:00:00.943970\n",
      "25/06/2025-15:11:14 | Performance:             balanced_accuracy - Train: 0.9412, Validation: 0.6678\n",
      "25/06/2025-15:11:14 | Best Performance So Far: balanced_accuracy - Train: 0.9412, Validation: 0.6678\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0014666036255122862\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:16 | Computed configuration 12/30 in 0:00:01.553772\n",
      "25/06/2025-15:11:16 | Performance:             balanced_accuracy - Train: 0.9441, Validation: 0.6488\n",
      "25/06/2025-15:11:16 | Best Performance So Far: balanced_accuracy - Train: 0.9412, Validation: 0.6678\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.008868888065564979\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:18 | Computed configuration 13/30 in 0:00:01.600233\n",
      "25/06/2025-15:11:18 | Performance:             balanced_accuracy - Train: 0.9459, Validation: 0.6690\n",
      "25/06/2025-15:11:18 | Best Performance So Far: balanced_accuracy - Train: 0.9459, Validation: 0.6690\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.2040376346369326\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:20 | Computed configuration 14/30 in 0:00:01.691636\n",
      "25/06/2025-15:11:20 | Performance:             balanced_accuracy - Train: 0.9874, Validation: 0.5370\n",
      "25/06/2025-15:11:20 | Best Performance So Far: balanced_accuracy - Train: 0.9459, Validation: 0.6690\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0070020777936015705\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:22 | Computed configuration 15/30 in 0:00:01.563584\n",
      "25/06/2025-15:11:22 | Performance:             balanced_accuracy - Train: 0.9444, Validation: 0.6704\n",
      "25/06/2025-15:11:22 | Best Performance So Far: balanced_accuracy - Train: 0.9444, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.008923295969367357\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:24 | Computed configuration 16/30 in 0:00:01.698831\n",
      "25/06/2025-15:11:24 | Performance:             balanced_accuracy - Train: 0.9459, Validation: 0.6688\n",
      "25/06/2025-15:11:24 | Best Performance So Far: balanced_accuracy - Train: 0.9444, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.017211459382919427\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:26 | Computed configuration 17/30 in 0:00:01.622783\n",
      "25/06/2025-15:11:26 | Performance:             balanced_accuracy - Train: 0.9520, Validation: 0.5534\n",
      "25/06/2025-15:11:26 | Best Performance So Far: balanced_accuracy - Train: 0.9444, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.007035479750705261\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:28 | Computed configuration 18/30 in 0:00:01.563599\n",
      "25/06/2025-15:11:28 | Performance:             balanced_accuracy - Train: 0.9444, Validation: 0.6704\n",
      "25/06/2025-15:11:28 | Best Performance So Far: balanced_accuracy - Train: 0.9444, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.009754241896645364\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:30 | Computed configuration 19/30 in 0:00:01.590002\n",
      "25/06/2025-15:11:30 | Performance:             balanced_accuracy - Train: 0.9459, Validation: 0.6688\n",
      "25/06/2025-15:11:30 | Best Performance So Far: balanced_accuracy - Train: 0.9444, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.010269191867328144\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:31 | Computed configuration 20/30 in 0:00:01.582370\n",
      "25/06/2025-15:11:31 | Performance:             balanced_accuracy - Train: 0.9459, Validation: 0.6688\n",
      "25/06/2025-15:11:31 | Best Performance So Far: balanced_accuracy - Train: 0.9444, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.011473255724587034\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:33 | Computed configuration 21/30 in 0:00:01.623105\n",
      "25/06/2025-15:11:33 | Performance:             balanced_accuracy - Train: 0.9475, Validation: 0.6175\n",
      "25/06/2025-15:11:33 | Best Performance So Far: balanced_accuracy - Train: 0.9444, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.008873938429830029\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:35 | Computed configuration 22/30 in 0:00:01.657324\n",
      "25/06/2025-15:11:35 | Performance:             balanced_accuracy - Train: 0.9459, Validation: 0.6690\n",
      "25/06/2025-15:11:35 | Best Performance So Far: balanced_accuracy - Train: 0.9444, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.00696682897280837\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:38 | Computed configuration 23/30 in 0:00:01.751103\n",
      "25/06/2025-15:11:38 | Performance:             balanced_accuracy - Train: 0.9437, Validation: 0.6587\n",
      "25/06/2025-15:11:38 | Best Performance So Far: balanced_accuracy - Train: 0.9444, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.008814550398387586\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:39 | Computed configuration 24/30 in 0:00:01.592196\n",
      "25/06/2025-15:11:39 | Performance:             balanced_accuracy - Train: 0.9459, Validation: 0.6690\n",
      "25/06/2025-15:11:39 | Best Performance So Far: balanced_accuracy - Train: 0.9444, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.008347768687168824\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:42 | Computed configuration 25/30 in 0:00:01.704946\n",
      "25/06/2025-15:11:42 | Performance:             balanced_accuracy - Train: 0.9439, Validation: 0.6586\n",
      "25/06/2025-15:11:42 | Best Performance So Far: balanced_accuracy - Train: 0.9444, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006945141147829958\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:43 | Computed configuration 26/30 in 0:00:00.981687\n",
      "25/06/2025-15:11:43 | Performance:             balanced_accuracy - Train: 0.9424, Validation: 0.6846\n",
      "25/06/2025-15:11:43 | Best Performance So Far: balanced_accuracy - Train: 0.9424, Validation: 0.6846\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006945929526529812\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:44 | Computed configuration 27/30 in 0:00:00.930135\n",
      "25/06/2025-15:11:44 | Performance:             balanced_accuracy - Train: 0.9424, Validation: 0.6846\n",
      "25/06/2025-15:11:44 | Best Performance So Far: balanced_accuracy - Train: 0.9424, Validation: 0.6846\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.00748810537885379\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:45 | Computed configuration 28/30 in 0:00:00.925616\n",
      "25/06/2025-15:11:45 | Performance:             balanced_accuracy - Train: 0.9424, Validation: 0.6846\n",
      "25/06/2025-15:11:45 | Best Performance So Far: balanced_accuracy - Train: 0.9424, Validation: 0.6846\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.01225666047704024\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:47 | Computed configuration 29/30 in 0:00:00.935998\n",
      "25/06/2025-15:11:47 | Performance:             balanced_accuracy - Train: 0.9486, Validation: 0.5567\n",
      "25/06/2025-15:11:47 | Best Performance So Far: balanced_accuracy - Train: 0.9424, Validation: 0.6846\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.008279959524280418\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:48 | Computed configuration 30/30 in 0:00:00.940209\n",
      "25/06/2025-15:11:48 | Performance:             balanced_accuracy - Train: 0.9448, Validation: 0.6855\n",
      "25/06/2025-15:11:48 | Best Performance So Far: balanced_accuracy - Train: 0.9448, Validation: 0.6855\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-15:11:48 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-15:11:48 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.008279959524280418\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9448      |      0.6855      |\n",
      "|      f1_score     |       0.9480      |      0.2614      |\n",
      "|      accuracy     |       0.9448      |      0.7749      |\n",
      "|     precision     |       0.9133      |      0.5268      |\n",
      "|    sensitivity    |       0.9878      |      0.5893      |\n",
      "|    specificity    |       0.9017      |      0.7818      |\n",
      "|        auc        |       0.9448      |      0.6855      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:11:49 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9242      |      0.5676      |\n",
      "|      f1_score     |       0.9286      |      0.1333      |\n",
      "|      accuracy     |       0.9242      |      0.9096      |\n",
      "|     precision     |       0.8768      |      0.1000      |\n",
      "|    sensitivity    |       0.9869      |      0.2000      |\n",
      "|    specificity    |       0.8614      |      0.9351      |\n",
      "|        auc        |       0.9242      |      0.5676      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:11:49 | Computations in outer fold 5 took 0.7394053833333333 minutes.\n",
      "25/06/2025-15:11:49 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Finished all outer fold computations.\n",
      "25/06/2025-15:11:52 | Now analysing the final results...\n",
      "25/06/2025-15:11:52 | Computing dummy metrics...\n",
      "25/06/2025-15:11:52 | Computing mean and std for all outer fold metrics...\n",
      "25/06/2025-15:11:52 | Find best config across outer folds...\n",
      "25/06/2025-15:11:52 | Save final results...\n",
      "25/06/2025-15:11:52 | Writing results to project folder...\n",
      "25/06/2025-15:11:55 | Prepare Hyperpipe.optimum pipe with best config..\n",
      "25/06/2025-15:11:55 | Fitting best model...\n",
      "25/06/2025-15:11:55 | Saved best model to file.\n",
      "25/06/2025-15:11:55 | Summarizing results...\n",
      "25/06/2025-15:11:55 | Write predictions to files...\n",
      "25/06/2025-15:11:55 | Write summary...\n",
      "*****************************************************************************************************\n",
      "\n",
      "ANALYSIS INFORMATION ================================================================================ \n",
      "Project Folder: ./analysis/participant2_15min\\5FinalPipelineCIFSGB_results_2025-06-25_15-07-57,\n",
      "Computation Time: 2025-06-25 15:07:57.585618 - 2025-06-25 15:11:52.144511\n",
      "Duration: 0:03:54.558893\n",
      "Optimized for: balanced_accuracy\n",
      "Hyperparameter Optimizer: sk_opt\n",
      "\n",
      "DUMMY RESULTS =======================================================================================\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.9656 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "\n",
      "AVERAGE PERFORMANCE ACROSS OUTER FOLDS ==============================================================\n",
      "+-------------------+---------------+--------------+-----------+----------+\n",
      "|    Metric Name    | Training Mean | Training Std | Test Mean | Test Std |\n",
      "+-------------------+---------------+--------------+-----------+----------+\n",
      "| balanced_accuracy |    0.921046   |   0.041009   |  0.66505  | 0.162755 |\n",
      "|      f1_score     |    0.923973   |   0.039298   |  0.252748 | 0.336592 |\n",
      "|      accuracy     |    0.921046   |   0.041009   |  0.716104 | 0.297126 |\n",
      "|     precision     |    0.896686   |   0.049955   |  0.242407 | 0.380232 |\n",
      "|    sensitivity    |    0.953723   |   0.033825   |    0.61   | 0.424735 |\n",
      "|    specificity    |    0.888369   |   0.05548    |   0.7201  | 0.317457 |\n",
      "|        auc        |    0.921046   |   0.041009   |  0.66505  | 0.162755 |\n",
      "+-------------------+---------------+--------------+-----------+----------+\n",
      "\n",
      "BEST HYPERPARAMETER CONFIGURATION ===================================================================\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006817654224626131\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "\n",
      "+--------+-------------------+----------+----------+-----------+-------------+-------------+--------+------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| fold # | balanced_accuracy | f1_score | accuracy | precision | sensitivity | specificity |  auc   |                                                                 Best Hyperparameter Config                                                                 |\n",
      "+--------+-------------------+----------+----------+-----------+-------------+-------------+--------+------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|   1    |       0.5863      |  0.0800  |  0.2014  |   0.0417  |    1.0000   |    0.1727   | 0.5863 |      {'ImbalancedDataTransformer': ['method_name=SMOTE'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.0026570059126609985']}       |\n",
      "|   2    |       0.7743      |  0.1315  |  0.5635  |   0.0704  |    1.0000   |    0.5486   | 0.7743 |  {'ImbalancedDataTransformer': ['method_name=BorderlineSMOTE'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.006166375906484462']}  |\n",
      "|   3*   |       0.9250      |  0.9189  |  0.9948  |   1.0000  |    0.8500   |    1.0000   | 0.9250 | {'ImbalancedDataTransformer': ['method_name=RandomOverSampler'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.006817654224626131']} |\n",
      "|   4    |       0.4721      |  0.0000  |  0.9113  |   0.0000  |    0.0000   |    0.9441   | 0.4721 |  {'ImbalancedDataTransformer': ['method_name=RandomOverSampler'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.4221874350041114']}  |\n",
      "|   5    |       0.5676      |  0.1333  |  0.9096  |   0.1000  |    0.2000   |    0.9351   | 0.5676 | {'ImbalancedDataTransformer': ['method_name=RandomOverSampler'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.008279959524280418']} |\n",
      "+--------+-------------------+----------+----------+-----------+-------------+-------------+--------+------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "PHOTONAI 2.5.2 ======================================================================================\n",
      "Your results are stored in ./analysis/participant2_15min\\5FinalPipelineCIFSGB_results_2025-06-25_15-07-57\n",
      "Go to https://explorer.photon-ai.com and upload your photonai_results.json for convenient result visualization! \n",
      "For more info and documentation visit https://www.photon-ai.com\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from photonai.base import Hyperpipe, PipelineElement\n",
    "from photonai.optimization import FloatRange, Categorical\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "tested_methods = Categorical(['RandomUnderSampler', 'RandomOverSampler', 'SMOTE', 'BorderlineSMOTE'])\n",
    "\n",
    "final_pipeline1 = Hyperpipe('5 - Final Pipeline CI + FS + GB',\n",
    "    outer_cv=StratifiedKFold(n_splits=5, shuffle=False),\n",
    "    inner_cv=StratifiedKFold(n_splits=3, shuffle=False),\n",
    "    use_test_set=True,\n",
    "    metrics=list(metrics.keys()),\n",
    "    best_config_metric='balanced_accuracy',\n",
    "    optimizer='sk_opt',\n",
    "    optimizer_params={'n_configurations': 30},\n",
    "    project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "    cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "\n",
    "final_pipeline1 += PipelineElement('ImbalancedDataTransformer',\n",
    "                           hyperparameters={'method_name': tested_methods})\n",
    "\n",
    "# from sklearn.feature_selection import f_classif\n",
    "\n",
    "# final_pipeline1 += PipelineElement('SelectKBest',\n",
    "#                                    hyperparameters={'k': [5, 10, 'all']},\n",
    "#                                    score_func=f_classif)\n",
    "\n",
    "\n",
    "\n",
    "final_pipeline1 += PipelineElement('GradientBoostingClassifier', \n",
    "                            hyperparameters={\n",
    "                                'loss': ['deviance', 'exponential'],\n",
    "                                'learning_rate': FloatRange(0.001, 1, 'logspace')\n",
    "                            }, random_state=4)\n",
    "\n",
    "# Fit hyperpipe\n",
    "final_pipeline1.fit(X, y)\n",
    "\n",
    "# Optionally print mean validation results\n",
    "# print(final_pipeline1.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# Optionally print feature importances\n",
    "# print_feature_importances(final_pipeline1)\n",
    "\n",
    "# Optionally debug CV splits\n",
    "# for k, v in final_pipeline1.cross_validation.outer_folds.items():\n",
    "#     print(v.train_indices)\n",
    "#     print(v.test_indices)\n",
    "#     print(len(v.train_indices), len(v.test_indices))\n",
    "#     print()\n",
    "\n",
    "# Write additional reports\n",
    "add_other_report_to_summary(final_pipeline1, with_estimator_comparison=False)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix_from_pipeline(final_pipeline1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03737f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: Built-in GradientBoosting Feature Importances\n",
      "-------------------------------------------------------\n",
      "time_from_last_drug_taken 0.8102\n",
      "light                0.0914\n",
      "heart_rate           0.0579\n",
      "awake                0.0204\n",
      "nonrem_total         0.0055\n",
      "total                0.0042\n",
      "deep                 0.0041\n",
      "sleep_efficiency     0.0032\n",
      "nonrem_percentage    0.0027\n",
      "stress_score         0.0003\n",
      "rem                  0.0000\n",
      "steps                0.0000\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative 1: Built-in Feature Importances (Fastest)\n",
    "print(\"Method 1: Built-in GradientBoosting Feature Importances\")\n",
    "print(\"-\" * 55)\n",
    "try:\n",
    "    # Get the trained estimator\n",
    "    gb_estimator = final_pipeline1.optimum_pipe.named_steps['GradientBoostingClassifier']\n",
    "    \n",
    "    if hasattr(gb_estimator, 'feature_importances_'):\n",
    "        importances = gb_estimator.feature_importances_\n",
    "        feature_names = np.array(columns[1:-1])\n",
    "        \n",
    "        # Sort by importance\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        for i, idx in enumerate(indices):\n",
    "            print(f\"{feature_names[idx]:<20} {importances[idx]:.4f}\")\n",
    "    else:\n",
    "        print(\"Built-in feature importances not available\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6de4c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 2: Sklearn Permutation Importance\n",
      "----------------------------------------\n",
      "Error: 'PhotonPipeline' object has no attribute 'classes_'\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative 2: Using sklearn's permutation_importance directly\n",
    "print(\"Method 2: Sklearn Permutation Importance\")\n",
    "print(\"-\" * 40)\n",
    "try:\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    \n",
    "    # Get the fitted pipeline\n",
    "    fitted_pipeline = final_pipeline1.optimum_pipe\n",
    "    \n",
    "    # Use a subset of data for faster computation (optional)\n",
    "    # X_sample = X.sample(n=min(1000, len(X)), random_state=42)\n",
    "    # y_sample = y.loc[X_sample.index]\n",
    "    \n",
    "    # Calculate permutation importance\n",
    "    perm_importance = permutation_importance(\n",
    "        fitted_pipeline, X, y, \n",
    "        n_repeats=10,  # Reduced for speed\n",
    "        random_state=42,\n",
    "        scoring='balanced_accuracy'\n",
    "    )\n",
    "    \n",
    "    feature_names = np.array(columns[1:-1])\n",
    "    \n",
    "    # Sort by importance\n",
    "    indices = np.argsort(perm_importance.importances_mean)[::-1]\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        print(f\"{feature_names[idx]:<20} {perm_importance.importances_mean[idx]:.4f} \"\n",
    "              f\"{perm_importance.importances_std[idx]:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f056a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 3: SHAP Feature Importance\n",
      "-----------------------------------\n",
      "Error: The passed model is not callable and cannot be analyzed directly with the given masker! Model: PhotonPipeline(elements=[('ImbalancedDataTransformer',\n",
      "                          PipelineElement(config=None,\n",
      "                                          method_name='RandomOverSampler',\n",
      "                                          name='ImbalancedDataTransformer')),\n",
      "                         ('GradientBoostingClassifier',\n",
      "                          PipelineElement(ccp_alpha=0.0,\n",
      "                                          criterion='friedman_mse', init=None,\n",
      "                                          learning_rate=0.006817654224626131,\n",
      "                                          loss='exponential', max_depth=3,\n",
      "                                          max_features=None,\n",
      "                                          max_leaf_nodes=None,\n",
      "                                          min_impurity_decrease=0.0,\n",
      "                                          min_samples_leaf=1,\n",
      "                                          min_samples_split=2,\n",
      "                                          min_weight_fraction_leaf=0.0,\n",
      "                                          n_estimators=100,\n",
      "                                          n_iter_no_change=None,\n",
      "                                          name='GradientBoostingClassifier',\n",
      "                                          random_state=4, subsample=1.0,\n",
      "                                          tol=0.0001, validation_fraction=0.1,\n",
      "                                          verbose=0, warm_start=False))])\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative 3: SHAP Values (if you have shap installed)\n",
    "print(\"Method 3: SHAP Feature Importance\")\n",
    "print(\"-\" * 35)\n",
    "try:\n",
    "    import shap\n",
    "    \n",
    "    # Get the fitted pipeline\n",
    "    fitted_pipeline = final_pipeline1.optimum_pipe\n",
    "    \n",
    "    # Use a sample for SHAP (it can be slow on large datasets)\n",
    "    X_sample = X.sample(n=min(500, len(X)), random_state=42)\n",
    "    \n",
    "    # Create explainer\n",
    "    explainer = shap.Explainer(fitted_pipeline, X_sample)\n",
    "    shap_values = explainer(X_sample)\n",
    "    \n",
    "    # Get mean absolute SHAP values as feature importance\n",
    "    feature_importance = np.abs(shap_values.values).mean(0)\n",
    "    feature_names = np.array(columns[1:-1])\n",
    "    \n",
    "    # Sort by importance\n",
    "    indices = np.argsort(feature_importance)[::-1]\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        print(f\"{feature_names[idx]:<20} {feature_importance[idx]:.4f}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"SHAP not installed. Install with: pip install shap\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bcee040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 4: DataFrame Summary\n",
      "-------------------------\n",
      "\n",
      "Computing permutation importances. This may take a while.\n",
      "*****************************************************************************************************\n",
      "Permutation Importances: Fitting model for outer fold 1\n",
      "Permutation Importances: Calculating performances for outer fold 1\n",
      "Error: 'PhotonPipeline' object has no attribute 'classes_'\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative 4: Simple DataFrame approach for better visualization\n",
    "print(\"Method 4: DataFrame Summary\")\n",
    "print(\"-\" * 25)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Using the original hyperpipe method but organizing results better\n",
    "    r = final_pipeline1.get_permutation_feature_importances(\n",
    "        n_repeats=20,  # Reduced for speed\n",
    "        random_state=0, \n",
    "        scoring='balanced_accuracy'\n",
    "    )\n",
    "    \n",
    "    # Create DataFrame for better organization\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': np.array(columns[1:-1]),\n",
    "        'Importance': r[\"mean\"],\n",
    "        'Std_Dev': r[\"std\"],\n",
    "        'Lower_Bound': r[\"mean\"] - 2 * r[\"std\"],\n",
    "        'Upper_Bound': r[\"mean\"] + 2 * r[\"std\"]\n",
    "    })\n",
    "    \n",
    "    # Sort by importance\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Display top 10\n",
    "    print(\"Top 10 Most Important Features:\")\n",
    "    print(importance_df.head(10).to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # Show only statistically significant features\n",
    "    significant_features = importance_df[importance_df['Lower_Bound'] > 0]\n",
    "    \n",
    "    if len(significant_features) > 0:\n",
    "        print(f\"\\nStatistically Significant Features ({len(significant_features)}):\")\n",
    "        print(significant_features.to_string(index=False, float_format='%.4f'))\n",
    "    else:\n",
    "        print(\"\\nNo statistically significant features found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8f40413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 5: Quick and Simple\n",
      "-------------------------\n",
      "Feature Importance Ranking:\n",
      " 1. time_from_last_drug_taken 0.8751\n",
      " 2. light                0.0489\n",
      " 3. rem                  0.0464\n",
      " 4. heart_rate           0.0211\n",
      " 5. deep                 0.0055\n",
      " 6. sleep_efficiency     0.0023\n",
      " 7. stress_score         0.0007\n",
      " 8. total                0.0000\n",
      " 9. steps                0.0000\n",
      "10. nonrem_total         0.0000\n",
      "11. nonrem_percentage    0.0000\n",
      "12. awake                0.0000\n"
     ]
    }
   ],
   "source": [
    "# Alternative 5: Quick and Simple (Minimal Code)\n",
    "print(\"Method 5: Quick and Simple\")\n",
    "print(\"-\" * 25)\n",
    "try:\n",
    "    # Just get the built-in importances with minimal code\n",
    "    estimator = final_pipeline1.optimum_pipe.named_steps['GradientBoostingClassifier']\n",
    "    importances = estimator.feature_importances_\n",
    "    features = np.array(columns[1:-1])\n",
    "    \n",
    "    # Create sorted list of (importance, feature) tuples\n",
    "    sorted_features = sorted(zip(importances, features), reverse=True)\n",
    "    \n",
    "    print(\"Feature Importance Ranking:\")\n",
    "    for i, (importance, feature) in enumerate(sorted_features[:15], 1):\n",
    "        print(f\"{i:2d}. {feature:<20} {importance:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
