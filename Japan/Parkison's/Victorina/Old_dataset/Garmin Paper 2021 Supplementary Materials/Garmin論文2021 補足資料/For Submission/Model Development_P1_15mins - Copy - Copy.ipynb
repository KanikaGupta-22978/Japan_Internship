{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'participant1'\n",
    "frequency = '15min' # 15min | 15s\n",
    "dataset_type = '' # ''\n",
    "\n",
    "if frequency == '15min':\n",
    "    record_size_per_day = 96\n",
    "elif frequency == '15s':\n",
    "    record_size_per_day = 5760\n",
    "\n",
    "# Columns to include    \n",
    "if dataset_type == '':\n",
    "    columns = [ 'timestamp', 'heart_rate', 'steps', 'stress_score',\n",
    "            'awake', 'deep', 'light', 'rem', 'nonrem_total', 'total', 'nonrem_percentage', 'sleep_efficiency',\n",
    "            'time_from_last_drug_taken', 'wearing_off' ]\n",
    "\n",
    "metrics = {\n",
    "    'balanced_accuracy': 'Bal. Acc.',\n",
    "    'f1_score': 'F1 Score',\n",
    "    'accuracy': 'Acc.',\n",
    "    'precision': 'Precision',\n",
    "    'sensitivity': 'Recall / Sn',\n",
    "    'specificity': 'Sp',\n",
    "    'auc': 'AUC'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from typing import Union, Generator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning, ConvergenceWarning\n",
    "\n",
    "import sklearn\n",
    "from photonai.base import Hyperpipe, PipelineElement, Stack, Switch\n",
    "from photonai.optimization import FloatRange, IntegerRange, Categorical, BooleanSwitch, PhotonHyperparam\n",
    "from photonai.optimization import Categorical as PhotonCategorical\n",
    "from photonai.optimization import MinimumPerformanceConstraint, DummyPerformanceConstraint, BestPerformanceConstraint\n",
    "from photonai.optimization.base_optimizer import PhotonSlaveOptimizer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tabulate import tabulate\n",
    "\n",
    "from skopt import Optimizer\n",
    "from skopt.space import Real, Integer, Dimension\n",
    "from skopt.space import Categorical as skoptCategorical\n",
    "from photonai.photonlogger.logger import logger\n",
    "from photonai.optimization.scikit_optimize.sk_opt import SkOptOptimizer\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_excel(f'./data/combined_data/{dataset_type}combined_data_{user}_{frequency}.xlsx',\n",
    "                              index_col=\"timestamp\",\n",
    "                              usecols=columns,\n",
    "                              engine='openpyxl')\n",
    "if dataset_type == '':\n",
    "    # Define prediction horizon\n",
    "    predict_ahead = pd.Timedelta(minutes=60)  # <- change to 2 or pd.Timedelta(seconds=15) as needed\n",
    "\n",
    "    # Ensure datetime index\n",
    "    combined_data = combined_data.sort_index()\n",
    "    combined_data.index = pd.to_datetime(combined_data.index)\n",
    "\n",
    "    # Estimate time delta between rows (assumes regular sampling)\n",
    "    median_step = combined_data.index.to_series().diff().median()\n",
    "\n",
    "    # How many steps to shift based on prediction horizon\n",
    "    steps_ahead = int(predict_ahead / median_step)\n",
    "\n",
    "    # Shift labels backward to align X at time t with y at t + n\n",
    "    combined_data['wearing_off_future'] = combined_data['wearing_off'].shift(-steps_ahead)\n",
    "\n",
    "    # Drop rows with NaNs from shifting\n",
    "    combined_data = combined_data.dropna(subset=['wearing_off_future'])\n",
    "\n",
    "    # Define X and y (keep X as DataFrame for .iloc to work)\n",
    "    X = combined_data.loc[:, columns[1:-1]]  # or X = combined_data[feature_cols]\n",
    "    y = combined_data['wearing_off_future'].astype(int).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Show feature importances\n",
    "def print_feature_importances(pipeline):\n",
    "    output = ''\n",
    "    if pipeline.optimum_pipe.feature_importances_ is None:\n",
    "        output = 'Best Hyperparameter Configuration is a non-linear SVM, thus feature importances cannot be retrieved'\n",
    "    else:\n",
    "        output = 'Feature Importances using the Best Hyperparameter Config'\n",
    "        if not [value.base_element.support_.tolist() for key, value in pipeline.optimum_pipe.elements if key == 'RFE']:\n",
    "            if len(pipeline.optimum_pipe.feature_importances_) == 1:\n",
    "                feature_importances = pipeline.optimum_pipe.feature_importances_[0]\n",
    "            else:\n",
    "                feature_importances = pipeline.optimum_pipe.feature_importances_\n",
    "            output += '\\n'\n",
    "            output += tabulate(\n",
    "                pd.DataFrame(\n",
    "                    [np.around(feature_importances, decimals=4)],\n",
    "                    columns=np.array(columns[1:-1])\n",
    "                ).transpose().sort_values(by=[0], ascending=False, key=abs),\n",
    "                tablefmt='psql', floatfmt=\".4f\", headers=['Features', 'Values']\n",
    "            )\n",
    "        else:\n",
    "            mask = [value.base_element.support_.tolist() for key, value in pipeline.optimum_pipe.elements if key == 'RFE'][0]\n",
    "            if len(pipeline.optimum_pipe.feature_importances_) == 1:\n",
    "                feature_importances = pipeline.optimum_pipe.feature_importances_[0]\n",
    "            else:\n",
    "                feature_importances = pipeline.optimum_pipe.feature_importances_\n",
    "            output += '\\n'\n",
    "            output += tabulate(\n",
    "                pd.DataFrame(\n",
    "                    [np.around(feature_importances, decimals=4)],\n",
    "                    columns=np.array(columns[1:-1])[mask]\n",
    "                ).transpose().sort_values(by=[0], ascending=False, key=abs),\n",
    "                tablefmt='psql', floatfmt=\".4f\", headers=['Features', 'Values']\n",
    "            )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, X, y, ax, n_splits=0, lw=20):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                    c=indices, marker='_', lw=lw, cmap=plt.cm.coolwarm,\n",
    "                    vmin=-.2, vmax=1.2)\n",
    "\n",
    "    n_splits = ii + 1\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X), c=y, marker='_', lw=lw, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['wearing-off']\n",
    "    ax.set(yticks=np.arange(n_splits+1) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Records\\'s Index', ylabel=\"Folds\",\n",
    "           ylim=[n_splits+1.2, -.2], xlim=[0, len(X)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_from_pipeline(pipeline):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    cm = confusion_matrix(\n",
    "        pipeline.results_handler.get_test_predictions()['y_true'],\n",
    "        pipeline.results_handler.get_test_predictions()['y_pred'],\n",
    "        labels=[0,1], normalize=None)\n",
    "    ax = plt.subplot()\n",
    "    sns.set(font_scale=3.0) # Adjust to fit\n",
    "    sns.heatmap(cm, annot=True, ax=ax, cmap=\"Blues\", fmt=\"g\");  \n",
    "\n",
    "    # Labels, title and ticks\n",
    "    label_font = {'size':'25'}  # Adjust to fit\n",
    "    ax.set_xlabel('Predicted labels', fontdict=label_font);\n",
    "    ax.set_ylabel('Observed labels', fontdict=label_font);\n",
    "\n",
    "    # title_font = {'size':'21'}  # Adjust to fit\n",
    "    # ax.set_title('Confusion Matrix', fontdict=title_font);\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=25)  # Adjust to fit\n",
    "    ax.xaxis.set_ticklabels(['Good', 'Wearing-Off']);\n",
    "    ax.yaxis.set_ticklabels(['Good', 'Wearing-Off']);\n",
    "    plt.rc('text') # , usetex=False)\n",
    "    plt.rc('font', family='serif')\n",
    "    # plt.savefig('./participant2-downsampling-confusionmatrix-real.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write other reports to summary file\n",
    "def add_other_report_to_summary(pipeline, with_estimator_comparison=True):\n",
    "    with open(f'{pipeline.output_settings.results_folder}/photon_summary.txt', \"a+\") as summary_file:\n",
    "        # 1. Write comparison of learning algorithms\n",
    "        if with_estimator_comparison:\n",
    "            summary_file.write(\"\\n\\n\")\n",
    "            summary_file.write(\"Comparison on learning algorithms on validation set\")\n",
    "            summary_file.write(\"\\n\")\n",
    "            summary_file.write(str(pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator()))\n",
    "\n",
    "        # 2. Write feature importance\n",
    "        summary_file.write(\"\\n\\n\")\n",
    "        summary_file.write(\"Feature Importance\")\n",
    "        summary_file.write(print_feature_importances(pipeline))\n",
    "        \n",
    "        # 3. Write beautified average test performance across outer folds\n",
    "        # a. Get Average Test Performance Across Outer Folds\n",
    "        test_metric_result = pipeline.results.get_test_metric_dict()\n",
    "        \n",
    "        # b. Replace display metric name\n",
    "        #   Reference: https://stackoverflow.com/a/55250496/2303766\n",
    "        test_metric_result = { metrics[metric]: test_metric_result[metric]\n",
    "                                  for metric, metric_name in metrics.items() if metric in test_metric_result\n",
    "                             }\n",
    "        \n",
    "        # c. Add beautified average test performance across outer folds to file \n",
    "        summary_file.write(\"\\n\\n\")\n",
    "        summary_file.write(\"Average Test Performance Across Outer Folds\")\n",
    "        summary_file.write(\"\\n\")\n",
    "        summary_file.write(\n",
    "            tabulate(\n",
    "                pd.DataFrame(\n",
    "                    test_metric_result\n",
    "                ).round(4).transpose(),\n",
    "                tablefmt='psql', floatfmt=\".4f\", headers='keys'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 4. Write outer fold results\n",
    "        summary_file.write(\"\\n\\n\")\n",
    "        summary_file.write(\"Outer Fold Best Estimators' Performance\")\n",
    "        summary_file.write(\"\\n\")\n",
    "        handler = pipeline.results_handler\n",
    "        performance_table = handler.get_performance_table()\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "            summary_file.write(\n",
    "                tabulate(\n",
    "                    performance_table.loc[:, ['fold', 'best_config', 'n_train', 'n_validation']].transpose(),\n",
    "                    tablefmt='psql', headers='keys'\n",
    "                )\n",
    "            )\n",
    "            summary_file.write(\"\\n\")\n",
    "            summary_file.write(\n",
    "                tabulate(\n",
    "                    performance_table.loc[:, ['fold'] + list(metrics.keys())].round(4).transpose(),\n",
    "                    tablefmt='psql', floatfmt=\".4f\", headers='keys'\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        outer_fold_performance = {}\n",
    "        config_evals = handler.get_config_evaluations()\n",
    "        for metric in metrics.keys():\n",
    "            # print(f'{metric}')\n",
    "            for i, j in enumerate(config_evals[metric]):\n",
    "                if f'{metric}_mean' in outer_fold_performance:\n",
    "                    # outer_fold_performance[f'{metric}_max'].append(np.max(j))\n",
    "                    outer_fold_performance[f'{metric}_mean'].append(np.mean(j))\n",
    "                    outer_fold_performance[f'{metric}_std'].append(np.std(j))\n",
    "                else:\n",
    "                    # outer_fold_performance[f'{metric}_max'] = [np.max(j)]\n",
    "                    outer_fold_performance[f'{metric}_mean'] = [np.mean(j)]\n",
    "                    outer_fold_performance[f'{metric}_std'] = [np.std(j)]\n",
    "        summary_file.write(\"\\n\")\n",
    "        summary_file.write(\n",
    "            tabulate(\n",
    "                pd.DataFrame(outer_fold_performance).round(4).transpose(),\n",
    "                tablefmt='psql', floatfmt=\".4f\", headers='keys'\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhotonAI Optimize Monkey-patch\n",
    "#     Added random_state for Optimize for result replicability\n",
    "def prepare(self, pipeline_elements: list, maximize_metric: bool) -> None:\n",
    "    \"\"\"\n",
    "    Initializes hyperparameter search with scikit-optimize.\n",
    "\n",
    "    Assembles all hyperparameters of the list of PipelineElements\n",
    "    in order to prepare the hyperparameter space.\n",
    "    Hyperparameters can be accessed via pipe_element.hyperparameters.\n",
    "\n",
    "    Parameters:\n",
    "        pipeline_elements:\n",
    "            List of all PipelineElements to create the hyperparameter space.\n",
    "\n",
    "        maximize_metric:\n",
    "            Boolean to distinguish between score and error.\n",
    "\n",
    "    \"\"\"\n",
    "    self.start_time = None\n",
    "    self.optimizer = None\n",
    "    self.hyperparameter_list = []\n",
    "    self.maximize_metric = maximize_metric\n",
    "\n",
    "    # build skopt space\n",
    "    space = []\n",
    "    for pipe_element in pipeline_elements:\n",
    "        if pipe_element.__class__.__name__ == 'Switch':\n",
    "            error_msg = 'Scikit-Optimize cannot operate in the specified hyperparameter space with a Switch ' \\\n",
    "                        'element. We recommend the use of SMAC.'\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if hasattr(pipe_element, 'hyperparameters'):\n",
    "            for name, value in pipe_element.hyperparameters.items():\n",
    "                # if we only have one value we do not need to optimize\n",
    "                if isinstance(value, list) and len(value) < 2:\n",
    "                    self.constant_dictionary[name] = value[0]\n",
    "                    continue\n",
    "                if isinstance(value, PhotonCategorical) and len(value.values) < 2:\n",
    "                    self.constant_dictionary[name] = value.values[0]\n",
    "                    continue\n",
    "                skopt_param = self._convert_photonai_to_skopt_space(value, name)\n",
    "                if skopt_param is not None:\n",
    "                    space.append(skopt_param)\n",
    "\n",
    "    if self.constant_dictionary:\n",
    "        msg = \"PHOTONAI has detected some one-valued params in your hyperparameters. Pleas use the kwargs for \" \\\n",
    "              \"constant values. This run ignores following settings: \" + str(self.constant_dictionary.keys())\n",
    "        logger.warning(msg)\n",
    "        warnings.warn(msg)\n",
    "\n",
    "    if len(space) == 0:\n",
    "        msg = \"Did not find any hyperparameter to convert into skopt space.\"\n",
    "        logger.warning(msg)\n",
    "        warnings.warn(msg)\n",
    "    else:\n",
    "        self.optimizer = Optimizer(space,\n",
    "                                   base_estimator=self.base_estimator,\n",
    "                                   n_initial_points=self.n_initial_points,\n",
    "                                   initial_point_generator=self.initial_point_generator,\n",
    "                                   acq_func=self.acq_func,\n",
    "                                   acq_func_kwargs=self.acq_func_kwargs,\n",
    "                                   random_state=4\n",
    "                                  )\n",
    "    self.ask = self.ask_generator()\n",
    "    \n",
    "#    Monkey patched new prepare function\n",
    "SkOptOptimizer.prepare = prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set for Outer Fold 0\n",
      "[ 479  484  485 ... 2873 2874 2875]\n",
      "\n",
      "Train Set for Outer Fold 1\n",
      "[   0    1    2 ... 2873 2874 2875]\n",
      "\n",
      "Train Set for Outer Fold 2\n",
      "[   0    1    2 ... 2873 2874 2875]\n",
      "\n",
      "Train Set for Outer Fold 3\n",
      "[   0    1    2 ... 2873 2874 2875]\n",
      "\n",
      "Train Set for Outer Fold 4\n",
      "[   0    1    2 ... 2319 2343 2344]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Outer CV\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "plot_cv_indices(cv, X, y, ax)\n",
    "plt.rc('text') # , usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "plt.title('Outer Folds')\n",
    "# Save as file\n",
    "# plt.savefig('./blockingtimeseriessplit.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "training_folds = []\n",
    "for train, test in cv.split(X, y):\n",
    "    print(f'Train Set for Outer Fold {len(training_folds)}')\n",
    "    print(train)\n",
    "    training_folds.append(train)\n",
    "    # print(\"Test\")\n",
    "    # print(test[0], test[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sets for Outer Fold 0\n",
      "Train Set for Inner Fold 0\n",
      "[ 661  667  668 ... 2297 2298 2299]\n",
      "\n",
      "Train Set for Inner Fold 1\n",
      "[   0    1    2 ... 2297 2298 2299]\n",
      "\n",
      "Train Set for Inner Fold 2\n",
      "[   0    1    2 ... 1561 1571 1575]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inner CV\n",
    "outer_fold_number = 0\n",
    "\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "plot_cv_indices(cv, X.iloc[training_folds[outer_fold_number]], y[training_folds[outer_fold_number]], ax)\n",
    "plt.rc('text') # , usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "plt.title(f'Inner Fold for Outer Fold {outer_fold_number}')\n",
    "# Save as file\n",
    "# plt.savefig('./blockingtimeseriessplit.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "inner_training_folds = []\n",
    "print(f'Train Sets for Outer Fold {outer_fold_number}')\n",
    "for train, test in cv.split(X.iloc[training_folds[outer_fold_number]], y[training_folds[outer_fold_number]]):\n",
    "    print(f'Train Set for Inner Fold {len(inner_training_folds)}')\n",
    "    print(train)\n",
    "    inner_training_folds.append(train)\n",
    "    # print(\"Test\")\n",
    "    # print(test[0], test[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photonai import PipelineElement, Switch\n",
    "from photonai.optimization import IntegerRange, FloatRange\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "estimator_selection = Switch('estimators')\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"LogisticRegression\",\n",
    "    base_element=LogisticRegression(class_weight='balanced', random_state=4),\n",
    "    hyperparameters={\n",
    "        'C': FloatRange(1, 10)\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"DecisionTreeClassifier\",\n",
    "    base_element=DecisionTreeClassifier(random_state=4, criterion='gini'),\n",
    "    hyperparameters={\n",
    "        'min_samples_split': IntegerRange(2, 30),\n",
    "        'min_samples_leaf': IntegerRange(2, 30)\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"LinearSVC\",\n",
    "    base_element=LinearSVC(class_weight='balanced', random_state=4),\n",
    "    hyperparameters={\n",
    "        'C': FloatRange(1, 25)\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"RandomForestClassifier\",\n",
    "    base_element=RandomForestClassifier(random_state=4, criterion='gini', bootstrap=True),\n",
    "    hyperparameters={\n",
    "        'min_samples_split': IntegerRange(2, 30),\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"GradientBoostingClassifier\",\n",
    "    base_element=GradientBoostingClassifier(random_state=4),\n",
    "    hyperparameters={\n",
    "        'loss': ['log_loss', 'exponential'],\n",
    "        'learning_rate': FloatRange(0.001, 1, 'logspace')\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add LGBMClassifier\n",
    "estimator_selection += PipelineElement(\n",
    "    \"LGBMClassifier\",\n",
    "    base_element=LGBMClassifier(random_state=4),\n",
    "    hyperparameters={\n",
    "        \"n_estimators\": IntegerRange(50, 150, step=10, range_type=\"range\"),\n",
    "        \"learning_rate\": FloatRange(0.01, 0.3, range_type=\"logspace\"),\n",
    "        \"max_depth\": IntegerRange(3, 10, step=1, range_type=\"range\")\n",
    "    }\n",
    ")\n",
    "# estimator_selection += PipelineElement(\n",
    "#     \"LGBMClassifier\",\n",
    "#     base_element=LGBMClassifier(random_state=4),\n",
    "#     hyperparameters={\n",
    "#         \"n_estimators\": IntegerRange(50, 150, step=10, range_type=\"range\"),\n",
    "#         \"learning_rate\": FloatRange(0.01, 0.3, range_type=\"logspace\"),\n",
    "#         \"max_depth\": IntegerRange(3, 10, step=1, range_type=\"range\")\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     16,
     20,
     25,
     29
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initial_pipeline = Hyperpipe('1 - Initial Pipeline',\n",
    "#                      outer_cv = StratifiedKFold(n_splits=5, shuffle=False),\n",
    "#                      inner_cv = StratifiedKFold(n_splits=3, shuffle=False),\n",
    "#                      use_test_set = False,\n",
    "#                      metrics = list(metrics.keys()),\n",
    "#                      best_config_metric='balanced_accuracy',\n",
    "#                      optimizer='switch',\n",
    "#                      optimizer_params={'name': 'sk_opt', 'n_configurations': 30},\n",
    "#                      project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "#                      cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "#                      verbosity=1,\n",
    "#                      performance_constraints=[MinimumPerformanceConstraint('balanced_accuracy', 0.75, 'mean')])\n",
    "\n",
    "# # Add learning algorithms to compare\n",
    "# initial_pipeline += estimator_selection\n",
    "\n",
    "# # Fit hyperpipe\n",
    "# initial_pipeline.fit(X, y)\n",
    "\n",
    "# # Show learning algorithms mean validation results\n",
    "# # print(\"Comparison on learning algorithms on validation set\")\n",
    "# # print(initial_pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# # # Show feature importances\n",
    "# # print_feature_importances(initial_pipeline)\n",
    "\n",
    "# # # View CV splits for debugging\n",
    "# # for k,v in initial_pipeline.cross_validation.outer_folds.items():\n",
    "# #     print(v.train_indices)\n",
    "# #     print(v.test_indices)\n",
    "# #     print(len(v.train_indices), len(v.test_indices))\n",
    "# #     print()\n",
    "\n",
    "# # Write other reports to summary file\n",
    "# add_other_report_to_summary(initial_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classifier = LogisticRegression(random_state=4).fit(X, y)\n",
    "\n",
    "# feature_selection_pipeline = Hyperpipe('2 - Feature Selection Pipline',\n",
    "#                      outer_cv = StratifiedKFold(n_splits=5, shuffle=False),\n",
    "#                      inner_cv = StratifiedKFold(n_splits=3, shuffle=False),\n",
    "#                      use_test_set = False,\n",
    "#                      metrics = list(metrics.keys()),\n",
    "#                      best_config_metric='balanced_accuracy',\n",
    "#                      optimizer='switch',\n",
    "#                      optimizer_params={'name': 'sk_opt', 'n_configurations': 30},\n",
    "#                      project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "#                      cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "#                      verbosity=1,\n",
    "#                      performance_constraints=[MinimumPerformanceConstraint('balanced_accuracy', 0.75, 'mean')])\n",
    "\n",
    "# feature_selection_pipeline += PipelineElement('RFE', \n",
    "#                            hyperparameters={\n",
    "#                                'n_features_to_select': IntegerRange(2, (len(columns) - 2))\n",
    "#                            }, estimator=classifier)\n",
    "\n",
    "# feature_selection_pipeline += estimator_selection\n",
    "\n",
    "# # Fit hyperpipe\n",
    "# feature_selection_pipeline.fit(X, y)\n",
    "\n",
    "# # Show learning algorithms mean validation results\n",
    "# # print(\"Comparison on learning algorithms on validation set\")\n",
    "# # print(feature_selection_pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# # # Show feature importances\n",
    "# # print_feature_importances(feature_selection_pipeline)\n",
    "\n",
    "# # # View CV splits for debugging\n",
    "# # for k,v in feature_selection_pipeline.cross_validation.outer_folds.items():\n",
    "# #     print(v.train_indices)\n",
    "# #     print(v.test_indices)\n",
    "# #     print(len(v.train_indices), len(v.test_indices))\n",
    "# #     print()\n",
    "\n",
    "# # Write other reports to summary file\n",
    "# add_other_report_to_summary(feature_selection_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalanced Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_imbalanced_pipeline = Hyperpipe('3 - Class Imbalanced Pipline',\n",
    "#                      outer_cv = StratifiedKFold(n_splits=5, shuffle=False),\n",
    "#                      inner_cv = StratifiedKFold(n_splits=3, shuffle=False),\n",
    "#                      use_test_set = False,\n",
    "#                      metrics = list(metrics.keys()),\n",
    "#                      best_config_metric='balanced_accuracy',\n",
    "#                      optimizer='switch',\n",
    "#                      optimizer_params={'name': 'sk_opt', 'n_configurations': 30},\n",
    "#                      project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "#                      cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "#                      verbosity=1,\n",
    "#                      performance_constraints=[MinimumPerformanceConstraint('balanced_accuracy', 0.75, 'mean')])\n",
    "\n",
    "# tested_methods = Categorical(['RandomUnderSampler', 'RandomOverSampler', 'SMOTE', 'BorderlineSMOTE'])\n",
    "# class_imbalanced_pipeline += PipelineElement('ImbalancedDataTransformer',\n",
    "#                            hyperparameters={ 'method_name': tested_methods })\n",
    "\n",
    "# class_imbalanced_pipeline += estimator_selection\n",
    "\n",
    "# # Fit hyperpipe\n",
    "# class_imbalanced_pipeline.fit(X, y)\n",
    "\n",
    "# # Show learning algorithms mean validation results\n",
    "# # print(\"Comparison on learning algorithms on validation set\")\n",
    "# # print(class_imbalanced_pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# # # Show feature importances\n",
    "# # print_feature_importances(class_imbalanced_pipeline)\n",
    "\n",
    "# # # View CV splits for debugging\n",
    "# # for k,v in class_imbalanced_pipeline.cross_validation.outer_folds.items():\n",
    "# #     print(v.train_indices)\n",
    "# #     print(v.test_indices)\n",
    "# #     print(len(v.train_indices), len(v.test_indices))\n",
    "# #     print()\n",
    "\n",
    "# # Write other reports to summary file\n",
    "# add_other_report_to_summary(class_imbalanced_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalanced + Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = LogisticRegression(random_state=4).fit(X, y)\n",
    "\n",
    "# class_imbalanced_feature_selection_pipeline = Hyperpipe('4 - CI and FS Pipeline',\n",
    "#                      outer_cv = StratifiedKFold(n_splits=5, shuffle=False),\n",
    "#                      inner_cv = StratifiedKFold(n_splits=3, shuffle=False),\n",
    "#                      use_test_set = False,\n",
    "#                      metrics = list(metrics.keys()),\n",
    "#                      best_config_metric='balanced_accuracy',\n",
    "#                      optimizer='switch',\n",
    "#                      optimizer_params={'name': 'sk_opt', 'n_configurations': 30},\n",
    "#                      project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "#                      cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "#                      verbosity=1,\n",
    "#                      performance_constraints=[MinimumPerformanceConstraint('balanced_accuracy', 0.75, 'mean')])\n",
    "\n",
    "\n",
    "# tested_methods = Categorical(['RandomUnderSampler', 'RandomOverSampler', 'SMOTE', 'BorderlineSMOTE'])\n",
    "# class_imbalanced_feature_selection_pipeline += PipelineElement('ImbalancedDataTransformer',\n",
    "#                            hyperparameters={ 'method_name': tested_methods })\n",
    "\n",
    "# class_imbalanced_feature_selection_pipeline += PipelineElement('RFE', \n",
    "#                            hyperparameters={\n",
    "#                                'n_features_to_select': IntegerRange(2, (len(columns) - 2))\n",
    "#                            }, estimator=classifier)\n",
    "\n",
    "# class_imbalanced_feature_selection_pipeline += estimator_selection\n",
    "\n",
    "# # Fit hyperpipe\n",
    "# class_imbalanced_feature_selection_pipeline.fit(X, y)\n",
    "\n",
    "# # Show learning algorithms mean validation results\n",
    "# # print(\"Comparison on learning algorithms on validation set\")\n",
    "# # print(class_imbalanced_feature_selection_pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# # # Show feature importances\n",
    "# # print_feature_importances(class_imbalanced_feature_selection_pipeline)\n",
    "\n",
    "# # # View CV splits for debugging\n",
    "# # for k,v in class_imbalanced_feature_selection_pipeline.cross_validation.outer_folds.items():\n",
    "# #     print(v.train_indices)\n",
    "# #     print(v.test_indices)\n",
    "# #     print(len(v.train_indices), len(v.test_indices))\n",
    "# #     print()\n",
    "\n",
    "# # Write other reports to summary file\n",
    "# add_other_report_to_summary(class_imbalanced_feature_selection_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS and CI, GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-14:59:05 | Output Folder: ./analysis/participant1_15min\\5FinalPipelineCIFSGB_results_2025-06-25_14-59-05\n",
      "=====================================================================================================\n",
      "PHOTONAI ANALYSIS: 5FinalPipelineCIFSGB\n",
      "=====================================================================================================\n",
      "25/06/2025-14:59:05 | Preparing data and PHOTONAI objects for analysis...\n",
      "25/06/2025-14:59:05 | Checking input data...\n",
      "25/06/2025-14:59:05 | Running analysis with 2876 samples.\n",
      "Found 2 target classes: [0 1]\n",
      "25/06/2025-14:59:05 | Removing cache files...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 1\n",
      "*****************************************************************************************************\n",
      "25/06/2025-14:59:05 | Preparing data for outer fold 1...\n",
      "25/06/2025-14:59:05 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-14:59:05 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.5052 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-14:59:06 | Computed configuration 2/30 in 0:00:00.969646\n",
      "25/06/2025-14:59:06 | Performance:             balanced_accuracy - Train: 0.6700, Validation: 0.5201\n",
      "25/06/2025-14:59:06 | Best Performance So Far: balanced_accuracy - Train: 0.6700, Validation: 0.5201\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:07 | Computed configuration 3/30 in 0:00:00.977667\n",
      "25/06/2025-14:59:07 | Performance:             balanced_accuracy - Train: 0.9429, Validation: 0.5079\n",
      "25/06/2025-14:59:07 | Best Performance So Far: balanced_accuracy - Train: 0.6700, Validation: 0.5201\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-14:59:08 | Computed configuration 5/30 in 0:00:00.960075\n",
      "25/06/2025-14:59:08 | Performance:             balanced_accuracy - Train: 0.7257, Validation: 0.5082\n",
      "25/06/2025-14:59:08 | Best Performance So Far: balanced_accuracy - Train: 0.6700, Validation: 0.5201\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:09 | Computed configuration 6/30 in 0:00:01.038774\n",
      "25/06/2025-14:59:09 | Performance:             balanced_accuracy - Train: 0.6844, Validation: 0.5172\n",
      "25/06/2025-14:59:09 | Best Performance So Far: balanced_accuracy - Train: 0.6700, Validation: 0.5201\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:10 | Computed configuration 7/30 in 0:00:00.920359\n",
      "25/06/2025-14:59:10 | Performance:             balanced_accuracy - Train: 0.6594, Validation: 0.5053\n",
      "25/06/2025-14:59:10 | Best Performance So Far: balanced_accuracy - Train: 0.6700, Validation: 0.5201\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:11 | Computed configuration 8/30 in 0:00:00.905627\n",
      "25/06/2025-14:59:11 | Performance:             balanced_accuracy - Train: 0.7434, Validation: 0.5122\n",
      "25/06/2025-14:59:11 | Best Performance So Far: balanced_accuracy - Train: 0.6700, Validation: 0.5201\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-14:59:12 | Computed configuration 10/30 in 0:00:00.917080\n",
      "25/06/2025-14:59:12 | Performance:             balanced_accuracy - Train: 0.9462, Validation: 0.5136\n",
      "25/06/2025-14:59:12 | Best Performance So Far: balanced_accuracy - Train: 0.6700, Validation: 0.5201\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002049128507720536\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:13 | Computed configuration 11/30 in 0:00:00.868538\n",
      "25/06/2025-14:59:13 | Performance:             balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "25/06/2025-14:59:13 | Best Performance So Far: balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0014666036255122862\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:14 | Computed configuration 12/30 in 0:00:00.905177\n",
      "25/06/2025-14:59:14 | Performance:             balanced_accuracy - Train: 0.6590, Validation: 0.5053\n",
      "25/06/2025-14:59:14 | Best Performance So Far: balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.004054905901580846\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:16 | Computed configuration 13/30 in 0:00:00.837795\n",
      "25/06/2025-14:59:16 | Performance:             balanced_accuracy - Train: 0.6812, Validation: 0.5186\n",
      "25/06/2025-14:59:16 | Best Performance So Far: balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.011808030860015228\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:17 | Computed configuration 14/30 in 0:00:00.779841\n",
      "25/06/2025-14:59:17 | Performance:             balanced_accuracy - Train: 0.7167, Validation: 0.5135\n",
      "25/06/2025-14:59:17 | Best Performance So Far: balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.8456238984393614\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:18 | Computed configuration 15/30 in 0:00:00.775387\n",
      "25/06/2025-14:59:18 | Performance:             balanced_accuracy - Train: 0.9705, Validation: 0.5144\n",
      "25/06/2025-14:59:18 | Best Performance So Far: balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0020039562505481177\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:19 | Computed configuration 16/30 in 0:00:00.802603\n",
      "25/06/2025-14:59:19 | Performance:             balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "25/06/2025-14:59:19 | Best Performance So Far: balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0016074520347421448\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:20 | Computed configuration 17/30 in 0:00:00.849808\n",
      "25/06/2025-14:59:20 | Performance:             balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "25/06/2025-14:59:20 | Best Performance So Far: balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002286005199655906\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:21 | Computed configuration 18/30 in 0:00:00.857325\n",
      "25/06/2025-14:59:21 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5298\n",
      "25/06/2025-14:59:21 | Best Performance So Far: balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0020373032198916863\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:22 | Computed configuration 19/30 in 0:00:00.830637\n",
      "25/06/2025-14:59:22 | Performance:             balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "25/06/2025-14:59:22 | Best Performance So Far: balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0012931968441213507\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:24 | Computed configuration 20/30 in 0:00:00.821900\n",
      "25/06/2025-14:59:24 | Performance:             balanced_accuracy - Train: 0.6599, Validation: 0.5298\n",
      "25/06/2025-14:59:24 | Best Performance So Far: balanced_accuracy - Train: 0.6599, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0014624932851492398\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:25 | Computed configuration 21/30 in 0:00:00.848800\n",
      "25/06/2025-14:59:25 | Performance:             balanced_accuracy - Train: 0.6599, Validation: 0.5298\n",
      "25/06/2025-14:59:25 | Best Performance So Far: balanced_accuracy - Train: 0.6599, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0016678948756302732\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:26 | Computed configuration 22/30 in 0:00:00.869070\n",
      "25/06/2025-14:59:26 | Performance:             balanced_accuracy - Train: 0.6624, Validation: 0.5298\n",
      "25/06/2025-14:59:26 | Best Performance So Far: balanced_accuracy - Train: 0.6599, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0014057416157334517\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:27 | Computed configuration 23/30 in 0:00:00.868889\n",
      "25/06/2025-14:59:27 | Performance:             balanced_accuracy - Train: 0.6599, Validation: 0.5298\n",
      "25/06/2025-14:59:27 | Best Performance So Far: balanced_accuracy - Train: 0.6599, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.00285244292600746\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:29 | Computed configuration 24/30 in 0:00:00.856000\n",
      "25/06/2025-14:59:29 | Performance:             balanced_accuracy - Train: 0.6695, Validation: 0.5293\n",
      "25/06/2025-14:59:29 | Best Performance So Far: balanced_accuracy - Train: 0.6599, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0055126769309422965\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:30 | Computed configuration 25/30 in 0:00:00.839565\n",
      "25/06/2025-14:59:30 | Performance:             balanced_accuracy - Train: 0.6852, Validation: 0.5251\n",
      "25/06/2025-14:59:30 | Best Performance So Far: balanced_accuracy - Train: 0.6599, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.007921059917382916\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:31 | Computed configuration 26/30 in 0:00:00.790545\n",
      "25/06/2025-14:59:31 | Performance:             balanced_accuracy - Train: 0.6921, Validation: 0.5232\n",
      "25/06/2025-14:59:31 | Best Performance So Far: balanced_accuracy - Train: 0.6599, Validation: 0.5298\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0015374940517896831\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:32 | Computed configuration 27/30 in 0:00:00.847097\n",
      "25/06/2025-14:59:32 | Performance:             balanced_accuracy - Train: 0.6624, Validation: 0.5307\n",
      "25/06/2025-14:59:32 | Best Performance So Far: balanced_accuracy - Train: 0.6624, Validation: 0.5307\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.02621675927570768\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:33 | Computed configuration 28/30 in 0:00:00.806683\n",
      "25/06/2025-14:59:33 | Performance:             balanced_accuracy - Train: 0.7476, Validation: 0.5162\n",
      "25/06/2025-14:59:33 | Best Performance So Far: balanced_accuracy - Train: 0.6624, Validation: 0.5307\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0015274044909071877\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:34 | Computed configuration 29/30 in 0:00:00.771940\n",
      "25/06/2025-14:59:34 | Performance:             balanced_accuracy - Train: 0.6624, Validation: 0.5307\n",
      "25/06/2025-14:59:34 | Best Performance So Far: balanced_accuracy - Train: 0.6624, Validation: 0.5307\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0015261214836403154\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:36 | Computed configuration 30/30 in 0:00:00.841918\n",
      "25/06/2025-14:59:36 | Performance:             balanced_accuracy - Train: 0.6624, Validation: 0.5307\n",
      "25/06/2025-14:59:36 | Best Performance So Far: balanced_accuracy - Train: 0.6624, Validation: 0.5307\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-14:59:36 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-14:59:36 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0015374940517896831\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.6624      |      0.5307      |\n",
      "|      f1_score     |       0.6565      |      0.5332      |\n",
      "|      accuracy     |       0.6624      |      0.5304      |\n",
      "|     precision     |       0.6693      |      0.5202      |\n",
      "|    sensitivity    |       0.6924      |      0.5484      |\n",
      "|    specificity    |       0.6325      |      0.5129      |\n",
      "|        auc        |       0.6624      |      0.5307      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-14:59:36 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.6747      |      0.5793      |\n",
      "|      f1_score     |       0.6786      |      0.6173      |\n",
      "|      accuracy     |       0.6747      |      0.5781      |\n",
      "|     precision     |       0.6706      |      0.5600      |\n",
      "|    sensitivity    |       0.6867      |      0.6877      |\n",
      "|    specificity    |       0.6627      |      0.4708      |\n",
      "|        auc        |       0.6747      |      0.5793      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-14:59:36 | Computations in outer fold 1 took 0.5220397166666666 minutes.\n",
      "25/06/2025-14:59:36 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 2\n",
      "*****************************************************************************************************\n",
      "25/06/2025-14:59:37 | Preparing data for outer fold 2...\n",
      "25/06/2025-14:59:37 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-14:59:37 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.5043 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-14:59:38 | Computed configuration 2/30 in 0:00:00.839924\n",
      "25/06/2025-14:59:38 | Performance:             balanced_accuracy - Train: 0.6840, Validation: 0.4891\n",
      "25/06/2025-14:59:38 | Best Performance So Far: balanced_accuracy - Train: 0.6840, Validation: 0.4891\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:39 | Computed configuration 3/30 in 0:00:00.840301\n",
      "25/06/2025-14:59:39 | Performance:             balanced_accuracy - Train: 0.9457, Validation: 0.5212\n",
      "25/06/2025-14:59:39 | Best Performance So Far: balanced_accuracy - Train: 0.9457, Validation: 0.5212\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-14:59:39 | Computed configuration 5/30 in 0:00:00.798529\n",
      "25/06/2025-14:59:39 | Performance:             balanced_accuracy - Train: 0.7240, Validation: 0.4830\n",
      "25/06/2025-14:59:39 | Best Performance So Far: balanced_accuracy - Train: 0.9457, Validation: 0.5212\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:40 | Computed configuration 6/30 in 0:00:00.897138\n",
      "25/06/2025-14:59:40 | Performance:             balanced_accuracy - Train: 0.7044, Validation: 0.4810\n",
      "25/06/2025-14:59:40 | Best Performance So Far: balanced_accuracy - Train: 0.9457, Validation: 0.5212\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:41 | Computed configuration 7/30 in 0:00:00.888729\n",
      "25/06/2025-14:59:41 | Performance:             balanced_accuracy - Train: 0.6558, Validation: 0.4978\n",
      "25/06/2025-14:59:41 | Best Performance So Far: balanced_accuracy - Train: 0.9457, Validation: 0.5212\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:42 | Computed configuration 8/30 in 0:00:00.828015\n",
      "25/06/2025-14:59:42 | Performance:             balanced_accuracy - Train: 0.7315, Validation: 0.4764\n",
      "25/06/2025-14:59:42 | Best Performance So Far: balanced_accuracy - Train: 0.9457, Validation: 0.5212\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-14:59:43 | Computed configuration 10/30 in 0:00:00.888191\n",
      "25/06/2025-14:59:43 | Performance:             balanced_accuracy - Train: 0.9506, Validation: 0.5325\n",
      "25/06/2025-14:59:43 | Best Performance So Far: balanced_accuracy - Train: 0.9506, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0844064265033311\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:44 | Computed configuration 11/30 in 0:00:00.899851\n",
      "25/06/2025-14:59:44 | Performance:             balanced_accuracy - Train: 0.8080, Validation: 0.5167\n",
      "25/06/2025-14:59:44 | Best Performance So Far: balanced_accuracy - Train: 0.9506, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.7017687264592064\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:45 | Computed configuration 12/30 in 0:00:00.907890\n",
      "25/06/2025-14:59:45 | Performance:             balanced_accuracy - Train: 0.9651, Validation: 0.5251\n",
      "25/06/2025-14:59:45 | Best Performance So Far: balanced_accuracy - Train: 0.9506, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5800620450735331\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:47 | Computed configuration 13/30 in 0:00:00.904596\n",
      "25/06/2025-14:59:47 | Performance:             balanced_accuracy - Train: 0.9503, Validation: 0.5186\n",
      "25/06/2025-14:59:47 | Best Performance So Far: balanced_accuracy - Train: 0.9506, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.36181102191958425\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:48 | Computed configuration 14/30 in 0:00:00.996427\n",
      "25/06/2025-14:59:48 | Performance:             balanced_accuracy - Train: 0.9157, Validation: 0.5104\n",
      "25/06/2025-14:59:48 | Best Performance So Far: balanced_accuracy - Train: 0.9506, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.2618605035802663\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:49 | Computed configuration 15/30 in 0:00:00.910511\n",
      "25/06/2025-14:59:49 | Performance:             balanced_accuracy - Train: 0.8919, Validation: 0.5088\n",
      "25/06/2025-14:59:49 | Best Performance So Far: balanced_accuracy - Train: 0.9506, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.47845648066927804\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:51 | Computed configuration 16/30 in 0:00:00.916857\n",
      "25/06/2025-14:59:51 | Performance:             balanced_accuracy - Train: 0.9377, Validation: 0.5182\n",
      "25/06/2025-14:59:51 | Best Performance So Far: balanced_accuracy - Train: 0.9506, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.1978890401905591\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:52 | Computed configuration 17/30 in 0:00:00.918292\n",
      "25/06/2025-14:59:52 | Performance:             balanced_accuracy - Train: 0.8654, Validation: 0.5309\n",
      "25/06/2025-14:59:52 | Best Performance So Far: balanced_accuracy - Train: 0.9506, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.19798146167149316\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:53 | Computed configuration 18/30 in 0:00:00.918423\n",
      "25/06/2025-14:59:53 | Performance:             balanced_accuracy - Train: 0.8622, Validation: 0.5331\n",
      "25/06/2025-14:59:53 | Best Performance So Far: balanced_accuracy - Train: 0.8622, Validation: 0.5331\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.08570283974070826\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:54 | Computed configuration 19/30 in 0:00:00.932207\n",
      "25/06/2025-14:59:54 | Performance:             balanced_accuracy - Train: 0.8042, Validation: 0.5103\n",
      "25/06/2025-14:59:54 | Best Performance So Far: balanced_accuracy - Train: 0.8622, Validation: 0.5331\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.07721745743052731\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:56 | Computed configuration 20/30 in 0:00:00.908792\n",
      "25/06/2025-14:59:56 | Performance:             balanced_accuracy - Train: 0.7898, Validation: 0.5098\n",
      "25/06/2025-14:59:56 | Best Performance So Far: balanced_accuracy - Train: 0.8622, Validation: 0.5331\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.19818449649320766\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:57 | Computed configuration 21/30 in 0:00:00.910605\n",
      "25/06/2025-14:59:57 | Performance:             balanced_accuracy - Train: 0.8669, Validation: 0.5248\n",
      "25/06/2025-14:59:57 | Best Performance So Far: balanced_accuracy - Train: 0.8622, Validation: 0.5331\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.14473865756421053\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-14:59:58 | Computed configuration 22/30 in 0:00:00.925910\n",
      "25/06/2025-14:59:58 | Performance:             balanced_accuracy - Train: 0.8431, Validation: 0.5178\n",
      "25/06/2025-14:59:58 | Best Performance So Far: balanced_accuracy - Train: 0.8622, Validation: 0.5331\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.1981065809542917\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:00 | Computed configuration 23/30 in 0:00:00.914415\n",
      "25/06/2025-15:00:00 | Performance:             balanced_accuracy - Train: 0.8635, Validation: 0.5273\n",
      "25/06/2025-15:00:00 | Best Performance So Far: balanced_accuracy - Train: 0.8622, Validation: 0.5331\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.031082874030801372\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:01 | Computed configuration 24/30 in 0:00:01.014461\n",
      "25/06/2025-15:00:01 | Performance:             balanced_accuracy - Train: 0.7515, Validation: 0.5098\n",
      "25/06/2025-15:00:01 | Best Performance So Far: balanced_accuracy - Train: 0.8622, Validation: 0.5331\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.020161107280363105\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:02 | Computed configuration 25/30 in 0:00:00.905194\n",
      "25/06/2025-15:00:02 | Performance:             balanced_accuracy - Train: 0.7328, Validation: 0.4769\n",
      "25/06/2025-15:00:02 | Best Performance So Far: balanced_accuracy - Train: 0.8622, Validation: 0.5331\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.19902793600645713\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:04 | Computed configuration 26/30 in 0:00:00.887752\n",
      "25/06/2025-15:00:04 | Performance:             balanced_accuracy - Train: 0.8676, Validation: 0.5254\n",
      "25/06/2025-15:00:04 | Best Performance So Far: balanced_accuracy - Train: 0.8622, Validation: 0.5331\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.20270157949864748\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:05 | Computed configuration 27/30 in 0:00:00.917971\n",
      "25/06/2025-15:00:05 | Performance:             balanced_accuracy - Train: 0.8642, Validation: 0.5334\n",
      "25/06/2025-15:00:05 | Best Performance So Far: balanced_accuracy - Train: 0.8642, Validation: 0.5334\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.22199508284254993\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:06 | Computed configuration 28/30 in 0:00:00.906847\n",
      "25/06/2025-15:00:06 | Performance:             balanced_accuracy - Train: 0.8764, Validation: 0.5176\n",
      "25/06/2025-15:00:06 | Best Performance So Far: balanced_accuracy - Train: 0.8642, Validation: 0.5334\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.20118273122612113\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:08 | Computed configuration 29/30 in 0:00:00.921173\n",
      "25/06/2025-15:00:08 | Performance:             balanced_accuracy - Train: 0.8665, Validation: 0.5235\n",
      "25/06/2025-15:00:08 | Best Performance So Far: balanced_accuracy - Train: 0.8642, Validation: 0.5334\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.19716480965427113\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:09 | Computed configuration 30/30 in 0:00:00.906985\n",
      "25/06/2025-15:00:09 | Performance:             balanced_accuracy - Train: 0.8635, Validation: 0.5299\n",
      "25/06/2025-15:00:09 | Best Performance So Far: balanced_accuracy - Train: 0.8642, Validation: 0.5334\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-15:00:09 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-15:00:09 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.20270157949864748\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.8642      |      0.5334      |\n",
      "|      f1_score     |       0.8666      |      0.5324      |\n",
      "|      accuracy     |       0.8642      |      0.5332      |\n",
      "|     precision     |       0.8520      |      0.5322      |\n",
      "|    sensitivity    |       0.8818      |      0.5449      |\n",
      "|    specificity    |       0.8465      |      0.5220      |\n",
      "|        auc        |       0.8642      |      0.5334      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:00:10 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.8315      |      0.3236      |\n",
      "|      f1_score     |       0.8349      |      0.3328      |\n",
      "|      accuracy     |       0.8315      |      0.3235      |\n",
      "|     precision     |       0.8183      |      0.3255      |\n",
      "|    sensitivity    |       0.8521      |      0.3404      |\n",
      "|    specificity    |       0.8108      |      0.3069      |\n",
      "|        auc        |       0.8315      |      0.3236      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:00:10 | Computations in outer fold 2 took 0.5484391166666666 minutes.\n",
      "25/06/2025-15:00:10 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 3\n",
      "*****************************************************************************************************\n",
      "25/06/2025-15:00:11 | Preparing data for outer fold 3...\n",
      "25/06/2025-15:00:11 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-15:00:11 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.5043 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:00:12 | Computed configuration 2/30 in 0:00:00.991368\n",
      "25/06/2025-15:00:12 | Performance:             balanced_accuracy - Train: 0.6503, Validation: 0.5224\n",
      "25/06/2025-15:00:12 | Best Performance So Far: balanced_accuracy - Train: 0.6503, Validation: 0.5224\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:13 | Computed configuration 3/30 in 0:00:00.941077\n",
      "25/06/2025-15:00:13 | Performance:             balanced_accuracy - Train: 0.9446, Validation: 0.5242\n",
      "25/06/2025-15:00:13 | Best Performance So Far: balanced_accuracy - Train: 0.9446, Validation: 0.5242\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:00:14 | Computed configuration 5/30 in 0:00:00.947092\n",
      "25/06/2025-15:00:14 | Performance:             balanced_accuracy - Train: 0.7317, Validation: 0.5157\n",
      "25/06/2025-15:00:14 | Best Performance So Far: balanced_accuracy - Train: 0.9446, Validation: 0.5242\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:15 | Computed configuration 6/30 in 0:00:00.981137\n",
      "25/06/2025-15:00:15 | Performance:             balanced_accuracy - Train: 0.6930, Validation: 0.5300\n",
      "25/06/2025-15:00:15 | Best Performance So Far: balanced_accuracy - Train: 0.6930, Validation: 0.5300\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:16 | Computed configuration 7/30 in 0:00:00.889969\n",
      "25/06/2025-15:00:16 | Performance:             balanced_accuracy - Train: 0.6307, Validation: 0.5191\n",
      "25/06/2025-15:00:16 | Best Performance So Far: balanced_accuracy - Train: 0.6930, Validation: 0.5300\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:16 | Computed configuration 8/30 in 0:00:00.896400\n",
      "25/06/2025-15:00:16 | Performance:             balanced_accuracy - Train: 0.7410, Validation: 0.5123\n",
      "25/06/2025-15:00:16 | Best Performance So Far: balanced_accuracy - Train: 0.6930, Validation: 0.5300\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:00:17 | Computed configuration 10/30 in 0:00:00.912526\n",
      "25/06/2025-15:00:17 | Performance:             balanced_accuracy - Train: 0.9546, Validation: 0.5244\n",
      "25/06/2025-15:00:17 | Best Performance So Far: balanced_accuracy - Train: 0.6930, Validation: 0.5300\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002049128507720536\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:19 | Computed configuration 11/30 in 0:00:00.891890\n",
      "25/06/2025-15:00:19 | Performance:             balanced_accuracy - Train: 0.6380, Validation: 0.5191\n",
      "25/06/2025-15:00:19 | Best Performance So Far: balanced_accuracy - Train: 0.6930, Validation: 0.5300\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006232012695368364\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:20 | Computed configuration 12/30 in 0:00:00.883145\n",
      "25/06/2025-15:00:20 | Performance:             balanced_accuracy - Train: 0.6941, Validation: 0.5296\n",
      "25/06/2025-15:00:20 | Best Performance So Far: balanced_accuracy - Train: 0.6930, Validation: 0.5300\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.009536616020457607\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:21 | Computed configuration 13/30 in 0:00:00.889587\n",
      "25/06/2025-15:00:21 | Performance:             balanced_accuracy - Train: 0.7132, Validation: 0.5288\n",
      "25/06/2025-15:00:21 | Best Performance So Far: balanced_accuracy - Train: 0.6930, Validation: 0.5300\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.2040376346369326\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:22 | Computed configuration 14/30 in 0:00:00.911868\n",
      "25/06/2025-15:00:22 | Performance:             balanced_accuracy - Train: 0.8719, Validation: 0.5249\n",
      "25/06/2025-15:00:22 | Best Performance So Far: balanced_accuracy - Train: 0.6930, Validation: 0.5300\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0011326749264943903\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:24 | Computed configuration 15/30 in 0:00:00.905886\n",
      "25/06/2025-15:00:24 | Performance:             balanced_accuracy - Train: 0.6290, Validation: 0.5191\n",
      "25/06/2025-15:00:24 | Best Performance So Far: balanced_accuracy - Train: 0.6930, Validation: 0.5300\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.4490610027308467\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:25 | Computed configuration 16/30 in 0:00:00.934000\n",
      "25/06/2025-15:00:25 | Performance:             balanced_accuracy - Train: 0.9381, Validation: 0.5343\n",
      "25/06/2025-15:00:25 | Best Performance So Far: balanced_accuracy - Train: 0.9381, Validation: 0.5343\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0036542220050125103\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:26 | Computed configuration 17/30 in 0:00:00.884175\n",
      "25/06/2025-15:00:26 | Performance:             balanced_accuracy - Train: 0.6703, Validation: 0.5185\n",
      "25/06/2025-15:00:26 | Best Performance So Far: balanced_accuracy - Train: 0.9381, Validation: 0.5343\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.6760564963881166\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:28 | Computed configuration 18/30 in 0:00:00.920955\n",
      "25/06/2025-15:00:28 | Performance:             balanced_accuracy - Train: 0.9682, Validation: 0.5343\n",
      "25/06/2025-15:00:28 | Best Performance So Far: balanced_accuracy - Train: 0.9381, Validation: 0.5343\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.3260431389142822\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:29 | Computed configuration 19/30 in 0:00:00.873481\n",
      "25/06/2025-15:00:29 | Performance:             balanced_accuracy - Train: 0.9076, Validation: 0.5442\n",
      "25/06/2025-15:00:29 | Best Performance So Far: balanced_accuracy - Train: 0.9076, Validation: 0.5442\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.3471471461233168\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:30 | Computed configuration 20/30 in 0:00:00.912307\n",
      "25/06/2025-15:00:30 | Performance:             balanced_accuracy - Train: 0.9147, Validation: 0.5410\n",
      "25/06/2025-15:00:30 | Best Performance So Far: balanced_accuracy - Train: 0.9076, Validation: 0.5442\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.3350416455235236\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:31 | Computed configuration 21/30 in 0:00:00.901659\n",
      "25/06/2025-15:00:31 | Performance:             balanced_accuracy - Train: 0.9106, Validation: 0.5414\n",
      "25/06/2025-15:00:31 | Best Performance So Far: balanced_accuracy - Train: 0.9076, Validation: 0.5442\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.2704836780452513\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:33 | Computed configuration 22/30 in 0:00:00.917554\n",
      "25/06/2025-15:00:33 | Performance:             balanced_accuracy - Train: 0.8895, Validation: 0.5392\n",
      "25/06/2025-15:00:33 | Best Performance So Far: balanced_accuracy - Train: 0.9076, Validation: 0.5442\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.23913903490401858\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:35 | Computed configuration 23/30 in 0:00:01.174498\n",
      "25/06/2025-15:00:35 | Performance:             balanced_accuracy - Train: 0.8826, Validation: 0.5294\n",
      "25/06/2025-15:00:35 | Best Performance So Far: balanced_accuracy - Train: 0.9076, Validation: 0.5442\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.3261075304966493\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:36 | Computed configuration 24/30 in 0:00:00.942817\n",
      "25/06/2025-15:00:36 | Performance:             balanced_accuracy - Train: 0.9078, Validation: 0.5263\n",
      "25/06/2025-15:00:36 | Best Performance So Far: balanced_accuracy - Train: 0.9076, Validation: 0.5442\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.32868486577979583\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:37 | Computed configuration 25/30 in 0:00:00.917416\n",
      "25/06/2025-15:00:37 | Performance:             balanced_accuracy - Train: 0.9114, Validation: 0.5341\n",
      "25/06/2025-15:00:37 | Best Performance So Far: balanced_accuracy - Train: 0.9076, Validation: 0.5442\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.3347609924899498\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:38 | Computed configuration 26/30 in 0:00:00.898899\n",
      "25/06/2025-15:00:38 | Performance:             balanced_accuracy - Train: 0.9151, Validation: 0.5389\n",
      "25/06/2025-15:00:38 | Best Performance So Far: balanced_accuracy - Train: 0.9076, Validation: 0.5442\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.33741013763440114\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:40 | Computed configuration 27/30 in 0:00:00.862669\n",
      "25/06/2025-15:00:40 | Performance:             balanced_accuracy - Train: 0.9127, Validation: 0.5326\n",
      "25/06/2025-15:00:40 | Best Performance So Far: balanced_accuracy - Train: 0.9076, Validation: 0.5442\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.33053695468758537\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:41 | Computed configuration 28/30 in 0:00:00.856839\n",
      "25/06/2025-15:00:41 | Performance:             balanced_accuracy - Train: 0.9144, Validation: 0.5185\n",
      "25/06/2025-15:00:41 | Best Performance So Far: balanced_accuracy - Train: 0.9076, Validation: 0.5442\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.21047869306379713\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:42 | Computed configuration 29/30 in 0:00:00.858830\n",
      "25/06/2025-15:00:42 | Performance:             balanced_accuracy - Train: 0.8719, Validation: 0.5191\n",
      "25/06/2025-15:00:42 | Best Performance So Far: balanced_accuracy - Train: 0.9076, Validation: 0.5442\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.3055669263759226\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:43 | Computed configuration 30/30 in 0:00:00.856044\n",
      "25/06/2025-15:00:43 | Performance:             balanced_accuracy - Train: 0.9026, Validation: 0.5399\n",
      "25/06/2025-15:00:43 | Best Performance So Far: balanced_accuracy - Train: 0.9076, Validation: 0.5442\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-15:00:44 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-15:00:44 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.3260431389142822\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9076      |      0.5442      |\n",
      "|      f1_score     |       0.9081      |      0.5616      |\n",
      "|      accuracy     |       0.9076      |      0.5432      |\n",
      "|     precision     |       0.9035      |      0.5401      |\n",
      "|    sensitivity    |       0.9127      |      0.6223      |\n",
      "|    specificity    |       0.9024      |      0.4662      |\n",
      "|        auc        |       0.9076      |      0.5442      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:00:44 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.8646      |      0.4585      |\n",
      "|      f1_score     |       0.8666      |      0.4165      |\n",
      "|      accuracy     |       0.8646      |      0.4591      |\n",
      "|     precision     |       0.8539      |      0.4476      |\n",
      "|    sensitivity    |       0.8796      |      0.3895      |\n",
      "|    specificity    |       0.8495      |      0.5276      |\n",
      "|        auc        |       0.8646      |      0.4585      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:00:44 | Computations in outer fold 3 took 0.5584158499999999 minutes.\n",
      "25/06/2025-15:00:44 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 4\n",
      "*****************************************************************************************************\n",
      "25/06/2025-15:00:45 | Preparing data for outer fold 4...\n",
      "25/06/2025-15:00:45 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-15:00:45 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.5061 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:00:47 | Computed configuration 2/30 in 0:00:00.987305\n",
      "25/06/2025-15:00:47 | Performance:             balanced_accuracy - Train: 0.6786, Validation: 0.4801\n",
      "25/06/2025-15:00:47 | Best Performance So Far: balanced_accuracy - Train: 0.6786, Validation: 0.4801\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:47 | Computed configuration 3/30 in 0:00:00.842358\n",
      "25/06/2025-15:00:47 | Performance:             balanced_accuracy - Train: 0.9513, Validation: 0.5273\n",
      "25/06/2025-15:00:47 | Best Performance So Far: balanced_accuracy - Train: 0.9513, Validation: 0.5273\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:00:48 | Computed configuration 5/30 in 0:00:00.922613\n",
      "25/06/2025-15:00:48 | Performance:             balanced_accuracy - Train: 0.7235, Validation: 0.4875\n",
      "25/06/2025-15:00:48 | Best Performance So Far: balanced_accuracy - Train: 0.9513, Validation: 0.5273\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:49 | Computed configuration 6/30 in 0:00:00.946917\n",
      "25/06/2025-15:00:49 | Performance:             balanced_accuracy - Train: 0.6988, Validation: 0.4734\n",
      "25/06/2025-15:00:49 | Best Performance So Far: balanced_accuracy - Train: 0.9513, Validation: 0.5273\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:50 | Computed configuration 7/30 in 0:00:00.884865\n",
      "25/06/2025-15:00:50 | Performance:             balanced_accuracy - Train: 0.6659, Validation: 0.4933\n",
      "25/06/2025-15:00:50 | Best Performance So Far: balanced_accuracy - Train: 0.9513, Validation: 0.5273\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:51 | Computed configuration 8/30 in 0:00:00.875152\n",
      "25/06/2025-15:00:51 | Performance:             balanced_accuracy - Train: 0.7357, Validation: 0.4932\n",
      "25/06/2025-15:00:51 | Best Performance So Far: balanced_accuracy - Train: 0.9513, Validation: 0.5273\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:00:52 | Computed configuration 10/30 in 0:00:01.033279\n",
      "25/06/2025-15:00:52 | Performance:             balanced_accuracy - Train: 0.9583, Validation: 0.5300\n",
      "25/06/2025-15:00:52 | Best Performance So Far: balanced_accuracy - Train: 0.9583, Validation: 0.5300\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0844064265033311\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:53 | Computed configuration 11/30 in 0:00:00.935946\n",
      "25/06/2025-15:00:53 | Performance:             balanced_accuracy - Train: 0.8079, Validation: 0.5171\n",
      "25/06/2025-15:00:53 | Best Performance So Far: balanced_accuracy - Train: 0.9583, Validation: 0.5300\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.27747856055598813\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:55 | Computed configuration 12/30 in 0:00:00.879494\n",
      "25/06/2025-15:00:55 | Performance:             balanced_accuracy - Train: 0.8991, Validation: 0.5328\n",
      "25/06/2025-15:00:55 | Best Performance So Far: balanced_accuracy - Train: 0.8991, Validation: 0.5328\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.4140721970646941\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:56 | Computed configuration 13/30 in 0:00:00.919640\n",
      "25/06/2025-15:00:56 | Performance:             balanced_accuracy - Train: 0.9236, Validation: 0.5252\n",
      "25/06/2025-15:00:56 | Best Performance So Far: balanced_accuracy - Train: 0.8991, Validation: 0.5328\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.2079406941904851\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:57 | Computed configuration 14/30 in 0:00:00.915074\n",
      "25/06/2025-15:00:57 | Performance:             balanced_accuracy - Train: 0.8718, Validation: 0.5358\n",
      "25/06/2025-15:00:57 | Best Performance So Far: balanced_accuracy - Train: 0.8718, Validation: 0.5358\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.20765951477939965\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:00:59 | Computed configuration 15/30 in 0:00:00.890968\n",
      "25/06/2025-15:00:59 | Performance:             balanced_accuracy - Train: 0.8711, Validation: 0.5328\n",
      "25/06/2025-15:00:59 | Best Performance So Far: balanced_accuracy - Train: 0.8718, Validation: 0.5358\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.23311468833983734\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:00 | Computed configuration 16/30 in 0:00:00.928754\n",
      "25/06/2025-15:01:00 | Performance:             balanced_accuracy - Train: 0.8834, Validation: 0.5298\n",
      "25/06/2025-15:01:00 | Best Performance So Far: balanced_accuracy - Train: 0.8718, Validation: 0.5358\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.11900696536440605\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:01 | Computed configuration 17/30 in 0:00:00.884299\n",
      "25/06/2025-15:01:01 | Performance:             balanced_accuracy - Train: 0.8371, Validation: 0.5180\n",
      "25/06/2025-15:01:01 | Best Performance So Far: balanced_accuracy - Train: 0.8718, Validation: 0.5358\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.23010274125651262\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:02 | Computed configuration 18/30 in 0:00:00.896263\n",
      "25/06/2025-15:01:02 | Performance:             balanced_accuracy - Train: 0.8817, Validation: 0.5257\n",
      "25/06/2025-15:01:02 | Best Performance So Far: balanced_accuracy - Train: 0.8718, Validation: 0.5358\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.1853795005375064\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:04 | Computed configuration 19/30 in 0:00:00.890999\n",
      "25/06/2025-15:01:04 | Performance:             balanced_accuracy - Train: 0.8655, Validation: 0.5369\n",
      "25/06/2025-15:01:04 | Best Performance So Far: balanced_accuracy - Train: 0.8655, Validation: 0.5369\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0810705467060629\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:05 | Computed configuration 20/30 in 0:00:00.897445\n",
      "25/06/2025-15:01:05 | Performance:             balanced_accuracy - Train: 0.8098, Validation: 0.5227\n",
      "25/06/2025-15:01:05 | Best Performance So Far: balanced_accuracy - Train: 0.8655, Validation: 0.5369\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.1897386493028301\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:06 | Computed configuration 21/30 in 0:00:00.968127\n",
      "25/06/2025-15:01:06 | Performance:             balanced_accuracy - Train: 0.8640, Validation: 0.5337\n",
      "25/06/2025-15:01:06 | Best Performance So Far: balanced_accuracy - Train: 0.8655, Validation: 0.5369\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.06449533442285284\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:08 | Computed configuration 22/30 in 0:00:00.862082\n",
      "25/06/2025-15:01:08 | Performance:             balanced_accuracy - Train: 0.7965, Validation: 0.5077\n",
      "25/06/2025-15:01:08 | Best Performance So Far: balanced_accuracy - Train: 0.8655, Validation: 0.5369\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.1890300872953025\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:09 | Computed configuration 23/30 in 0:00:00.830929\n",
      "25/06/2025-15:01:09 | Performance:             balanced_accuracy - Train: 0.8642, Validation: 0.5244\n",
      "25/06/2025-15:01:09 | Best Performance So Far: balanced_accuracy - Train: 0.8655, Validation: 0.5369\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.16931848339070835\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:10 | Computed configuration 24/30 in 0:00:00.876495\n",
      "25/06/2025-15:01:10 | Performance:             balanced_accuracy - Train: 0.8559, Validation: 0.5289\n",
      "25/06/2025-15:01:10 | Best Performance So Far: balanced_accuracy - Train: 0.8655, Validation: 0.5369\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.16275189357685022\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:11 | Computed configuration 25/30 in 0:00:00.892896\n",
      "25/06/2025-15:01:11 | Performance:             balanced_accuracy - Train: 0.8522, Validation: 0.5232\n",
      "25/06/2025-15:01:11 | Best Performance So Far: balanced_accuracy - Train: 0.8655, Validation: 0.5369\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.07213681687008289\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:13 | Computed configuration 26/30 in 0:00:00.906687\n",
      "25/06/2025-15:01:13 | Performance:             balanced_accuracy - Train: 0.8006, Validation: 0.5101\n",
      "25/06/2025-15:01:13 | Best Performance So Far: balanced_accuracy - Train: 0.8655, Validation: 0.5369\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.1781257184682904\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:14 | Computed configuration 27/30 in 0:00:00.873773\n",
      "25/06/2025-15:01:14 | Performance:             balanced_accuracy - Train: 0.8645, Validation: 0.5311\n",
      "25/06/2025-15:01:14 | Best Performance So Far: balanced_accuracy - Train: 0.8655, Validation: 0.5369\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.019773662018928547\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:15 | Computed configuration 28/30 in 0:00:00.904411\n",
      "25/06/2025-15:01:15 | Performance:             balanced_accuracy - Train: 0.7341, Validation: 0.4945\n",
      "25/06/2025-15:01:15 | Best Performance So Far: balanced_accuracy - Train: 0.8655, Validation: 0.5369\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.18406362367515997\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:16 | Computed configuration 29/30 in 0:00:00.881205\n",
      "25/06/2025-15:01:16 | Performance:             balanced_accuracy - Train: 0.8621, Validation: 0.5347\n",
      "25/06/2025-15:01:16 | Best Performance So Far: balanced_accuracy - Train: 0.8655, Validation: 0.5369\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.18586922209254067\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:18 | Computed configuration 30/30 in 0:00:00.917700\n",
      "25/06/2025-15:01:18 | Performance:             balanced_accuracy - Train: 0.8591, Validation: 0.5353\n",
      "25/06/2025-15:01:18 | Best Performance So Far: balanced_accuracy - Train: 0.8655, Validation: 0.5369\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-15:01:18 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-15:01:18 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.1853795005375064\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.8655      |      0.5369      |\n",
      "|      f1_score     |       0.8684      |      0.5494      |\n",
      "|      accuracy     |       0.8655      |      0.5363      |\n",
      "|     precision     |       0.8501      |      0.5432      |\n",
      "|    sensitivity    |       0.8877      |      0.5883      |\n",
      "|    specificity    |       0.8434      |      0.4854      |\n",
      "|        auc        |       0.8655      |      0.5369      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:01:19 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.8326      |      0.5299      |\n",
      "|      f1_score     |       0.8377      |      0.5073      |\n",
      "|      accuracy     |       0.8326      |      0.5304      |\n",
      "|     precision     |       0.8130      |      0.5265      |\n",
      "|    sensitivity    |       0.8640      |      0.4894      |\n",
      "|    specificity    |       0.8012      |      0.5704      |\n",
      "|        auc        |       0.8326      |      0.5299      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:01:19 | Computations in outer fold 4 took 0.5529271666666666 minutes.\n",
      "25/06/2025-15:01:19 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 5\n",
      "*****************************************************************************************************\n",
      "25/06/2025-15:01:20 | Preparing data for outer fold 5...\n",
      "25/06/2025-15:01:20 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-15:01:20 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.5061 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:01:21 | Computed configuration 2/30 in 0:00:00.884112\n",
      "25/06/2025-15:01:21 | Performance:             balanced_accuracy - Train: 0.6788, Validation: 0.5211\n",
      "25/06/2025-15:01:21 | Best Performance So Far: balanced_accuracy - Train: 0.6788, Validation: 0.5211\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:22 | Computed configuration 3/30 in 0:00:00.843287\n",
      "25/06/2025-15:01:22 | Performance:             balanced_accuracy - Train: 0.9392, Validation: 0.5289\n",
      "25/06/2025-15:01:22 | Best Performance So Far: balanced_accuracy - Train: 0.9392, Validation: 0.5289\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:01:23 | Computed configuration 5/30 in 0:00:00.833571\n",
      "25/06/2025-15:01:23 | Performance:             balanced_accuracy - Train: 0.7201, Validation: 0.5031\n",
      "25/06/2025-15:01:23 | Best Performance So Far: balanced_accuracy - Train: 0.9392, Validation: 0.5289\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:24 | Computed configuration 6/30 in 0:00:00.967722\n",
      "25/06/2025-15:01:24 | Performance:             balanced_accuracy - Train: 0.6956, Validation: 0.5123\n",
      "25/06/2025-15:01:24 | Best Performance So Far: balanced_accuracy - Train: 0.9392, Validation: 0.5289\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:25 | Computed configuration 7/30 in 0:00:00.765824\n",
      "25/06/2025-15:01:25 | Performance:             balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "25/06/2025-15:01:25 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:25 | Computed configuration 8/30 in 0:00:00.758700\n",
      "25/06/2025-15:01:25 | Performance:             balanced_accuracy - Train: 0.7313, Validation: 0.5061\n",
      "25/06/2025-15:01:25 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:01:26 | Computed configuration 10/30 in 0:00:00.790939\n",
      "25/06/2025-15:01:26 | Performance:             balanced_accuracy - Train: 0.9540, Validation: 0.5100\n",
      "25/06/2025-15:01:26 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002049128507720536\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:27 | Computed configuration 11/30 in 0:00:00.753286\n",
      "25/06/2025-15:01:27 | Performance:             balanced_accuracy - Train: 0.6706, Validation: 0.5187\n",
      "25/06/2025-15:01:27 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0014666036255122862\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:28 | Computed configuration 12/30 in 0:00:00.823939\n",
      "25/06/2025-15:01:28 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5325\n",
      "25/06/2025-15:01:28 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.08229530985262312\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:29 | Computed configuration 13/30 in 0:00:00.772140\n",
      "25/06/2025-15:01:29 | Performance:             balanced_accuracy - Train: 0.8046, Validation: 0.5173\n",
      "25/06/2025-15:01:29 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006607606845869705\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:31 | Computed configuration 14/30 in 0:00:00.806806\n",
      "25/06/2025-15:01:31 | Performance:             balanced_accuracy - Train: 0.6971, Validation: 0.5049\n",
      "25/06/2025-15:01:31 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0011178249558918643\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:32 | Computed configuration 15/30 in 0:00:00.756873\n",
      "25/06/2025-15:01:32 | Performance:             balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "25/06/2025-15:01:32 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0013626771793862926\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:33 | Computed configuration 16/30 in 0:00:00.777202\n",
      "25/06/2025-15:01:33 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5325\n",
      "25/06/2025-15:01:33 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0016970894484922162\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:34 | Computed configuration 17/30 in 0:00:00.756432\n",
      "25/06/2025-15:01:34 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5325\n",
      "25/06/2025-15:01:34 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0013771112361664667\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:35 | Computed configuration 18/30 in 0:00:00.777151\n",
      "25/06/2025-15:01:35 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5325\n",
      "25/06/2025-15:01:35 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0017985820921717075\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:36 | Computed configuration 19/30 in 0:00:00.755348\n",
      "25/06/2025-15:01:36 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5325\n",
      "25/06/2025-15:01:36 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.005486404900084412\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:37 | Computed configuration 20/30 in 0:00:00.753787\n",
      "25/06/2025-15:01:37 | Performance:             balanced_accuracy - Train: 0.6936, Validation: 0.5067\n",
      "25/06/2025-15:01:37 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0018611046710919855\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:38 | Computed configuration 21/30 in 0:00:00.747785\n",
      "25/06/2025-15:01:38 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5298\n",
      "25/06/2025-15:01:38 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0013851583541369698\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:39 | Computed configuration 22/30 in 0:00:00.763115\n",
      "25/06/2025-15:01:39 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5325\n",
      "25/06/2025-15:01:39 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002937529812271817\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:40 | Computed configuration 23/30 in 0:00:00.748653\n",
      "25/06/2025-15:01:40 | Performance:             balanced_accuracy - Train: 0.6749, Validation: 0.5180\n",
      "25/06/2025-15:01:40 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001373787419845492\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:41 | Computed configuration 24/30 in 0:00:00.746059\n",
      "25/06/2025-15:01:41 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5325\n",
      "25/06/2025-15:01:41 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0013857201153062298\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:42 | Computed configuration 25/30 in 0:00:00.765709\n",
      "25/06/2025-15:01:42 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5325\n",
      "25/06/2025-15:01:42 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0035042029433761087\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:43 | Computed configuration 26/30 in 0:00:00.760233\n",
      "25/06/2025-15:01:43 | Performance:             balanced_accuracy - Train: 0.6848, Validation: 0.5163\n",
      "25/06/2025-15:01:43 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0013848070568529874\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:44 | Computed configuration 27/30 in 0:00:00.774663\n",
      "25/06/2025-15:01:44 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5325\n",
      "25/06/2025-15:01:44 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0017235368736743483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:45 | Computed configuration 28/30 in 0:00:00.756744\n",
      "25/06/2025-15:01:45 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5325\n",
      "25/06/2025-15:01:45 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001713011170510813\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:46 | Computed configuration 29/30 in 0:00:00.761339\n",
      "25/06/2025-15:01:46 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5325\n",
      "25/06/2025-15:01:46 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0017246088106991596\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:01:47 | Computed configuration 30/30 in 0:00:00.754650\n",
      "25/06/2025-15:01:47 | Performance:             balanced_accuracy - Train: 0.6667, Validation: 0.5325\n",
      "25/06/2025-15:01:47 | Best Performance So Far: balanced_accuracy - Train: 0.6665, Validation: 0.5325\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-15:01:48 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-15:01:48 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.6665      |      0.5325      |\n",
      "|      f1_score     |       0.6656      |      0.5129      |\n",
      "|      accuracy     |       0.6665      |      0.5328      |\n",
      "|     precision     |       0.6780      |      0.5297      |\n",
      "|    sensitivity    |       0.6935      |      0.4979      |\n",
      "|    specificity    |       0.6395      |      0.5671      |\n",
      "|        auc        |       0.6665      |      0.5325      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:01:48 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.6558      |      0.5349      |\n",
      "|      f1_score     |       0.6779      |      0.5649      |\n",
      "|      accuracy     |       0.6558      |      0.5339      |\n",
      "|     precision     |       0.6369      |      0.5241      |\n",
      "|    sensitivity    |       0.7246      |      0.6127      |\n",
      "|    specificity    |       0.5869      |      0.4570      |\n",
      "|        auc        |       0.6558      |      0.5349      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:01:48 | Computations in outer fold 5 took 0.4623228833333333 minutes.\n",
      "25/06/2025-15:01:48 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Finished all outer fold computations.\n",
      "25/06/2025-15:01:50 | Now analysing the final results...\n",
      "25/06/2025-15:01:50 | Computing dummy metrics...\n",
      "25/06/2025-15:01:50 | Computing mean and std for all outer fold metrics...\n",
      "25/06/2025-15:01:50 | Find best config across outer folds...\n",
      "25/06/2025-15:01:50 | Save final results...\n",
      "25/06/2025-15:01:50 | Writing results to project folder...\n",
      "25/06/2025-15:01:51 | Prepare Hyperpipe.optimum pipe with best config..\n",
      "25/06/2025-15:01:51 | Fitting best model...\n",
      "25/06/2025-15:01:52 | Saved best model to file.\n",
      "25/06/2025-15:01:52 | Summarizing results...\n",
      "25/06/2025-15:01:52 | Write predictions to files...\n",
      "25/06/2025-15:01:52 | Write summary...\n",
      "*****************************************************************************************************\n",
      "\n",
      "ANALYSIS INFORMATION ================================================================================ \n",
      "Project Folder: ./analysis/participant1_15min\\5FinalPipelineCIFSGB_results_2025-06-25_14-59-05,\n",
      "Computation Time: 2025-06-25 14:59:05.523906 - 2025-06-25 15:01:50.189631\n",
      "Duration: 0:02:44.665725\n",
      "Optimized for: balanced_accuracy\n",
      "Hyperparameter Optimizer: sk_opt\n",
      "\n",
      "DUMMY RESULTS =======================================================================================\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.5052 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "\n",
      "AVERAGE PERFORMANCE ACROSS OUTER FOLDS ==============================================================\n",
      "+-------------------+---------------+--------------+-----------+----------+\n",
      "|    Metric Name    | Training Mean | Training Std | Test Mean | Test Std |\n",
      "+-------------------+---------------+--------------+-----------+----------+\n",
      "| balanced_accuracy |    0.771825   |   0.088044   |  0.485242 | 0.089591 |\n",
      "|      f1_score     |    0.779137   |   0.083114   |  0.487766 | 0.102201 |\n",
      "|      accuracy     |    0.771825   |   0.088044   |  0.485016 | 0.089317 |\n",
      "|     precision     |    0.758543   |   0.087364   |  0.476739 | 0.084113 |\n",
      "|    sensitivity    |    0.801423   |   0.079566   |  0.503931 | 0.130899 |\n",
      "|    specificity    |    0.742227   |   0.100151   |  0.466553 | 0.089574 |\n",
      "|        auc        |    0.771825   |   0.088044   |  0.485242 | 0.089591 |\n",
      "+-------------------+---------------+--------------+-----------+----------+\n",
      "\n",
      "BEST HYPERPARAMETER CONFIGURATION ===================================================================\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0015374940517896831\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "\n",
      "+--------+-------------------+----------+----------+-----------+-------------+-------------+--------+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| fold # | balanced_accuracy | f1_score | accuracy | precision | sensitivity | specificity |  auc   |                                                                  Best Hyperparameter Config                                                                 |\n",
      "+--------+-------------------+----------+----------+-----------+-------------+-------------+--------+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|   1*   |       0.5793      |  0.6173  |  0.5781  |   0.5600  |    0.6877   |    0.4708   | 0.5793 | {'ImbalancedDataTransformer': ['method_name=RandomOverSampler'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.0015374940517896831']} |\n",
      "|   2    |       0.3236      |  0.3328  |  0.3235  |   0.3255  |    0.3404   |    0.3069   | 0.3236 |   {'ImbalancedDataTransformer': ['method_name=BorderlineSMOTE'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.20270157949864748']}   |\n",
      "|   3    |       0.4585      |  0.4165  |  0.4591  |   0.4476  |    0.3895   |    0.5276   | 0.4585 |    {'ImbalancedDataTransformer': ['method_name=BorderlineSMOTE'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.3260431389142822']}   |\n",
      "|   4    |       0.5299      |  0.5073  |  0.5304  |   0.5265  |    0.4894   |    0.5704   | 0.5299 |   {'ImbalancedDataTransformer': ['method_name=RandomOverSampler'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.1853795005375064']}  |\n",
      "|   5    |       0.5349      |  0.5649  |  0.5339  |   0.5241  |    0.6127   |    0.4570   | 0.5349 |        {'ImbalancedDataTransformer': ['method_name=SMOTE'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.001140444703947033']}       |\n",
      "+--------+-------------------+----------+----------+-----------+-------------+-------------+--------+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "PHOTONAI 2.5.2 ======================================================================================\n",
      "Your results are stored in ./analysis/participant1_15min\\5FinalPipelineCIFSGB_results_2025-06-25_14-59-05\n",
      "Go to https://explorer.photon-ai.com and upload your photonai_results.json for convenient result visualization! \n",
      "For more info and documentation visit https://www.photon-ai.com\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from photonai.base import Hyperpipe, PipelineElement\n",
    "from photonai.optimization import FloatRange, Categorical\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "tested_methods = Categorical(['RandomUnderSampler', 'RandomOverSampler', 'SMOTE', 'BorderlineSMOTE'])\n",
    "\n",
    "final_pipeline1 = Hyperpipe('5 - Final Pipeline CI + FS + GB',\n",
    "    outer_cv=StratifiedKFold(n_splits=5, shuffle=False),\n",
    "    inner_cv=StratifiedKFold(n_splits=3, shuffle=False),\n",
    "    use_test_set=True,\n",
    "    metrics=list(metrics.keys()),\n",
    "    best_config_metric='balanced_accuracy',\n",
    "    optimizer='sk_opt',\n",
    "    optimizer_params={'n_configurations': 30},\n",
    "    project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "    cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "\n",
    "final_pipeline1 += PipelineElement('ImbalancedDataTransformer',\n",
    "                           hyperparameters={'method_name': tested_methods})\n",
    "\n",
    "# from sklearn.feature_selection import f_classif\n",
    "\n",
    "# final_pipeline1 += PipelineElement('SelectKBest',\n",
    "#                                    hyperparameters={'k': [5, 10, 'all']},\n",
    "#                                    score_func=f_classif)\n",
    "\n",
    "\n",
    "\n",
    "final_pipeline1 += PipelineElement('GradientBoostingClassifier', \n",
    "                            hyperparameters={\n",
    "                                'loss': ['deviance', 'exponential'],\n",
    "                                'learning_rate': FloatRange(0.001, 1, 'logspace')\n",
    "                            }, random_state=4)\n",
    "\n",
    "# Fit hyperpipe\n",
    "final_pipeline1.fit(X, y)\n",
    "\n",
    "# Optionally print mean validation results\n",
    "# print(final_pipeline1.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# Optionally print feature importances\n",
    "# print_feature_importances(final_pipeline1)\n",
    "\n",
    "# Optionally debug CV splits\n",
    "# for k, v in final_pipeline1.cross_validation.outer_folds.items():\n",
    "#     print(v.train_indices)\n",
    "#     print(v.test_indices)\n",
    "#     print(len(v.train_indices), len(v.test_indices))\n",
    "#     print()\n",
    "\n",
    "# Write additional reports\n",
    "add_other_report_to_summary(final_pipeline1, with_estimator_comparison=False)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix_from_pipeline(final_pipeline1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40cb1e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: Built-in GradientBoosting Feature Importances\n",
      "-------------------------------------------------------\n",
      "time_from_last_drug_taken 0.3242\n",
      "heart_rate           0.2377\n",
      "stress_score         0.1276\n",
      "deep                 0.1034\n",
      "steps                0.0869\n",
      "awake                0.0699\n",
      "nonrem_percentage    0.0286\n",
      "total                0.0159\n",
      "light                0.0039\n",
      "rem                  0.0020\n",
      "sleep_efficiency     0.0000\n",
      "nonrem_total         0.0000\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Alternative 1: Built-in Feature Importances (Fastest)\n",
    "print(\"Method 1: Built-in GradientBoosting Feature Importances\")\n",
    "print(\"-\" * 55)\n",
    "try:\n",
    "    # Get the trained estimator\n",
    "    gb_estimator = final_pipeline1.optimum_pipe.named_steps['GradientBoostingClassifier']\n",
    "    \n",
    "    if hasattr(gb_estimator, 'feature_importances_'):\n",
    "        importances = gb_estimator.feature_importances_\n",
    "        feature_names = np.array(columns[1:-1])\n",
    "        \n",
    "        # Sort by importance\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        for i, idx in enumerate(indices):\n",
    "            print(f\"{feature_names[idx]:<20} {importances[idx]:.4f}\")\n",
    "    else:\n",
    "        print(\"Built-in feature importances not available\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b391b0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 2: Sklearn Permutation Importance\n",
      "----------------------------------------\n",
      "Error: 'PhotonPipeline' object has no attribute 'classes_'\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative 2: Using sklearn's permutation_importance directly\n",
    "print(\"Method 2: Sklearn Permutation Importance\")\n",
    "print(\"-\" * 40)\n",
    "try:\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    \n",
    "    # Get the fitted pipeline\n",
    "    fitted_pipeline = final_pipeline1.optimum_pipe\n",
    "    \n",
    "    # Use a subset of data for faster computation (optional)\n",
    "    # X_sample = X.sample(n=min(1000, len(X)), random_state=42)\n",
    "    # y_sample = y.loc[X_sample.index]\n",
    "    \n",
    "    # Calculate permutation importance\n",
    "    perm_importance = permutation_importance(\n",
    "        fitted_pipeline, X, y, \n",
    "        n_repeats=10,  # Reduced for speed\n",
    "        random_state=42,\n",
    "        scoring='balanced_accuracy'\n",
    "    )\n",
    "    \n",
    "    feature_names = np.array(columns[1:-1])\n",
    "    \n",
    "    # Sort by importance\n",
    "    indices = np.argsort(perm_importance.importances_mean)[::-1]\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        print(f\"{feature_names[idx]:<20} {perm_importance.importances_mean[idx]:.4f} \"\n",
    "              f\"±{perm_importance.importances_std[idx]:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3867dc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 3: SHAP Feature Importance\n",
      "-----------------------------------\n",
      "Error: The passed model is not callable and cannot be analyzed directly with the given masker! Model: PhotonPipeline(elements=[('ImbalancedDataTransformer',\n",
      "                          PipelineElement(config=None,\n",
      "                                          method_name='RandomOverSampler',\n",
      "                                          name='ImbalancedDataTransformer')),\n",
      "                         ('GradientBoostingClassifier',\n",
      "                          PipelineElement(ccp_alpha=0.0,\n",
      "                                          criterion='friedman_mse', init=None,\n",
      "                                          learning_rate=0.0015374940517896831,\n",
      "                                          loss='exponential', max_depth=3,\n",
      "                                          max_features=None,\n",
      "                                          max_leaf_nodes=None,\n",
      "                                          min_impurity_decrease=0.0,\n",
      "                                          min_samples_leaf=1,\n",
      "                                          min_samples_split=2,\n",
      "                                          min_weight_fraction_leaf=0.0,\n",
      "                                          n_estimators=100,\n",
      "                                          n_iter_no_change=None,\n",
      "                                          name='GradientBoostingClassifier',\n",
      "                                          random_state=4, subsample=1.0,\n",
      "                                          tol=0.0001, validation_fraction=0.1,\n",
      "                                          verbose=0, warm_start=False))])\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative 3: SHAP Values (if you have shap installed)\n",
    "print(\"Method 3: SHAP Feature Importance\")\n",
    "print(\"-\" * 35)\n",
    "try:\n",
    "    import shap\n",
    "    \n",
    "    # Get the fitted pipeline\n",
    "    fitted_pipeline = final_pipeline1.optimum_pipe\n",
    "    \n",
    "    # Use a sample for SHAP (it can be slow on large datasets)\n",
    "    X_sample = X.sample(n=min(500, len(X)), random_state=42)\n",
    "    \n",
    "    # Create explainer\n",
    "    explainer = shap.Explainer(fitted_pipeline, X_sample)\n",
    "    shap_values = explainer(X_sample)\n",
    "    \n",
    "    # Get mean absolute SHAP values as feature importance\n",
    "    feature_importance = np.abs(shap_values.values).mean(0)\n",
    "    feature_names = np.array(columns[1:-1])\n",
    "    \n",
    "    # Sort by importance\n",
    "    indices = np.argsort(feature_importance)[::-1]\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        print(f\"{feature_names[idx]:<20} {feature_importance[idx]:.4f}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"SHAP not installed. Install with: pip install shap\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5e96786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 4: DataFrame Summary\n",
      "-------------------------\n",
      "\n",
      "Computing permutation importances. This may take a while.\n",
      "*****************************************************************************************************\n",
      "Permutation Importances: Fitting model for outer fold 1\n",
      "Permutation Importances: Calculating performances for outer fold 1\n",
      "Error: 'PhotonPipeline' object has no attribute 'classes_'\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative 4: Simple DataFrame approach for better visualization\n",
    "print(\"Method 4: DataFrame Summary\")\n",
    "print(\"-\" * 25)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Using the original hyperpipe method but organizing results better\n",
    "    r = final_pipeline1.get_permutation_feature_importances(\n",
    "        n_repeats=20,  # Reduced for speed\n",
    "        random_state=0, \n",
    "        scoring='balanced_accuracy'\n",
    "    )\n",
    "    \n",
    "    # Create DataFrame for better organization\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': np.array(columns[1:-1]),\n",
    "        'Importance': r[\"mean\"],\n",
    "        'Std_Dev': r[\"std\"],\n",
    "        'Lower_Bound': r[\"mean\"] - 2 * r[\"std\"],\n",
    "        'Upper_Bound': r[\"mean\"] + 2 * r[\"std\"]\n",
    "    })\n",
    "    \n",
    "    # Sort by importance\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Display top 10\n",
    "    print(\"Top 10 Most Important Features:\")\n",
    "    print(importance_df.head(10).to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # Show only statistically significant features\n",
    "    significant_features = importance_df[importance_df['Lower_Bound'] > 0]\n",
    "    \n",
    "    if len(significant_features) > 0:\n",
    "        print(f\"\\nStatistically Significant Features ({len(significant_features)}):\")\n",
    "        print(significant_features.to_string(index=False, float_format='%.4f'))\n",
    "    else:\n",
    "        print(\"\\nNo statistically significant features found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e699c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 5: Quick and Simple\n",
      "-------------------------\n",
      "Feature Importance Ranking:\n",
      " 1. heart_rate           0.5611\n",
      " 2. time_from_last_drug_taken 0.2721\n",
      " 3. deep                 0.0723\n",
      " 4. total                0.0621\n",
      " 5. rem                  0.0151\n",
      " 6. awake                0.0128\n",
      " 7. sleep_efficiency     0.0025\n",
      " 8. nonrem_percentage    0.0010\n",
      " 9. nonrem_total         0.0010\n",
      "10. stress_score         0.0000\n",
      "11. steps                0.0000\n",
      "12. light                0.0000\n"
     ]
    }
   ],
   "source": [
    "# Alternative 5: Quick and Simple (Minimal Code)\n",
    "print(\"Method 5: Quick and Simple\")\n",
    "print(\"-\" * 25)\n",
    "try:\n",
    "    # Just get the built-in importances with minimal code\n",
    "    estimator = final_pipeline1.optimum_pipe.named_steps['GradientBoostingClassifier']\n",
    "    importances = estimator.feature_importances_\n",
    "    features = np.array(columns[1:-1])\n",
    "    \n",
    "    # Create sorted list of (importance, feature) tuples\n",
    "    sorted_features = sorted(zip(importances, features), reverse=True)\n",
    "    \n",
    "    print(\"Feature Importance Ranking:\")\n",
    "    for i, (importance, feature) in enumerate(sorted_features[:15], 1):\n",
    "        print(f\"{i:2d}. {feature:<20} {importance:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
