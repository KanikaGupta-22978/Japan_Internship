{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'participant2'\n",
    "frequency = '15s' # 15min | 15s\n",
    "dataset_type = '' # ''\n",
    "\n",
    "if frequency == '15min':\n",
    "    record_size_per_day = 96\n",
    "elif frequency == '15s':\n",
    "    record_size_per_day = 5760\n",
    "\n",
    "# Columns to include  \n",
    "if dataset_type == '':\n",
    "    columns = [ 'timestamp', 'heart_rate', 'steps', 'stress_score',\n",
    "            'awake', 'deep', 'light', 'rem', 'nonrem_total', 'total', 'nonrem_percentage', 'sleep_efficiency',\n",
    "            'time_from_last_drug_taken', 'wearing_off' ]\n",
    "\n",
    "metrics = {\n",
    "    'balanced_accuracy': 'Bal. Acc.',\n",
    "    'f1_score': 'F1 Score',\n",
    "    'accuracy': 'Acc.',\n",
    "    'precision': 'Precision',\n",
    "    'sensitivity': 'Recall / Sn',\n",
    "    'specificity': 'Sp',\n",
    "    'auc': 'AUC'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from typing import Union, Generator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning, ConvergenceWarning\n",
    "\n",
    "import sklearn\n",
    "from photonai.base import Hyperpipe, PipelineElement, Stack, Switch\n",
    "from photonai.optimization import FloatRange, IntegerRange, Categorical, BooleanSwitch, PhotonHyperparam\n",
    "from photonai.optimization import Categorical as PhotonCategorical\n",
    "from photonai.optimization import MinimumPerformanceConstraint, DummyPerformanceConstraint, BestPerformanceConstraint\n",
    "from photonai.optimization.base_optimizer import PhotonSlaveOptimizer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tabulate import tabulate\n",
    "\n",
    "from skopt import Optimizer\n",
    "from skopt.space import Real, Integer, Dimension\n",
    "from skopt.space import Categorical as skoptCategorical\n",
    "from photonai.photonlogger.logger import logger\n",
    "from photonai.optimization.scikit_optimize.sk_opt import SkOptOptimizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "from photonai.base import Hyperpipe\n",
    "from photonai.optimization import MinimumPerformanceConstraint\n",
    "from photonai.photonlogger import logger \n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_excel(f'./data/combined_data/{dataset_type}combined_data_{user}_{frequency}.xlsx',\n",
    "                              index_col=\"timestamp\",\n",
    "                              usecols=columns,\n",
    "                              engine='openpyxl')\n",
    "if dataset_type == '':\n",
    "    # Define prediction horizon\n",
    "    predict_ahead = pd.Timedelta(minutes=60)  # <- change to 2 or pd.Timedelta(seconds=15) as needed\n",
    "\n",
    "    # Ensure datetime index\n",
    "    combined_data = combined_data.sort_index()\n",
    "    combined_data.index = pd.to_datetime(combined_data.index)\n",
    "\n",
    "    # Estimate time delta between rows (assumes regular sampling)\n",
    "    median_step = combined_data.index.to_series().diff().median()\n",
    "\n",
    "    # How many steps to shift based on prediction horizon\n",
    "    steps_ahead = int(predict_ahead / median_step)\n",
    "\n",
    "    # Shift labels backward to align X at time t with y at t + n\n",
    "    combined_data['wearing_off_future'] = combined_data['wearing_off'].shift(-steps_ahead)\n",
    "\n",
    "    # Drop rows with NaNs from shifting\n",
    "    combined_data = combined_data.dropna(subset=['wearing_off_future'])\n",
    "\n",
    "    # Define X and y\n",
    "    y = combined_data['wearing_off_future'].astype(int).values\n",
    "    X = combined_data.loc[:, columns[1:-1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Show feature importances\n",
    "def print_feature_importances(pipeline):\n",
    "    output = ''\n",
    "    if pipeline.optimum_pipe.feature_importances_ is None:\n",
    "        output = 'Best Hyperparameter Configuration is a non-linear SVM, thus feature importances cannot be retrieved'\n",
    "    else:\n",
    "        output = 'Feature Importances using the Best Hyperparameter Config'\n",
    "        if not [value.base_element.support_.tolist() for key, value in pipeline.optimum_pipe.elements if key == 'RFE']:\n",
    "            if len(pipeline.optimum_pipe.feature_importances_) == 1:\n",
    "                feature_importances = pipeline.optimum_pipe.feature_importances_[0]\n",
    "            else:\n",
    "                feature_importances = pipeline.optimum_pipe.feature_importances_\n",
    "            output += '\\n'\n",
    "            output += tabulate(\n",
    "                pd.DataFrame(\n",
    "                    [np.around(feature_importances, decimals=4)],\n",
    "                    columns=np.array(columns[1:-1])\n",
    "                ).transpose().sort_values(by=[0], ascending=False, key=abs),\n",
    "                tablefmt='psql', floatfmt=\".4f\", headers=['Features', 'Values']\n",
    "            )\n",
    "        else:\n",
    "            mask = [value.base_element.support_.tolist() for key, value in pipeline.optimum_pipe.elements if key == 'RFE'][0]\n",
    "            if len(pipeline.optimum_pipe.feature_importances_) == 1:\n",
    "                feature_importances = pipeline.optimum_pipe.feature_importances_[0]\n",
    "            else:\n",
    "                feature_importances = pipeline.optimum_pipe.feature_importances_\n",
    "            output += '\\n'\n",
    "            output += tabulate(\n",
    "                pd.DataFrame(\n",
    "                    [np.around(feature_importances, decimals=4)],\n",
    "                    columns=np.array(columns[1:-1])[mask]\n",
    "                ).transpose().sort_values(by=[0], ascending=False, key=abs),\n",
    "                tablefmt='psql', floatfmt=\".4f\", headers=['Features', 'Values']\n",
    "            )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, X, y, ax, n_splits=0, lw=20):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                    c=indices, marker='_', lw=lw, cmap=plt.cm.coolwarm,\n",
    "                    vmin=-.2, vmax=1.2)\n",
    "\n",
    "    n_splits = ii + 1\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X), c=y, marker='_', lw=lw, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['wearing-off']\n",
    "    ax.set(yticks=np.arange(n_splits+1) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Records\\'s Index', ylabel=\"Folds\",\n",
    "           ylim=[n_splits+1.2, -.2], xlim=[0, len(X)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_from_pipeline(pipeline):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    cm = confusion_matrix(\n",
    "        pipeline.results_handler.get_test_predictions()['y_true'],\n",
    "        pipeline.results_handler.get_test_predictions()['y_pred'],\n",
    "        labels=[0,1], normalize=None)\n",
    "    ax = plt.subplot()\n",
    "    sns.set(font_scale=3.0) # Adjust to fit\n",
    "    sns.heatmap(cm, annot=True, ax=ax, cmap=\"Blues\", fmt=\"g\");  \n",
    "\n",
    "    # Labels, title and ticks\n",
    "    label_font = {'size':'25'}  # Adjust to fit\n",
    "    ax.set_xlabel('Predicted labels', fontdict=label_font);\n",
    "    ax.set_ylabel('Observed labels', fontdict=label_font);\n",
    "\n",
    "    # title_font = {'size':'21'}  # Adjust to fit\n",
    "    # ax.set_title('Confusion Matrix', fontdict=title_font);\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=25)  # Adjust to fit\n",
    "    ax.xaxis.set_ticklabels(['Good', 'Wearing-Off']);\n",
    "    ax.yaxis.set_ticklabels(['Good', 'Wearing-Off']);\n",
    "    plt.rc('text') # , usetex=False)\n",
    "    plt.rc('font', family='serif')\n",
    "    # plt.savefig('./participant2-downsampling-confusionmatrix-real.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write other reports to summary file\n",
    "def add_other_report_to_summary(pipeline, with_estimator_comparison=True):\n",
    "    with open(f'{pipeline.output_settings.results_folder}/photon_summary.txt', \"a+\") as summary_file:\n",
    "        # 1. Write comparison of learning algorithms\n",
    "        if with_estimator_comparison:\n",
    "            summary_file.write(\"\\n\\n\")\n",
    "            summary_file.write(\"Comparison on learning algorithms on validation set\")\n",
    "            summary_file.write(\"\\n\")\n",
    "            summary_file.write(str(pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator()))\n",
    "\n",
    "        # 2. Write feature importance\n",
    "        summary_file.write(\"\\n\\n\")\n",
    "        summary_file.write(\"Feature Importance\")\n",
    "        summary_file.write(print_feature_importances(pipeline))\n",
    "        \n",
    "        # 3. Write beautified average test performance across outer folds\n",
    "        # a. Get Average Test Performance Across Outer Folds\n",
    "        test_metric_result = pipeline.results.get_test_metric_dict()\n",
    "        \n",
    "        # b. Replace display metric name\n",
    "        #   Reference: https://stackoverflow.com/a/55250496/2303766\n",
    "        test_metric_result = { metrics[metric]: test_metric_result[metric]\n",
    "                                  for metric, metric_name in metrics.items() if metric in test_metric_result\n",
    "                             }\n",
    "        \n",
    "        # c. Add beautified average test performance across outer folds to file \n",
    "        summary_file.write(\"\\n\\n\")\n",
    "        summary_file.write(\"Average Test Performance Across Outer Folds\")\n",
    "        summary_file.write(\"\\n\")\n",
    "        summary_file.write(\n",
    "            tabulate(\n",
    "                pd.DataFrame(\n",
    "                    test_metric_result\n",
    "                ).round(4).transpose(),\n",
    "                tablefmt='psql', floatfmt=\".4f\", headers='keys'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 4. Write outer fold results\n",
    "        summary_file.write(\"\\n\\n\")\n",
    "        summary_file.write(\"Outer Fold Best Estimators' Performance\")\n",
    "        summary_file.write(\"\\n\")\n",
    "        handler = pipeline.results_handler\n",
    "        performance_table = handler.get_performance_table()\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "            summary_file.write(\n",
    "                tabulate(\n",
    "                    performance_table.loc[:, ['fold', 'best_config', 'n_train', 'n_validation']].transpose(),\n",
    "                    tablefmt='psql', headers='keys'\n",
    "                )\n",
    "            )\n",
    "            summary_file.write(\"\\n\")\n",
    "            summary_file.write(\n",
    "                tabulate(\n",
    "                    performance_table.loc[:, ['fold'] + list(metrics.keys())].round(4).transpose(),\n",
    "                    tablefmt='psql', floatfmt=\".4f\", headers='keys'\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        outer_fold_performance = {}\n",
    "        config_evals = handler.get_config_evaluations()\n",
    "        for metric in metrics.keys():\n",
    "            # print(f'{metric}')\n",
    "            for i, j in enumerate(config_evals[metric]):\n",
    "                if f'{metric}_mean' in outer_fold_performance:\n",
    "                    # outer_fold_performance[f'{metric}_max'].append(np.max(j))\n",
    "                    outer_fold_performance[f'{metric}_mean'].append(np.mean(j))\n",
    "                    outer_fold_performance[f'{metric}_std'].append(np.std(j))\n",
    "                else:\n",
    "                    # outer_fold_performance[f'{metric}_max'] = [np.max(j)]\n",
    "                    outer_fold_performance[f'{metric}_mean'] = [np.mean(j)]\n",
    "                    outer_fold_performance[f'{metric}_std'] = [np.std(j)]\n",
    "        summary_file.write(\"\\n\")\n",
    "        summary_file.write(\n",
    "            tabulate(\n",
    "                pd.DataFrame(outer_fold_performance).round(4).transpose(),\n",
    "                tablefmt='psql', floatfmt=\".4f\", headers='keys'\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhotonAI Optimize Monkey-patch\n",
    "#     Added random_state for Optimize for result replicability\n",
    "def prepare(self, pipeline_elements: list, maximize_metric: bool) -> None:\n",
    "    \"\"\"\n",
    "    Initializes hyperparameter search with scikit-optimize.\n",
    "\n",
    "    Assembles all hyperparameters of the list of PipelineElements\n",
    "    in order to prepare the hyperparameter space.\n",
    "    Hyperparameters can be accessed via pipe_element.hyperparameters.\n",
    "\n",
    "    Parameters:\n",
    "        pipeline_elements:\n",
    "            List of all PipelineElements to create the hyperparameter space.\n",
    "\n",
    "        maximize_metric:\n",
    "            Boolean to distinguish between score and error.\n",
    "\n",
    "    \"\"\"\n",
    "    self.start_time = None\n",
    "    self.optimizer = None\n",
    "    self.hyperparameter_list = []\n",
    "    self.maximize_metric = maximize_metric\n",
    "\n",
    "    # build skopt space\n",
    "    space = []\n",
    "    for pipe_element in pipeline_elements:\n",
    "        if pipe_element.__class__.__name__ == 'Switch':\n",
    "            error_msg = 'Scikit-Optimize cannot operate in the specified hyperparameter space with a Switch ' \\\n",
    "                        'element. We recommend the use of SMAC.'\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if hasattr(pipe_element, 'hyperparameters'):\n",
    "            for name, value in pipe_element.hyperparameters.items():\n",
    "                # if we only have one value we do not need to optimize\n",
    "                if isinstance(value, list) and len(value) < 2:\n",
    "                    self.constant_dictionary[name] = value[0]\n",
    "                    continue\n",
    "                if isinstance(value, PhotonCategorical) and len(value.values) < 2:\n",
    "                    self.constant_dictionary[name] = value.values[0]\n",
    "                    continue\n",
    "                skopt_param = self._convert_photonai_to_skopt_space(value, name)\n",
    "                if skopt_param is not None:\n",
    "                    space.append(skopt_param)\n",
    "\n",
    "    if self.constant_dictionary:\n",
    "        msg = \"PHOTONAI has detected some one-valued params in your hyperparameters. Pleas use the kwargs for \" \\\n",
    "              \"constant values. This run ignores following settings: \" + str(self.constant_dictionary.keys())\n",
    "        logger.warning(msg)\n",
    "        warnings.warn(msg)\n",
    "\n",
    "    if len(space) == 0:\n",
    "        msg = \"Did not find any hyperparameter to convert into skopt space.\"\n",
    "        logger.warning(msg)\n",
    "        warnings.warn(msg)\n",
    "    else:\n",
    "        self.optimizer = Optimizer(space,\n",
    "                                   base_estimator=self.base_estimator,\n",
    "                                   n_initial_points=self.n_initial_points,\n",
    "                                   initial_point_generator=self.initial_point_generator,\n",
    "                                   acq_func=self.acq_func,\n",
    "                                   acq_func_kwargs=self.acq_func_kwargs,\n",
    "                                   random_state=4\n",
    "                                  )\n",
    "    self.ask = self.ask_generator()\n",
    "    \n",
    "#    Monkey patched new prepare function\n",
    "SkOptOptimizer.prepare = prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set for Outer Fold 0\n",
      "[ 30490  30491  30492 ... 172557 172558 172559]\n",
      "\n",
      "Train Set for Outer Fold 1\n",
      "[     0      1      2 ... 172557 172558 172559]\n",
      "\n",
      "Train Set for Outer Fold 2\n",
      "[     0      1      2 ... 172557 172558 172559]\n",
      "\n",
      "Train Set for Outer Fold 3\n",
      "[     0      1      2 ... 172557 172558 172559]\n",
      "\n",
      "Train Set for Outer Fold 4\n",
      "[     0      1      2 ... 138511 138512 138513]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Outer CV\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "plot_cv_indices(cv, X, y, ax)\n",
    "plt.rc('text') # , usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "plt.title('Outer Folds')\n",
    "# Save as file\n",
    "# plt.savefig('./blockingtimeseriessplit.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "training_folds = []\n",
    "for train, test in cv.split(X, y):\n",
    "    print(f'Train Set for Outer Fold {len(training_folds)}')\n",
    "    print(train)\n",
    "    training_folds.append(train)\n",
    "    # print(\"Test\")\n",
    "    # print(test[0], test[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sets for Outer Fold 0\n",
      "Train Set for Inner Fold 0\n",
      "[  1310   1311   1312 ... 138045 138046 138047]\n",
      "\n",
      "Train Set for Inner Fold 1\n",
      "[     0      1      2 ... 138045 138046 138047]\n",
      "\n",
      "Train Set for Inner Fold 2\n",
      "[    0     1     2 ... 92629 92630 92631]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inner CV\n",
    "outer_fold_number = 0\n",
    "\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "plot_cv_indices(cv, X.iloc[training_folds[outer_fold_number]], y[training_folds[outer_fold_number]], ax)\n",
    "plt.rc('text') # , usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "plt.title(f'Inner Fold for Outer Fold {outer_fold_number}')\n",
    "# Save as file\n",
    "# plt.savefig('./blockingtimeseriessplit.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "inner_training_folds = []\n",
    "print(f'Train Sets for Outer Fold {outer_fold_number}')\n",
    "for train, test in cv.split(X.iloc[training_folds[outer_fold_number]], y[training_folds[outer_fold_number]]):\n",
    "    print(f'Train Set for Inner Fold {len(inner_training_folds)}')\n",
    "    print(train)\n",
    "    inner_training_folds.append(train)\n",
    "    # print(\"Test\")\n",
    "    # print(test[0], test[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photonai import PipelineElement, Switch\n",
    "from photonai.optimization import IntegerRange, FloatRange\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "estimator_selection = Switch('estimators')\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"LogisticRegression\",\n",
    "    base_element=LogisticRegression(class_weight='balanced', random_state=4),\n",
    "    hyperparameters={\n",
    "        'C': FloatRange(1, 10)\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"DecisionTreeClassifier\",\n",
    "    base_element=DecisionTreeClassifier(random_state=4, criterion='gini'),\n",
    "    hyperparameters={\n",
    "        'min_samples_split': IntegerRange(2, 30),\n",
    "        'min_samples_leaf': IntegerRange(2, 30)\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"LinearSVC\",\n",
    "    base_element=LinearSVC(class_weight='balanced', random_state=4),\n",
    "    hyperparameters={\n",
    "        'C': FloatRange(1, 25)\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"RandomForestClassifier\",\n",
    "    base_element=RandomForestClassifier(random_state=4, criterion='gini', bootstrap=True),\n",
    "    hyperparameters={\n",
    "        'min_samples_split': IntegerRange(2, 30),\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator_selection += PipelineElement(\n",
    "    \"GradientBoostingClassifier\",\n",
    "    base_element=GradientBoostingClassifier(random_state=4),\n",
    "    hyperparameters={\n",
    "        'loss': ['log_loss', 'exponential'],\n",
    "        'learning_rate': FloatRange(0.001, 1, 'logspace')\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add LGBMClassifier\n",
    "estimator_selection += PipelineElement(\n",
    "    \"LGBMClassifier\",\n",
    "    base_element=LGBMClassifier(random_state=4),\n",
    "    hyperparameters={\n",
    "        \"n_estimators\": IntegerRange(50, 150, step=10, range_type=\"range\"),\n",
    "        \"learning_rate\": FloatRange(0.01, 0.3, range_type=\"logspace\"),\n",
    "        \"max_depth\": IntegerRange(3, 10, step=1, range_type=\"range\")\n",
    "    }\n",
    ")\n",
    "# estimator_selection += PipelineElement(\n",
    "#     \"LGBMClassifier\",\n",
    "#     base_element=LGBMClassifier(random_state=4),\n",
    "#     hyperparameters={\n",
    "#         \"n_estimators\": IntegerRange(50, 150, step=10, range_type=\"range\"),\n",
    "#         \"learning_rate\": FloatRange(0.01, 0.3, range_type=\"logspace\"),\n",
    "#         \"max_depth\": IntegerRange(3, 10, step=1, range_type=\"range\")\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     16,
     20,
     25,
     29
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initial_pipeline = Hyperpipe('1 - Initial Pipeline',\n",
    "#                      outer_cv = StratifiedKFold(n_splits=5, shuffle=False),\n",
    "#                      inner_cv = StratifiedKFold(n_splits=3, shuffle=False),\n",
    "#                      use_test_set = False,\n",
    "#                      metrics = list(metrics.keys()),\n",
    "#                      best_config_metric='balanced_accuracy',\n",
    "#                      optimizer='switch',\n",
    "#                      optimizer_params={'name': 'sk_opt', 'n_configurations': 30},\n",
    "#                      project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "#                      cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "#                      verbosity=1,\n",
    "#                      performance_constraints=[MinimumPerformanceConstraint('balanced_accuracy', 0.75, 'mean')])\n",
    "\n",
    "# # Add learning algorithms to compare\n",
    "# initial_pipeline += estimator_selection\n",
    "\n",
    "# # Fit hyperpipe\n",
    "# initial_pipeline.fit(X, y)\n",
    "\n",
    "# # Show learning algorithms mean validation results\n",
    "# # print(\"Comparison on learning algorithms on validation set\")\n",
    "# # print(initial_pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# # # Show feature importances\n",
    "# # print_feature_importances(initial_pipeline)\n",
    "\n",
    "# # # View CV splits for debugging\n",
    "# # for k,v in initial_pipeline.cross_validation.outer_folds.items():\n",
    "# #     print(v.train_indices)\n",
    "# #     print(v.test_indices)\n",
    "# #     print(len(v.train_indices), len(v.test_indices))\n",
    "# #     print()\n",
    "\n",
    "# # Write other reports to summary file\n",
    "# add_other_report_to_summary(initial_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classifier = LogisticRegression(random_state=4).fit(X, y)\n",
    "\n",
    "# feature_selection_pipeline = Hyperpipe('2 - Feature Selection Pipline',\n",
    "#                      outer_cv = StratifiedKFold(n_splits=5, shuffle=False),\n",
    "#                      inner_cv = StratifiedKFold(n_splits=3, shuffle=False),\n",
    "#                      use_test_set = False,\n",
    "#                      metrics = list(metrics.keys()),\n",
    "#                      best_config_metric='balanced_accuracy',\n",
    "#                      optimizer='switch',\n",
    "#                      optimizer_params={'name': 'sk_opt', 'n_configurations': 30},\n",
    "#                      project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "#                      cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "#                      verbosity=1,\n",
    "#                      performance_constraints=[MinimumPerformanceConstraint('balanced_accuracy', 0.75, 'mean')])\n",
    "\n",
    "# feature_selection_pipeline += PipelineElement('RFE', \n",
    "#                            hyperparameters={\n",
    "#                                'n_features_to_select': IntegerRange(2, (len(columns) - 2))\n",
    "#                            }, estimator=classifier)\n",
    "\n",
    "# feature_selection_pipeline += estimator_selection\n",
    "\n",
    "# # Fit hyperpipe\n",
    "# feature_selection_pipeline.fit(X, y)\n",
    "\n",
    "# # Show learning algorithms mean validation results\n",
    "# # print(\"Comparison on learning algorithms on validation set\")\n",
    "# # print(feature_selection_pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# # # Show feature importances\n",
    "# # print_feature_importances(feature_selection_pipeline)\n",
    "\n",
    "# # # View CV splits for debugging\n",
    "# # for k,v in feature_selection_pipeline.cross_validation.outer_folds.items():\n",
    "# #     print(v.train_indices)\n",
    "# #     print(v.test_indices)\n",
    "# #     print(len(v.train_indices), len(v.test_indices))\n",
    "# #     print()\n",
    "\n",
    "# # Write other reports to summary file\n",
    "# add_other_report_to_summary(feature_selection_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalanced Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_imbalanced_pipeline = Hyperpipe('3 - Class Imbalanced Pipline',\n",
    "#                      outer_cv = StratifiedKFold(n_splits=5, shuffle=False),\n",
    "#                      inner_cv = StratifiedKFold(n_splits=3, shuffle=False),\n",
    "#                      use_test_set = False,\n",
    "#                      metrics = list(metrics.keys()),\n",
    "#                      best_config_metric='balanced_accuracy',\n",
    "#                      optimizer='switch',\n",
    "#                      optimizer_params={'name': 'sk_opt', 'n_configurations': 30},\n",
    "#                      project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "#                      cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "#                      verbosity=1,\n",
    "#                      performance_constraints=[MinimumPerformanceConstraint('balanced_accuracy', 0.75, 'mean')])\n",
    "\n",
    "# tested_methods = Categorical(['RandomUnderSampler', 'RandomOverSampler', 'SMOTE', 'BorderlineSMOTE'])\n",
    "# class_imbalanced_pipeline += PipelineElement('ImbalancedDataTransformer',\n",
    "#                            hyperparameters={ 'method_name': tested_methods })\n",
    "\n",
    "# class_imbalanced_pipeline += estimator_selection\n",
    "\n",
    "# # Fit hyperpipe\n",
    "# class_imbalanced_pipeline.fit(X, y)\n",
    "\n",
    "# # Show learning algorithms mean validation results\n",
    "# # print(\"Comparison on learning algorithms on validation set\")\n",
    "# # print(class_imbalanced_pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# # # Show feature importances\n",
    "# # print_feature_importances(class_imbalanced_pipeline)\n",
    "\n",
    "# # # View CV splits for debugging\n",
    "# # for k,v in class_imbalanced_pipeline.cross_validation.outer_folds.items():\n",
    "# #     print(v.train_indices)\n",
    "# #     print(v.test_indices)\n",
    "# #     print(len(v.train_indices), len(v.test_indices))\n",
    "# #     print()\n",
    "\n",
    "# # Write other reports to summary file\n",
    "# add_other_report_to_summary(class_imbalanced_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "737f77f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from photonai.base.hyperpipe import OutputSettings\n",
    "\n",
    "# Save original method\n",
    "original_update_settings = OutputSettings.update_settings\n",
    "\n",
    "def patched_update_settings(self, name, timestamp):\n",
    "    max_retries = 5\n",
    "    delay = 1  # seconds\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            original_update_settings(self, name, timestamp)\n",
    "            break  # success, exit retry loop\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError on attempt {attempt+1}/{max_retries} when updating settings: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(\"Max retries reached. Raising the PermissionError.\")\n",
    "                raise\n",
    "\n",
    "# Apply monkey patch\n",
    "OutputSettings.update_settings = patched_update_settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalanced + Feature Selection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = LogisticRegression(random_state=4).fit(X, y)\n",
    "\n",
    "# class_imbalanced_feature_selection_pipeline = Hyperpipe('4 - CI and FS Pipeline',\n",
    "#                      outer_cv = StratifiedKFold(n_splits=5, shuffle=False),\n",
    "#                      inner_cv = StratifiedKFold(n_splits=3, shuffle=False),\n",
    "#                      use_test_set = False,\n",
    "#                      metrics = list(metrics.keys()),\n",
    "#                      best_config_metric='balanced_accuracy',\n",
    "#                      optimizer='switch',\n",
    "#                      optimizer_params={'name': 'sk_opt', 'n_configurations': 30},\n",
    "#                      project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "#                      cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "#                      verbosity=1,\n",
    "#                      performance_constraints=[MinimumPerformanceConstraint('balanced_accuracy', 0.75, 'mean')])\n",
    "\n",
    "\n",
    "# tested_methods = Categorical(['RandomUnderSampler', 'RandomOverSampler', 'SMOTE', 'BorderlineSMOTE'])\n",
    "# class_imbalanced_feature_selection_pipeline += PipelineElement('ImbalancedDataTransformer',\n",
    "#                            hyperparameters={ 'method_name': tested_methods })\n",
    "\n",
    "# class_imbalanced_feature_selection_pipeline += PipelineElement('RFE', \n",
    "#                            hyperparameters={\n",
    "#                                'n_features_to_select': IntegerRange(2, (len(columns) - 2))\n",
    "#                            }, estimator=classifier)\n",
    "\n",
    "# class_imbalanced_feature_selection_pipeline += estimator_selection\n",
    "\n",
    "# # Fit hyperpipe\n",
    "# class_imbalanced_feature_selection_pipeline.fit(X, y)\n",
    "\n",
    "# # Show learning algorithms mean validation results\n",
    "\n",
    "# # print(\"Comparison on learning algorithms on validation set\")\n",
    "# # print(class_imbalanced_feature_selection_pipeline.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# # # Show feature importances\n",
    "# # print_feature_importances(class_imbalanced_feature_selection_pipeline)\n",
    "\n",
    "# # # View CV splits for debugging\n",
    "# # for k,v in class_imbalanced_feature_selection_pipeline.cross_validation.outer_folds.items():\n",
    "# #     print(v.train_indices)\n",
    "# #     print(v.test_indices)\n",
    "# #     print(len(v.train_indices), len(v.test_indices))\n",
    "# #     print()\n",
    "\n",
    "# # Write other reports to summary file\n",
    "# add_other_report_to_summary(class_imbalanced_feature_selection_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CI GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:08:37 | Output Folder: ./analysis/participant2_15s\\5FinalPipelineCIFSGB_results_2025-06-25_15-08-37\n",
      "=====================================================================================================\n",
      "PHOTONAI ANALYSIS: 5FinalPipelineCIFSGB\n",
      "=====================================================================================================\n",
      "25/06/2025-15:08:37 | Preparing data and PHOTONAI objects for analysis...\n",
      "25/06/2025-15:08:37 | Checking input data...\n",
      "25/06/2025-15:08:37 | Running analysis with 172560 samples.\n",
      "Found 2 target classes: [0 1]\n",
      "Target classes are imbalanced: 97.39742698191934% belongs to 0\n",
      "25/06/2025-15:08:37 | Removing cache files...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 1\n",
      "*****************************************************************************************************\n",
      "25/06/2025-15:08:37 | Preparing data for outer fold 1...\n",
      "25/06/2025-15:08:37 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-15:08:37 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.9740 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:09:42 | Computed configuration 2/30 in 0:01:04.674051\n",
      "25/06/2025-15:09:42 | Performance:             balanced_accuracy - Train: 0.9529, Validation: 0.5922\n",
      "25/06/2025-15:09:42 | Best Performance So Far: balanced_accuracy - Train: 0.9529, Validation: 0.5922\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:09:44 | Computed configuration 3/30 in 0:00:01.874852\n",
      "25/06/2025-15:09:44 | Performance:             balanced_accuracy - Train: 0.9999, Validation: 0.4901\n",
      "25/06/2025-15:09:44 | Best Performance So Far: balanced_accuracy - Train: 0.9529, Validation: 0.5922\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:10:37 | Computed configuration 5/30 in 0:00:52.930091\n",
      "25/06/2025-15:10:37 | Performance:             balanced_accuracy - Train: 0.9648, Validation: 0.5927\n",
      "25/06/2025-15:10:37 | Best Performance So Far: balanced_accuracy - Train: 0.9648, Validation: 0.5927\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:11:43 | Computed configuration 6/30 in 0:01:05.573451\n",
      "25/06/2025-15:11:43 | Performance:             balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "25/06/2025-15:11:43 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:12:42 | Computed configuration 7/30 in 0:00:59.500695\n",
      "25/06/2025-15:12:42 | Performance:             balanced_accuracy - Train: 0.9439, Validation: 0.6037\n",
      "25/06/2025-15:12:42 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:12:44 | Computed configuration 8/30 in 0:00:01.661986\n",
      "25/06/2025-15:12:44 | Performance:             balanced_accuracy - Train: 0.9772, Validation: 0.6215\n",
      "25/06/2025-15:12:44 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:13:46 | Computed configuration 10/30 in 0:01:02.248079\n",
      "25/06/2025-15:13:46 | Performance:             balanced_accuracy - Train: 0.9993, Validation: 0.4767\n",
      "25/06/2025-15:13:46 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002049128507720536\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:14:32 | Computed configuration 11/30 in 0:00:45.215701\n",
      "25/06/2025-15:14:32 | Performance:             balanced_accuracy - Train: 0.9496, Validation: 0.5922\n",
      "25/06/2025-15:14:32 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006232012695368364\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:15:31 | Computed configuration 12/30 in 0:00:58.833388\n",
      "25/06/2025-15:15:31 | Performance:             balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "25/06/2025-15:15:31 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006247306990365161\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:16:31 | Computed configuration 13/30 in 0:01:00.196614\n",
      "25/06/2025-15:16:31 | Performance:             balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "25/06/2025-15:16:31 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.005765456844439381\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:17:32 | Computed configuration 14/30 in 0:00:59.791239\n",
      "25/06/2025-15:17:32 | Performance:             balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "25/06/2025-15:17:32 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006108675384335357\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:18:40 | Computed configuration 15/30 in 0:01:07.945045\n",
      "25/06/2025-15:18:40 | Performance:             balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "25/06/2025-15:18:40 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006249901001548972\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:19:40 | Computed configuration 16/30 in 0:00:59.325013\n",
      "25/06/2025-15:19:40 | Performance:             balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "25/06/2025-15:19:40 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.007538881234393783\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:20:38 | Computed configuration 17/30 in 0:00:57.729030\n",
      "25/06/2025-15:20:38 | Performance:             balanced_accuracy - Train: 0.9495, Validation: 0.6603\n",
      "25/06/2025-15:20:38 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.003919085654246674\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:21:37 | Computed configuration 18/30 in 0:00:59.252553\n",
      "25/06/2025-15:21:37 | Performance:             balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "25/06/2025-15:21:37 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.00918981710614759\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:22:37 | Computed configuration 19/30 in 0:00:59.379769\n",
      "25/06/2025-15:22:37 | Performance:             balanced_accuracy - Train: 0.9499, Validation: 0.6767\n",
      "25/06/2025-15:22:37 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.011064702303164852\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:23:36 | Computed configuration 20/30 in 0:00:58.864432\n",
      "25/06/2025-15:23:36 | Performance:             balanced_accuracy - Train: 0.9519, Validation: 0.6726\n",
      "25/06/2025-15:23:36 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014285113802731798\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:24:35 | Computed configuration 21/30 in 0:00:58.575231\n",
      "25/06/2025-15:24:35 | Performance:             balanced_accuracy - Train: 0.9541, Validation: 0.6527\n",
      "25/06/2025-15:24:35 | Best Performance So Far: balanced_accuracy - Train: 0.9432, Validation: 0.7135\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0017212829426857287\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:25:34 | Computed configuration 22/30 in 0:00:59.005305\n",
      "25/06/2025-15:25:34 | Performance:             balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "25/06/2025-15:25:34 | Best Performance So Far: balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.06623830728819599\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:26:37 | Computed configuration 23/30 in 0:01:02.052289\n",
      "25/06/2025-15:26:37 | Performance:             balanced_accuracy - Train: 0.9890, Validation: 0.4780\n",
      "25/06/2025-15:26:37 | Best Performance So Far: balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0012056354489138105\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:27:36 | Computed configuration 24/30 in 0:00:58.947409\n",
      "25/06/2025-15:27:36 | Performance:             balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "25/06/2025-15:27:36 | Best Performance So Far: balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0015780436258440863\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:28:36 | Computed configuration 25/30 in 0:00:59.996228\n",
      "25/06/2025-15:28:36 | Performance:             balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "25/06/2025-15:28:36 | Best Performance So Far: balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0022476973032483274\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:29:42 | Computed configuration 26/30 in 0:01:05.326489\n",
      "25/06/2025-15:29:42 | Performance:             balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "25/06/2025-15:29:42 | Best Performance So Far: balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.00110996186991975\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:30:36 | Computed configuration 27/30 in 0:00:53.321465\n",
      "25/06/2025-15:30:36 | Performance:             balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "25/06/2025-15:30:36 | Best Performance So Far: balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0031240026007831427\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:31:30 | Computed configuration 28/30 in 0:00:53.396204\n",
      "25/06/2025-15:31:30 | Performance:             balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "25/06/2025-15:31:30 | Best Performance So Far: balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.003115573682635602\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:32:23 | Computed configuration 29/30 in 0:00:53.392277\n",
      "25/06/2025-15:32:23 | Performance:             balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "25/06/2025-15:32:23 | Best Performance So Far: balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0031229443111808236\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:33:16 | Computed configuration 30/30 in 0:00:52.274234\n",
      "25/06/2025-15:33:16 | Performance:             balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "25/06/2025-15:33:16 | Best Performance So Far: balanced_accuracy - Train: 0.9438, Validation: 0.7137\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-15:33:16 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-15:33:16 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0017212829426857287\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9438      |      0.7137      |\n",
      "|      f1_score     |       0.9468      |      0.3506      |\n",
      "|      accuracy     |       0.9438      |      0.8017      |\n",
      "|     precision     |       0.9293      |      0.3629      |\n",
      "|    sensitivity    |       0.9692      |      0.6208      |\n",
      "|    specificity    |       0.9184      |      0.8065      |\n",
      "|        auc        |       0.9438      |      0.7137      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:33:45 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9338      |      0.4336      |\n",
      "|      f1_score     |       0.9370      |      0.0422      |\n",
      "|      accuracy     |       0.9338      |      0.2165      |\n",
      "|     precision     |       0.8938      |      0.0218      |\n",
      "|    sensitivity    |       0.9847      |      0.6626      |\n",
      "|    specificity    |       0.8830      |      0.2046      |\n",
      "|        auc        |       0.9338      |      0.4336      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:33:46 | Computations in outer fold 1 took 25.154303316666667 minutes.\n",
      "25/06/2025-15:33:46 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 2\n",
      "*****************************************************************************************************\n",
      "25/06/2025-15:34:10 | Preparing data for outer fold 2...\n",
      "25/06/2025-15:34:10 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-15:34:10 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.9740 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:35:03 | Computed configuration 2/30 in 0:00:52.423863\n",
      "25/06/2025-15:35:03 | Performance:             balanced_accuracy - Train: 0.9117, Validation: 0.6584\n",
      "25/06/2025-15:35:03 | Best Performance So Far: balanced_accuracy - Train: 0.9117, Validation: 0.6584\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:35:05 | Computed configuration 3/30 in 0:00:01.941808\n",
      "25/06/2025-15:35:05 | Performance:             balanced_accuracy - Train: 0.9971, Validation: 0.5987\n",
      "25/06/2025-15:35:05 | Best Performance So Far: balanced_accuracy - Train: 0.9117, Validation: 0.6584\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:35:46 | Computed configuration 5/30 in 0:00:41.631717\n",
      "25/06/2025-15:35:46 | Performance:             balanced_accuracy - Train: 0.9392, Validation: 0.6186\n",
      "25/06/2025-15:35:46 | Best Performance So Far: balanced_accuracy - Train: 0.9117, Validation: 0.6584\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:36:39 | Computed configuration 6/30 in 0:00:52.135608\n",
      "25/06/2025-15:36:39 | Performance:             balanced_accuracy - Train: 0.9507, Validation: 0.7445\n",
      "25/06/2025-15:36:39 | Best Performance So Far: balanced_accuracy - Train: 0.9507, Validation: 0.7445\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:37:31 | Computed configuration 7/30 in 0:00:52.706080\n",
      "25/06/2025-15:37:31 | Performance:             balanced_accuracy - Train: 0.9083, Validation: 0.6584\n",
      "25/06/2025-15:37:31 | Best Performance So Far: balanced_accuracy - Train: 0.9507, Validation: 0.7445\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:37:33 | Computed configuration 8/30 in 0:00:01.566841\n",
      "25/06/2025-15:37:33 | Performance:             balanced_accuracy - Train: 0.9547, Validation: 0.6258\n",
      "25/06/2025-15:37:33 | Best Performance So Far: balanced_accuracy - Train: 0.9507, Validation: 0.7445\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:38:27 | Computed configuration 10/30 in 0:00:53.632605\n",
      "25/06/2025-15:38:27 | Performance:             balanced_accuracy - Train: 0.9981, Validation: 0.6132\n",
      "25/06/2025-15:38:27 | Best Performance So Far: balanced_accuracy - Train: 0.9507, Validation: 0.7445\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002049128507720536\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:39:07 | Computed configuration 11/30 in 0:00:40.556565\n",
      "25/06/2025-15:39:07 | Performance:             balanced_accuracy - Train: 0.9115, Validation: 0.6354\n",
      "25/06/2025-15:39:07 | Best Performance So Far: balanced_accuracy - Train: 0.9507, Validation: 0.7445\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006232012695368364\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:40:04 | Computed configuration 12/30 in 0:00:56.648569\n",
      "25/06/2025-15:40:04 | Performance:             balanced_accuracy - Train: 0.9507, Validation: 0.7445\n",
      "25/06/2025-15:40:04 | Best Performance So Far: balanced_accuracy - Train: 0.9507, Validation: 0.7445\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0019042182601686805\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:41:02 | Computed configuration 13/30 in 0:00:56.849007\n",
      "25/06/2025-15:41:02 | Performance:             balanced_accuracy - Train: 0.9526, Validation: 0.7709\n",
      "25/06/2025-15:41:02 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7709\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006918507923398173\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:41:53 | Computed configuration 14/30 in 0:00:51.507287\n",
      "25/06/2025-15:41:53 | Performance:             balanced_accuracy - Train: 0.9507, Validation: 0.7445\n",
      "25/06/2025-15:41:53 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7709\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0011326749264943903\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:42:50 | Computed configuration 15/30 in 0:00:56.421147\n",
      "25/06/2025-15:42:50 | Performance:             balanced_accuracy - Train: 0.9496, Validation: 0.7582\n",
      "25/06/2025-15:42:50 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7709\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.4490610027308467\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:43:45 | Computed configuration 16/30 in 0:00:54.296827\n",
      "25/06/2025-15:43:45 | Performance:             balanced_accuracy - Train: 0.9979, Validation: 0.6067\n",
      "25/06/2025-15:43:45 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7709\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0036542220050125103\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:44:38 | Computed configuration 17/30 in 0:00:52.325071\n",
      "25/06/2025-15:44:38 | Performance:             balanced_accuracy - Train: 0.9480, Validation: 0.7546\n",
      "25/06/2025-15:44:38 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7709\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0032557773941822364\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:45:26 | Computed configuration 18/30 in 0:00:47.734375\n",
      "25/06/2025-15:45:26 | Performance:             balanced_accuracy - Train: 0.9499, Validation: 0.7496\n",
      "25/06/2025-15:45:26 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7709\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001100500857874543\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:46:16 | Computed configuration 19/30 in 0:00:49.760955\n",
      "25/06/2025-15:46:16 | Performance:             balanced_accuracy - Train: 0.9496, Validation: 0.7582\n",
      "25/06/2025-15:46:16 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7709\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0020124243438942382\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:47:06 | Computed configuration 20/30 in 0:00:50.209756\n",
      "25/06/2025-15:47:06 | Performance:             balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "25/06/2025-15:47:06 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0021982704217897563\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:47:57 | Computed configuration 21/30 in 0:00:50.268627\n",
      "25/06/2025-15:47:57 | Performance:             balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "25/06/2025-15:47:57 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0017212829426857287\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:48:48 | Computed configuration 22/30 in 0:00:50.431148\n",
      "25/06/2025-15:48:48 | Performance:             balanced_accuracy - Train: 0.9517, Validation: 0.7709\n",
      "25/06/2025-15:48:48 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.013082947821001768\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:49:40 | Computed configuration 23/30 in 0:00:52.104718\n",
      "25/06/2025-15:49:40 | Performance:             balanced_accuracy - Train: 0.9537, Validation: 0.7633\n",
      "25/06/2025-15:49:40 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0235158663196492\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:50:32 | Computed configuration 24/30 in 0:00:51.678828\n",
      "25/06/2025-15:50:32 | Performance:             balanced_accuracy - Train: 0.9664, Validation: 0.6984\n",
      "25/06/2025-15:50:32 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0020319220000571407\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:51:24 | Computed configuration 25/30 in 0:00:51.314802\n",
      "25/06/2025-15:51:24 | Performance:             balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "25/06/2025-15:51:24 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002050879603646787\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:52:13 | Computed configuration 26/30 in 0:00:48.552216\n",
      "25/06/2025-15:52:13 | Performance:             balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "25/06/2025-15:52:13 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0020267534049030296\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:53:01 | Computed configuration 27/30 in 0:00:48.323798\n",
      "25/06/2025-15:53:01 | Performance:             balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "25/06/2025-15:53:01 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002057597031320469\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:53:50 | Computed configuration 28/30 in 0:00:48.389621\n",
      "25/06/2025-15:53:50 | Performance:             balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "25/06/2025-15:53:50 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.013806710664793906\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:54:41 | Computed configuration 29/30 in 0:00:49.943438\n",
      "25/06/2025-15:54:41 | Performance:             balanced_accuracy - Train: 0.9538, Validation: 0.7368\n",
      "25/06/2025-15:54:41 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002062002626860559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:55:30 | Computed configuration 30/30 in 0:00:48.734781\n",
      "25/06/2025-15:55:30 | Performance:             balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "25/06/2025-15:55:30 | Best Performance So Far: balanced_accuracy - Train: 0.9526, Validation: 0.7713\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-15:55:30 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-15:55:30 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0020124243438942382\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9526      |      0.7713      |\n",
      "|      f1_score     |       0.9539      |      0.3970      |\n",
      "|      accuracy     |       0.9526      |      0.8138      |\n",
      "|     precision     |       0.9361      |      0.3785      |\n",
      "|    sensitivity    |       0.9742      |      0.7264      |\n",
      "|    specificity    |       0.9309      |      0.8161      |\n",
      "|        auc        |       0.9526      |      0.7713      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:55:58 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9533      |      0.8876      |\n",
      "|      f1_score     |       0.9551      |      0.1920      |\n",
      "|      accuracy     |       0.9533      |      0.7811      |\n",
      "|     precision     |       0.9209      |      0.1062      |\n",
      "|    sensitivity    |       0.9919      |      1.0000      |\n",
      "|    specificity    |       0.9148      |      0.7752      |\n",
      "|        auc        |       0.9533      |      0.8876      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-15:55:59 | Computations in outer fold 2 took 21.811517499999997 minutes.\n",
      "25/06/2025-15:55:59 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 3\n",
      "*****************************************************************************************************\n",
      "25/06/2025-15:56:45 | Preparing data for outer fold 3...\n",
      "25/06/2025-15:56:45 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-15:56:45 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.9740 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:57:35 | Computed configuration 2/30 in 0:00:49.499682\n",
      "25/06/2025-15:57:35 | Performance:             balanced_accuracy - Train: 0.8841, Validation: 0.6006\n",
      "25/06/2025-15:57:35 | Best Performance So Far: balanced_accuracy - Train: 0.8841, Validation: 0.6006\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:57:37 | Computed configuration 3/30 in 0:00:01.607728\n",
      "25/06/2025-15:57:37 | Performance:             balanced_accuracy - Train: 0.9928, Validation: 0.5423\n",
      "25/06/2025-15:57:37 | Best Performance So Far: balanced_accuracy - Train: 0.8841, Validation: 0.6006\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-15:58:15 | Computed configuration 5/30 in 0:00:38.457208\n",
      "25/06/2025-15:58:15 | Performance:             balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "25/06/2025-15:58:15 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:59:05 | Computed configuration 6/30 in 0:00:49.704107\n",
      "25/06/2025-15:59:05 | Performance:             balanced_accuracy - Train: 0.9357, Validation: 0.6064\n",
      "25/06/2025-15:59:05 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:59:57 | Computed configuration 7/30 in 0:00:51.609012\n",
      "25/06/2025-15:59:57 | Performance:             balanced_accuracy - Train: 0.8660, Validation: 0.5947\n",
      "25/06/2025-15:59:57 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-15:59:58 | Computed configuration 8/30 in 0:00:01.516969\n",
      "25/06/2025-15:59:58 | Performance:             balanced_accuracy - Train: 0.9306, Validation: 0.6075\n",
      "25/06/2025-15:59:58 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-16:00:50 | Computed configuration 10/30 in 0:00:52.189467\n",
      "25/06/2025-16:00:50 | Performance:             balanced_accuracy - Train: 0.9954, Validation: 0.4875\n",
      "25/06/2025-16:00:50 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.015966509444436554\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:01:31 | Computed configuration 11/30 in 0:00:40.245369\n",
      "25/06/2025-16:01:31 | Performance:             balanced_accuracy - Train: 0.9196, Validation: 0.6335\n",
      "25/06/2025-16:01:31 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.015811047807506824\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:02:11 | Computed configuration 12/30 in 0:00:40.146690\n",
      "25/06/2025-16:02:11 | Performance:             balanced_accuracy - Train: 0.9188, Validation: 0.6382\n",
      "25/06/2025-16:02:11 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.4140721970646941\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:02:55 | Computed configuration 13/30 in 0:00:43.429884\n",
      "25/06/2025-16:02:55 | Performance:             balanced_accuracy - Train: 0.9921, Validation: 0.5328\n",
      "25/06/2025-16:02:55 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.04021843268046692\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:03:38 | Computed configuration 14/30 in 0:00:42.967152\n",
      "25/06/2025-16:03:38 | Performance:             balanced_accuracy - Train: 0.9480, Validation: 0.6006\n",
      "25/06/2025-16:03:38 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.01769222358137789\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:04:21 | Computed configuration 15/30 in 0:00:42.827522\n",
      "25/06/2025-16:04:21 | Performance:             balanced_accuracy - Train: 0.9233, Validation: 0.6030\n",
      "25/06/2025-16:04:21 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.029742109096960106\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:05:04 | Computed configuration 16/30 in 0:00:41.848137\n",
      "25/06/2025-16:05:04 | Performance:             balanced_accuracy - Train: 0.9388, Validation: 0.6020\n",
      "25/06/2025-16:05:04 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.07983801052708557\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:05:47 | Computed configuration 17/30 in 0:00:42.817549\n",
      "25/06/2025-16:05:47 | Performance:             balanced_accuracy - Train: 0.9687, Validation: 0.5600\n",
      "25/06/2025-16:05:47 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.013999478162280567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:06:27 | Computed configuration 18/30 in 0:00:40.467803\n",
      "25/06/2025-16:06:27 | Performance:             balanced_accuracy - Train: 0.9176, Validation: 0.6385\n",
      "25/06/2025-16:06:27 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014403570956222734\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:07:09 | Computed configuration 19/30 in 0:00:40.791967\n",
      "25/06/2025-16:07:09 | Performance:             balanced_accuracy - Train: 0.9180, Validation: 0.6382\n",
      "25/06/2025-16:07:09 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014867984794056512\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:07:50 | Computed configuration 20/30 in 0:00:40.604401\n",
      "25/06/2025-16:07:50 | Performance:             balanced_accuracy - Train: 0.9187, Validation: 0.6384\n",
      "25/06/2025-16:07:50 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014323322425049164\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:08:31 | Computed configuration 21/30 in 0:00:40.705203\n",
      "25/06/2025-16:08:31 | Performance:             balanced_accuracy - Train: 0.9180, Validation: 0.6385\n",
      "25/06/2025-16:08:31 | Best Performance So Far: balanced_accuracy - Train: 0.9190, Validation: 0.6422\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014071814103563281\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:09:12 | Computed configuration 22/30 in 0:00:41.183859\n",
      "25/06/2025-16:09:12 | Performance:             balanced_accuracy - Train: 0.9171, Validation: 0.6521\n",
      "25/06/2025-16:09:12 | Best Performance So Far: balanced_accuracy - Train: 0.9171, Validation: 0.6521\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.10306224095809909\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:09:56 | Computed configuration 23/30 in 0:00:43.571505\n",
      "25/06/2025-16:09:56 | Performance:             balanced_accuracy - Train: 0.9749, Validation: 0.5904\n",
      "25/06/2025-16:09:56 | Best Performance So Far: balanced_accuracy - Train: 0.9171, Validation: 0.6521\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014236238751597045\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:10:35 | Computed configuration 24/30 in 0:00:38.666647\n",
      "25/06/2025-16:10:35 | Performance:             balanced_accuracy - Train: 0.9176, Validation: 0.6385\n",
      "25/06/2025-16:10:35 | Best Performance So Far: balanced_accuracy - Train: 0.9171, Validation: 0.6521\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014114446560117544\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:11:14 | Computed configuration 25/30 in 0:00:38.232781\n",
      "25/06/2025-16:11:14 | Performance:             balanced_accuracy - Train: 0.9181, Validation: 0.6411\n",
      "25/06/2025-16:11:14 | Best Performance So Far: balanced_accuracy - Train: 0.9171, Validation: 0.6521\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.013916351700717249\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:11:51 | Computed configuration 26/30 in 0:00:37.087810\n",
      "25/06/2025-16:11:51 | Performance:             balanced_accuracy - Train: 0.9173, Validation: 0.6372\n",
      "25/06/2025-16:11:51 | Best Performance So Far: balanced_accuracy - Train: 0.9171, Validation: 0.6521\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.01406585603700476\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:12:33 | Computed configuration 27/30 in 0:00:41.520201\n",
      "25/06/2025-16:12:33 | Performance:             balanced_accuracy - Train: 0.9171, Validation: 0.6330\n",
      "25/06/2025-16:12:33 | Best Performance So Far: balanced_accuracy - Train: 0.9171, Validation: 0.6521\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014075097212988384\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:13:10 | Computed configuration 28/30 in 0:00:36.264043\n",
      "25/06/2025-16:13:10 | Performance:             balanced_accuracy - Train: 0.9171, Validation: 0.6372\n",
      "25/06/2025-16:13:10 | Best Performance So Far: balanced_accuracy - Train: 0.9171, Validation: 0.6521\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.031424278429742644\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:13:47 | Computed configuration 29/30 in 0:00:37.101831\n",
      "25/06/2025-16:13:47 | Performance:             balanced_accuracy - Train: 0.9409, Validation: 0.5960\n",
      "25/06/2025-16:13:47 | Best Performance So Far: balanced_accuracy - Train: 0.9171, Validation: 0.6521\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.01410528065587381\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:14:24 | Computed configuration 30/30 in 0:00:36.398655\n",
      "25/06/2025-16:14:24 | Performance:             balanced_accuracy - Train: 0.9181, Validation: 0.6337\n",
      "25/06/2025-16:14:24 | Best Performance So Far: balanced_accuracy - Train: 0.9171, Validation: 0.6521\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-16:14:24 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-16:14:24 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014071814103563281\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9171      |      0.6521      |\n",
      "|      f1_score     |       0.9240      |      0.1299      |\n",
      "|      accuracy     |       0.9171      |      0.5838      |\n",
      "|     precision     |       0.8777      |      0.0909      |\n",
      "|    sensitivity    |       0.9818      |      0.7242      |\n",
      "|    specificity    |       0.8524      |      0.5801      |\n",
      "|        auc        |       0.9171      |      0.6521      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-16:14:45 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.8658      |      0.7579      |\n",
      "|      f1_score     |       0.8679      |      0.1169      |\n",
      "|      accuracy     |       0.8658      |      0.6625      |\n",
      "|     precision     |       0.8547      |      0.0627      |\n",
      "|    sensitivity    |       0.8814      |      0.8586      |\n",
      "|    specificity    |       0.8502      |      0.6573      |\n",
      "|        auc        |       0.8658      |      0.7579      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-16:14:45 | Computations in outer fold 3 took 17.998931483333333 minutes.\n",
      "25/06/2025-16:14:45 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 4\n",
      "*****************************************************************************************************\n",
      "25/06/2025-16:15:54 | Preparing data for outer fold 4...\n",
      "25/06/2025-16:15:54 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-16:15:54 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.9740 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-16:16:46 | Computed configuration 2/30 in 0:00:50.951547\n",
      "25/06/2025-16:16:46 | Performance:             balanced_accuracy - Train: 0.8955, Validation: 0.6444\n",
      "25/06/2025-16:16:46 | Best Performance So Far: balanced_accuracy - Train: 0.8955, Validation: 0.6444\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:16:48 | Computed configuration 3/30 in 0:00:01.751317\n",
      "25/06/2025-16:16:48 | Performance:             balanced_accuracy - Train: 0.9936, Validation: 0.5245\n",
      "25/06/2025-16:16:48 | Best Performance So Far: balanced_accuracy - Train: 0.8955, Validation: 0.6444\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-16:17:31 | Computed configuration 5/30 in 0:00:42.825528\n",
      "25/06/2025-16:17:31 | Performance:             balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "25/06/2025-16:17:31 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:18:22 | Computed configuration 6/30 in 0:00:51.560144\n",
      "25/06/2025-16:18:22 | Performance:             balanced_accuracy - Train: 0.9433, Validation: 0.5595\n",
      "25/06/2025-16:18:22 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:19:16 | Computed configuration 7/30 in 0:00:54.030540\n",
      "25/06/2025-16:19:16 | Performance:             balanced_accuracy - Train: 0.8955, Validation: 0.6444\n",
      "25/06/2025-16:19:16 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:19:18 | Computed configuration 8/30 in 0:00:01.552847\n",
      "25/06/2025-16:19:18 | Performance:             balanced_accuracy - Train: 0.9358, Validation: 0.6610\n",
      "25/06/2025-16:19:18 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-16:20:11 | Computed configuration 10/30 in 0:00:53.059139\n",
      "25/06/2025-16:20:11 | Performance:             balanced_accuracy - Train: 0.9957, Validation: 0.4511\n",
      "25/06/2025-16:20:11 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.015966509444436554\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:20:54 | Computed configuration 11/30 in 0:00:42.450528\n",
      "25/06/2025-16:20:54 | Performance:             balanced_accuracy - Train: 0.9311, Validation: 0.6701\n",
      "25/06/2025-16:20:54 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.017576733651570132\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:21:45 | Computed configuration 12/30 in 0:00:50.931858\n",
      "25/06/2025-16:21:45 | Performance:             balanced_accuracy - Train: 0.9501, Validation: 0.5515\n",
      "25/06/2025-16:21:45 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.08229530985262312\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:22:39 | Computed configuration 13/30 in 0:00:54.273861\n",
      "25/06/2025-16:22:39 | Performance:             balanced_accuracy - Train: 0.9736, Validation: 0.5376\n",
      "25/06/2025-16:22:39 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.03320542032863933\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:23:22 | Computed configuration 14/30 in 0:00:41.884016\n",
      "25/06/2025-16:23:22 | Performance:             balanced_accuracy - Train: 0.9438, Validation: 0.6414\n",
      "25/06/2025-16:23:22 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0646364056434986\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:24:04 | Computed configuration 15/30 in 0:00:42.482417\n",
      "25/06/2025-16:24:04 | Performance:             balanced_accuracy - Train: 0.9657, Validation: 0.5373\n",
      "25/06/2025-16:24:04 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.01383328933148954\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:24:45 | Computed configuration 16/30 in 0:00:40.532601\n",
      "25/06/2025-16:24:45 | Performance:             balanced_accuracy - Train: 0.9315, Validation: 0.6701\n",
      "25/06/2025-16:24:45 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.026361511425001333\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:25:27 | Computed configuration 17/30 in 0:00:41.201841\n",
      "25/06/2025-16:25:27 | Performance:             balanced_accuracy - Train: 0.9403, Validation: 0.6591\n",
      "25/06/2025-16:25:27 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.015871338759759247\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:26:08 | Computed configuration 18/30 in 0:00:40.996390\n",
      "25/06/2025-16:26:08 | Performance:             balanced_accuracy - Train: 0.9311, Validation: 0.6701\n",
      "25/06/2025-16:26:08 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.031071386110349188\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:26:50 | Computed configuration 19/30 in 0:00:41.495057\n",
      "25/06/2025-16:26:50 | Performance:             balanced_accuracy - Train: 0.9440, Validation: 0.6410\n",
      "25/06/2025-16:26:50 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.020279263671903983\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:27:31 | Computed configuration 20/30 in 0:00:41.089109\n",
      "25/06/2025-16:27:31 | Performance:             balanced_accuracy - Train: 0.9317, Validation: 0.6668\n",
      "25/06/2025-16:27:31 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.043024302747082174\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:28:14 | Computed configuration 21/30 in 0:00:41.911942\n",
      "25/06/2025-16:28:14 | Performance:             balanced_accuracy - Train: 0.9507, Validation: 0.6107\n",
      "25/06/2025-16:28:14 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.004386127752738684\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:28:53 | Computed configuration 22/30 in 0:00:38.631743\n",
      "25/06/2025-16:28:53 | Performance:             balanced_accuracy - Train: 0.8948, Validation: 0.6444\n",
      "25/06/2025-16:28:53 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.22536378673314705\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:29:39 | Computed configuration 23/30 in 0:00:45.634986\n",
      "25/06/2025-16:29:39 | Performance:             balanced_accuracy - Train: 0.9881, Validation: 0.5437\n",
      "25/06/2025-16:29:39 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.015628066209326764\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:30:24 | Computed configuration 24/30 in 0:00:44.787224\n",
      "25/06/2025-16:30:24 | Performance:             balanced_accuracy - Train: 0.9312, Validation: 0.6701\n",
      "25/06/2025-16:30:24 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.01582875364300493\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:31:09 | Computed configuration 25/30 in 0:00:44.464117\n",
      "25/06/2025-16:31:09 | Performance:             balanced_accuracy - Train: 0.9311, Validation: 0.6701\n",
      "25/06/2025-16:31:09 | Best Performance So Far: balanced_accuracy - Train: 0.9316, Validation: 0.6701\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.02452833277003635\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:31:56 | Computed configuration 26/30 in 0:00:46.906616\n",
      "25/06/2025-16:31:56 | Performance:             balanced_accuracy - Train: 0.9335, Validation: 0.6704\n",
      "25/06/2025-16:31:56 | Best Performance So Far: balanced_accuracy - Train: 0.9335, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.015427627970756653\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:32:39 | Computed configuration 27/30 in 0:00:42.484411\n",
      "25/06/2025-16:32:39 | Performance:             balanced_accuracy - Train: 0.9311, Validation: 0.6701\n",
      "25/06/2025-16:32:39 | Best Performance So Far: balanced_accuracy - Train: 0.9335, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.024044707430448165\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:33:21 | Computed configuration 28/30 in 0:00:41.596784\n",
      "25/06/2025-16:33:21 | Performance:             balanced_accuracy - Train: 0.9347, Validation: 0.6515\n",
      "25/06/2025-16:33:21 | Best Performance So Far: balanced_accuracy - Train: 0.9335, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.024357313631967744\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:34:04 | Computed configuration 29/30 in 0:00:42.949138\n",
      "25/06/2025-16:34:04 | Performance:             balanced_accuracy - Train: 0.9346, Validation: 0.6512\n",
      "25/06/2025-16:34:04 | Best Performance So Far: balanced_accuracy - Train: 0.9335, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.03545059314057564\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:34:49 | Computed configuration 30/30 in 0:00:44.533958\n",
      "25/06/2025-16:34:49 | Performance:             balanced_accuracy - Train: 0.9456, Validation: 0.6155\n",
      "25/06/2025-16:34:49 | Best Performance So Far: balanced_accuracy - Train: 0.9335, Validation: 0.6704\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-16:34:49 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-16:34:49 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.02452833277003635\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9335      |      0.6704      |\n",
      "|      f1_score     |       0.9385      |      0.1750      |\n",
      "|      accuracy     |       0.9335      |      0.6817      |\n",
      "|     precision     |       0.8872      |      0.1207      |\n",
      "|    sensitivity    |       0.9982      |      0.6583      |\n",
      "|    specificity    |       0.8689      |      0.6824      |\n",
      "|        auc        |       0.9335      |      0.6704      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-16:35:13 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9271      |      0.8448      |\n",
      "|      f1_score     |       0.9319      |      0.1984      |\n",
      "|      accuracy     |       0.9271      |      0.8159      |\n",
      "|     precision     |       0.8742      |      0.1119      |\n",
      "|    sensitivity    |       0.9978      |      0.8753      |\n",
      "|    specificity    |       0.8565      |      0.8143      |\n",
      "|        auc        |       0.9271      |      0.8448      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-16:35:14 | Computations in outer fold 4 took 19.32379578333333 minutes.\n",
      "25/06/2025-16:35:14 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Outer Cross validation Fold 5\n",
      "*****************************************************************************************************\n",
      "25/06/2025-16:36:48 | Preparing data for outer fold 5...\n",
      "25/06/2025-16:36:48 | Preparing Hyperparameter Optimization...\n",
      "25/06/2025-16:36:48 | Running Dummy Estimator...\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.9740 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.3688610897684593\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0026570059126609985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-16:37:42 | Computed configuration 2/30 in 0:00:52.929484\n",
      "25/06/2025-16:37:42 | Performance:             balanced_accuracy - Train: 0.9417, Validation: 0.7836\n",
      "25/06/2025-16:37:42 | Best Performance So Far: balanced_accuracy - Train: 0.9417, Validation: 0.7836\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5123132299514567\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:37:43 | Computed configuration 3/30 in 0:00:01.680507\n",
      "25/06/2025-16:37:43 | Performance:             balanced_accuracy - Train: 0.9942, Validation: 0.5839\n",
      "25/06/2025-16:37:43 | Best Performance So Far: balanced_accuracy - Train: 0.9417, Validation: 0.7836\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.05212780929227985\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.014972646975855559\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-16:38:26 | Computed configuration 5/30 in 0:00:42.998035\n",
      "25/06/2025-16:38:26 | Performance:             balanced_accuracy - Train: 0.9482, Validation: 0.7913\n",
      "25/06/2025-16:38:26 | Best Performance So Far: balanced_accuracy - Train: 0.9482, Validation: 0.7913\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.006301171989311478\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:39:17 | Computed configuration 6/30 in 0:00:50.473050\n",
      "25/06/2025-16:39:17 | Performance:             balanced_accuracy - Train: 0.9531, Validation: 0.5841\n",
      "25/06/2025-16:39:17 | Best Performance So Far: balanced_accuracy - Train: 0.9482, Validation: 0.7913\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.001140444703947033\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:40:08 | Computed configuration 7/30 in 0:00:51.392592\n",
      "25/06/2025-16:40:08 | Performance:             balanced_accuracy - Train: 0.9417, Validation: 0.7836\n",
      "25/06/2025-16:40:08 | Best Performance So Far: balanced_accuracy - Train: 0.9482, Validation: 0.7913\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.021829691199987622\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:40:10 | Computed configuration 8/30 in 0:00:01.501984\n",
      "25/06/2025-16:40:10 | Performance:             balanced_accuracy - Train: 0.9516, Validation: 0.7320\n",
      "25/06/2025-16:40:10 | Best Performance So Far: balanced_accuracy - Train: 0.9482, Validation: 0.7913\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=deviance\",\n",
      "        \"learning_rate=0.0033696415113161483\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.5962926931408471\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 154, in fit\n",
      "    curr_test_fold, curr_train_fold = InnerFoldManager.fit_and_score(job_data)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\processing\\inner_folds.py\", line 350, in fit_and_score\n",
      "    pipe.fit(job.train_data.X, job.train_data.y, **job.train_data.cv_kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_pipeline.py\", line 162, in fit\n",
      "    self._final_estimator.fit(X, y, **kwargs)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\photonai\\base\\photon_elements.py\", line 459, in fit\n",
      "    obj.fit(X, y)\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Shared-PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/06/2025-16:41:00 | Computed configuration 10/30 in 0:00:50.029240\n",
      "25/06/2025-16:41:00 | Performance:             balanced_accuracy - Train: 0.9949, Validation: 0.5491\n",
      "25/06/2025-16:41:00 | Best Performance So Far: balanced_accuracy - Train: 0.9482, Validation: 0.7913\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.002049128507720536\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:41:38 | Computed configuration 11/30 in 0:00:37.733152\n",
      "25/06/2025-16:41:38 | Performance:             balanced_accuracy - Train: 0.9414, Validation: 0.8262\n",
      "25/06/2025-16:41:38 | Best Performance So Far: balanced_accuracy - Train: 0.9414, Validation: 0.8262\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0014666036255122862\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:42:30 | Computed configuration 12/30 in 0:00:51.595053\n",
      "25/06/2025-16:42:30 | Performance:             balanced_accuracy - Train: 0.9417, Validation: 0.7836\n",
      "25/06/2025-16:42:30 | Best Performance So Far: balanced_accuracy - Train: 0.9414, Validation: 0.8262\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.08229530985262312\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=SMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:43:23 | Computed configuration 13/30 in 0:00:52.758938\n",
      "25/06/2025-16:43:23 | Performance:             balanced_accuracy - Train: 0.9755, Validation: 0.6292\n",
      "25/06/2025-16:43:23 | Best Performance So Far: balanced_accuracy - Train: 0.9414, Validation: 0.8262\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0017932219207202904\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:10 | Computed configuration 14/30 in 0:00:47.115027\n",
      "25/06/2025-16:44:10 | Performance:             balanced_accuracy - Train: 0.9524, Validation: 0.5590\n",
      "25/06/2025-16:44:10 | Best Performance So Far: balanced_accuracy - Train: 0.9414, Validation: 0.8262\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0022559924369785905\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:12 | Computed configuration 15/30 in 0:00:01.453116\n",
      "25/06/2025-16:44:12 | Performance:             balanced_accuracy - Train: 0.9440, Validation: 0.8262\n",
      "25/06/2025-16:44:12 | Best Performance So Far: balanced_accuracy - Train: 0.9414, Validation: 0.8262\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0021960445588725262\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:14 | Computed configuration 16/30 in 0:00:01.454111\n",
      "25/06/2025-16:44:14 | Performance:             balanced_accuracy - Train: 0.9440, Validation: 0.8262\n",
      "25/06/2025-16:44:14 | Best Performance So Far: balanced_accuracy - Train: 0.9414, Validation: 0.8262\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0022567580514200507\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:16 | Computed configuration 17/30 in 0:00:01.460094\n",
      "25/06/2025-16:44:16 | Performance:             balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "25/06/2025-16:44:16 | Best Performance So Far: balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0041836415781149276\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:18 | Computed configuration 18/30 in 0:00:01.474091\n",
      "25/06/2025-16:44:18 | Performance:             balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "25/06/2025-16:44:18 | Best Performance So Far: balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.003834738386483758\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:19 | Computed configuration 19/30 in 0:00:01.465050\n",
      "25/06/2025-16:44:19 | Performance:             balanced_accuracy - Train: 0.9440, Validation: 0.8262\n",
      "25/06/2025-16:44:19 | Best Performance So Far: balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.005525705762727965\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:21 | Computed configuration 20/30 in 0:00:01.441176\n",
      "25/06/2025-16:44:21 | Performance:             balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "25/06/2025-16:44:21 | Best Performance So Far: balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.005878440172064993\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:23 | Computed configuration 21/30 in 0:00:01.475087\n",
      "25/06/2025-16:44:23 | Performance:             balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "25/06/2025-16:44:23 | Best Performance So Far: balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.009086673066671153\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:25 | Computed configuration 22/30 in 0:00:01.482036\n",
      "25/06/2025-16:44:25 | Performance:             balanced_accuracy - Train: 0.9440, Validation: 0.8455\n",
      "25/06/2025-16:44:25 | Best Performance So Far: balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.010862498659400656\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:26 | Computed configuration 23/30 in 0:00:01.500987\n",
      "25/06/2025-16:44:26 | Performance:             balanced_accuracy - Train: 0.9455, Validation: 0.8455\n",
      "25/06/2025-16:44:26 | Best Performance So Far: balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.017184628853978822\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:28 | Computed configuration 24/30 in 0:00:01.496998\n",
      "25/06/2025-16:44:28 | Performance:             balanced_accuracy - Train: 0.9505, Validation: 0.7913\n",
      "25/06/2025-16:44:28 | Best Performance So Far: balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.009053946425590584\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:30 | Computed configuration 25/30 in 0:00:01.477051\n",
      "25/06/2025-16:44:30 | Performance:             balanced_accuracy - Train: 0.9440, Validation: 0.8455\n",
      "25/06/2025-16:44:30 | Best Performance So Far: balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.01088593208884201\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:32 | Computed configuration 26/30 in 0:00:01.468074\n",
      "25/06/2025-16:44:32 | Performance:             balanced_accuracy - Train: 0.9455, Validation: 0.8455\n",
      "25/06/2025-16:44:32 | Best Performance So Far: balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.005886962497526031\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:34 | Computed configuration 27/30 in 0:00:01.492013\n",
      "25/06/2025-16:44:34 | Performance:             balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "25/06/2025-16:44:34 | Best Performance So Far: balanced_accuracy - Train: 0.9440, Validation: 0.8475\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.012160382397380258\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:35 | Computed configuration 28/30 in 0:00:01.477084\n",
      "25/06/2025-16:44:35 | Performance:             balanced_accuracy - Train: 0.9483, Validation: 0.8544\n",
      "25/06/2025-16:44:35 | Best Performance So Far: balanced_accuracy - Train: 0.9483, Validation: 0.8544\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.9390503322401108\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:44:37 | Computed configuration 29/30 in 0:00:01.406268\n",
      "25/06/2025-16:44:37 | Performance:             balanced_accuracy - Train: 0.9960, Validation: 0.5761\n",
      "25/06/2025-16:44:37 | Best Performance So Far: balanced_accuracy - Train: 0.9483, Validation: 0.8544\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.004994264078376853\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomOverSampler\"\n",
      "    ]\n",
      "}\n",
      "25/06/2025-16:45:16 | Computed configuration 30/30 in 0:00:38.979781\n",
      "25/06/2025-16:45:16 | Performance:             balanced_accuracy - Train: 0.9414, Validation: 0.8262\n",
      "25/06/2025-16:45:16 | Best Performance So Far: balanced_accuracy - Train: 0.9483, Validation: 0.8544\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "25/06/2025-16:45:17 | Hyperparameter Optimization finished. Now finding best configuration .... \n",
      "25/06/2025-16:45:17 | 30\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "BEST_CONFIG \n",
      "-----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.012160382397380258\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=RandomUnderSampler\"\n",
      "    ]\n",
      "}\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "VALIDATION PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9483      |      0.8544      |\n",
      "|      f1_score     |       0.9516      |      0.5184      |\n",
      "|      accuracy     |       0.9483      |      0.8039      |\n",
      "|     precision     |       0.9128      |      0.4640      |\n",
      "|    sensitivity    |       0.9958      |      0.9076      |\n",
      "|    specificity    |       0.9007      |      0.8012      |\n",
      "|        auc        |       0.9483      |      0.8544      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-16:45:17 | Calculating best model performance on test set...\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "TEST PERFORMANCE\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "+-------------------+-------------------+------------------+\n",
      "|       METRIC      | PERFORMANCE TRAIN | PERFORMANCE TEST |\n",
      "+-------------------+-------------------+------------------+\n",
      "| balanced_accuracy |       0.9389      |      0.5771      |\n",
      "|      f1_score     |       0.9423      |      0.1203      |\n",
      "|      accuracy     |       0.9389      |      0.9165      |\n",
      "|     precision     |       0.8923      |      0.0829      |\n",
      "|    sensitivity    |       0.9983      |      0.2191      |\n",
      "|    specificity    |       0.8795      |      0.9351      |\n",
      "|        auc        |       0.9389      |      0.5771      |\n",
      "+-------------------+-------------------+------------------+\n",
      "25/06/2025-16:45:17 | Computations in outer fold 5 took 8.4839501 minutes.\n",
      "25/06/2025-16:45:17 | Writing results to project folder...\n",
      "\n",
      "*****************************************************************************************************\n",
      "Finished all outer fold computations.\n",
      "25/06/2025-16:46:58 | Now analysing the final results...\n",
      "25/06/2025-16:46:58 | Computing dummy metrics...\n",
      "25/06/2025-16:46:58 | Computing mean and std for all outer fold metrics...\n",
      "25/06/2025-16:46:58 | Find best config across outer folds...\n",
      "25/06/2025-16:46:58 | Save final results...\n",
      "25/06/2025-16:46:58 | Writing results to project folder...\n",
      "25/06/2025-16:48:46 | Prepare Hyperpipe.optimum pipe with best config..\n",
      "25/06/2025-16:48:46 | Fitting best model...\n",
      "25/06/2025-16:49:24 | Saved best model to file.\n",
      "25/06/2025-16:49:24 | Summarizing results...\n",
      "25/06/2025-16:49:24 | Write predictions to files...\n",
      "25/06/2025-16:49:25 | Write summary...\n",
      "*****************************************************************************************************\n",
      "\n",
      "ANALYSIS INFORMATION ================================================================================ \n",
      "Project Folder: ./analysis/participant2_15s\\5FinalPipelineCIFSGB_results_2025-06-25_15-08-37,\n",
      "Computation Time: 2025-06-25 15:08:37.414454 - 2025-06-25 16:46:58.411137\n",
      "Duration: 1:38:20.996683\n",
      "Optimized for: balanced_accuracy\n",
      "Hyperparameter Optimizer: sk_opt\n",
      "\n",
      "DUMMY RESULTS =======================================================================================\n",
      "+-------------------+--------+\n",
      "| PERFORMANCE DUMMY |        |\n",
      "+-------------------+--------+\n",
      "| balanced_accuracy | 0.5000 |\n",
      "|      f1_score     | 0.0000 |\n",
      "|      accuracy     | 0.9740 |\n",
      "|     precision     | 0.0000 |\n",
      "|    sensitivity    | 0.0000 |\n",
      "|    specificity    | 1.0000 |\n",
      "|        auc        | 0.5000 |\n",
      "+-------------------+--------+\n",
      "\n",
      "AVERAGE PERFORMANCE ACROSS OUTER FOLDS ==============================================================\n",
      "+-------------------+---------------+--------------+-----------+----------+\n",
      "|    Metric Name    | Training Mean | Training Std | Test Mean | Test Std |\n",
      "+-------------------+---------------+--------------+-----------+----------+\n",
      "| balanced_accuracy |    0.923798   |   0.030249   |  0.70021  | 0.170646 |\n",
      "|      f1_score     |    0.926846   |   0.030474   |  0.133948 | 0.05732  |\n",
      "|      accuracy     |    0.923798   |   0.030249   |  0.678494 | 0.244853 |\n",
      "|     precision     |    0.887173   |   0.02203    |  0.07709  | 0.032734 |\n",
      "|    sensitivity    |    0.97083    |   0.044962   |  0.723114 | 0.274164 |\n",
      "|    specificity    |    0.876766   |   0.022848   |  0.677307 | 0.252482 |\n",
      "|        auc        |    0.923798   |   0.030249   |  0.70021  | 0.170646 |\n",
      "+-------------------+---------------+--------------+-----------+----------+\n",
      "\n",
      "BEST HYPERPARAMETER CONFIGURATION ===================================================================\n",
      "{\n",
      "    \"GradientBoostingClassifier\": [\n",
      "        \"loss=exponential\",\n",
      "        \"learning_rate=0.0020124243438942382\"\n",
      "    ],\n",
      "    \"ImbalancedDataTransformer\": [\n",
      "        \"method_name=BorderlineSMOTE\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "\n",
      "+--------+-------------------+----------+----------+-----------+-------------+-------------+--------+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| fold # | balanced_accuracy | f1_score | accuracy | precision | sensitivity | specificity |  auc   |                                                                  Best Hyperparameter Config                                                                 |\n",
      "+--------+-------------------+----------+----------+-----------+-------------+-------------+--------+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|   1    |       0.4336      |  0.0422  |  0.2165  |   0.0218  |    0.6626   |    0.2046   | 0.4336 |  {'ImbalancedDataTransformer': ['method_name=BorderlineSMOTE'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.0017212829426857287']}  |\n",
      "|   2*   |       0.8876      |  0.1920  |  0.7811  |   0.1062  |    1.0000   |    0.7752   | 0.8876 |  {'ImbalancedDataTransformer': ['method_name=BorderlineSMOTE'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.0020124243438942382']}  |\n",
      "|   3    |       0.7579      |  0.1169  |  0.6625  |   0.0627  |    0.8586   |    0.6573   | 0.7579 |  {'ImbalancedDataTransformer': ['method_name=RandomOverSampler'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.014071814103563281']} |\n",
      "|   4    |       0.8448      |  0.1984  |  0.8159  |   0.1119  |    0.8753   |    0.8143   | 0.8448 |  {'ImbalancedDataTransformer': ['method_name=RandomOverSampler'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.02452833277003635']}  |\n",
      "|   5    |       0.5771      |  0.1203  |  0.9165  |   0.0829  |    0.2191   |    0.9351   | 0.5771 | {'ImbalancedDataTransformer': ['method_name=RandomUnderSampler'], 'GradientBoostingClassifier': ['loss=exponential', 'learning_rate=0.012160382397380258']} |\n",
      "+--------+-------------------+----------+----------+-----------+-------------+-------------+--------+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "PHOTONAI 2.5.2 ======================================================================================\n",
      "Your results are stored in ./analysis/participant2_15s\\5FinalPipelineCIFSGB_results_2025-06-25_15-08-37\n",
      "Go to https://explorer.photon-ai.com and upload your photonai_results.json for convenient result visualization! \n",
      "For more info and documentation visit https://www.photon-ai.com\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8cAAANpCAYAAAAmGUvEAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAA8Z1JREFUeJzs3QWYVNX7wPGXXro7pUG6U1LKBhUxEAVMGgRBAZVUQkEFFSVUBEUQle7ubpTuzqXr/7zn95917szs7szO7O7E9+Mzz3Dv3Hvuubss7nvPe96T4MGDBw8EAAAAAIAQljC+OwAAAAAAQHwjOAYAAAAAhDyCYwAAAABAyCM4BgAAAACEPIJjAAAAAEDIIzgGAAAAAIQ8gmMAAAAAQMgjOAYAAAAAhLzE8d2BUJW8bLv47gIA+FTHAR3iuwsA4FODmxQWf+Wvv0ve2PxVfHcBiDFGjgEAAAAAIY/gGAAAAAAQ8kirBgAAAAJNAsa4AF/jpwoAAAAAEPIIjgEAAAAAIY+0agAAACDQJEgQ3z0Agg4jxwAAAACAkEdwDAAAAAAIeaRVAwAAAIGGatWAz/FTBQAAAAAIeQTHAAAAAICQR1o1AAAAEGioVg34HCPHAAAAAICQR3AMAAAAAAh5pFUDAAAAgYZq1YDP8VMFAAAAAAh5BMcAAAAAgJBHWjUAAAAQaKhWDfgcI8cAAAAAgJBHcAwAAAAACHmkVQMAAACBhmrVgM/xUwUAAAAACHkExwAAAACAkEdaNQAAABBoqFYN+BwjxwAAAACAkEdwDAAAAAAIeaRVAwAAAIGGatWAz/FTBQAAAAAIeQTHAAAAAICQR1o1AAAAEGioVg34HCPHAAAAAICQR3AMAAAAAAh5pFUDAAAAgYZq1YDP8VMFAAAAAAh5BMcAAAAAgJBHWjUAAAAQaKhWDfgcI8cAAAAAgJBHcAwAAAAACHmkVQMAAACBhmrVgM/xUwUAAAAACHkExwAAAACAkEdaNQAAABBoSKsGfI6fKgAAAABAyCM4BgAAAACEPNKqAQAAgECTMEF89wAIOowcAwAAAABCHsExAAAAACDkkVYNAAAABBqqVQM+x08VAAAAACDkERwDAAAAAEIeadUAAABAoElAtWrA1xg5BgAAAACEPIJjAAAAAEDII60aAAAACDRUqwZ8jp8qAAAAAEDIIzgGAAAAAIQ80qoBAACAQEO1asDnGDkGAAAAAIQ8gmMAAAAAQMgjrRoAAAAINFSrBnyOnyoAAAAAQMgjOAYAAAAAhDzSqgEAAIBAQ7VqwOcYOQYAAAAAhDyCYwAAAABAyCOtGgAAAAg0VKsGfI6fKgAAAABAyCM4BgAAAACEPNKqAQAAgEBDtWrA5xg5BgAAAACEPIJjAAAAAEDII60aAAAACDRUqwZ8jp8qAAAAAEDIIzgGAAAAAIQ80qoBAACAQEO1asDnGDkGAAAAAIQ8gmMAAAAAQMgjrRoAAAAINFSrBnyO4BgAAABAwLl79648+eSTsn//frO9d+/eGLd17do1mT59uixfvlx2794tFy9elAcPHkimTJmkWLFiUr9+fXn88ccladKkXvV527Zt8ueff8rGjRvl5MmTEh4eLsmTJ5c8efJI5cqV5ZlnnpHChQt7dQ3uJeYSPNDWEeeSl20X310AAJ/qOKBDfHcBAHxqcBPvfrGPTckf/0r80Y0Zcfc77nfffSfDhg2L2I5pcPzXX39J//795fLly1Eelz17dhk6dKhUqFDB42ucO3dOevfuLYsWLYr22ObNm0uvXr0kLCzM4+twL94hHwMAAAAIxLRqf3zFkfXr18vIkSO9bufzzz+X9957L9oATOnoaMuWLWXixIkeXePIkSPy7LPPuhVMql9//VWee+45uXDhgkfX4V4mirdIqwYAAAAQMPbs2SPt2rWTO3fueNWOBlPffPONZV/q1KmlQYMGUqBAAbl165bs2LFDlixZIvfu3TOf6/uAAQNM6nDNmjWjvYamGrdu3doEcPZKly4t1apVk3Tp0pnP5s2bJydOnIj4/J9//pGOHTvKuHHjJHHi6EM27uWeR/cSGdKq4wlp1QCCDWnVAIKNX6dVPzFK/NGNv9+J1fZ1nmvbtm3l0qVLTp95klZ96NAheeKJJ+T27dsR+x599FEZOHCgpEmTxnKszmnW4O7ff/+N2KeB4Pz5852OddSzZ0+ZNm1axLYeP3jwYKlXr57lOA3uNCD86quv5P79+xH7O3ToIO+++y73MtC39xIZ0qoBAACAQJMggX++YtFvv/0mL730ksvA2FPDhw+3BGA1atSQESNGuAyqdLTyp59+kty5c0fs0z6MHz8+2hFuLSZlo6OmX375pVMwqRIlSmQCxx49elj262jrlStXuJc0vruXqBAcAwAAAPBbms6rRZ20CJR94BRTR48eNam/NlrpWAs/aVAXmfTp05t5sAnsHgBMmDDBVFOOjAZp9iOnOve2SpUqUfatVatWUqdOnYjtq1evmgCQe/HdvUSF4BgAAACA39FgbMqUKdKwYUOZOnWq5bN8+fLFuN0//vjDLAdko+1rxePolCxZUqpXr24J2pcuXeryWA3O5syZ4xQsuuOtt96ybM+cOTPSY7kX8eheokNwDAAAAASaIK9WrUWXmjZtKh9++KFZOshepUqVTBXkmHIMnBo1auT2uY7H6vzWyKpp37hxI2K7aNGibgf0ZcqUsQSFOrf2wIEDLo/lXjy7l+gQHAMAAADwKxoc796927JP02y7du1qUny18FJMaGrvrl27IrY1HbdixYpun1+5cmXL9vLlyy2jnTZr1651Cug94dinZcuWOR3DvXh+L9EhOAYAAADg16pWrWrSbt94440o56BGR5cVsp87mzNnTkmbNq3b5+tSQSlTprQEdYcPH3ZZwMreww8/7FE/ixcvbtnevn270zHci+f3Eh2CYwAAACDQhEi16mLFisno0aPNaHHBggW9bs8xpfehhx7yuA0NxOwdPHjQ6RhNH/bmOvYVmCO7Bvfi+b1Eh+AYAAAAgF9JliyZCYh1+aC6dev6rN3jx49btrNly+ZxG1mzZrVsnzhxwrJ99+5dOXPmjFfXie4ainvx/DrRITgGAAAA4HfBsaZS+9qFCxcs2xkzZvS4jQwZMkTZpm47znd1PMfTa+j6vfZpx66uy71kiLJNdyT2+AwAAAAA8cuHlaFDiQZm9lKlSuVxG/ZzW9Xly5ejvEZYWJgkSZLEq2togKrzaO3n4XIvnt2LOwiOAQAAAPhEvXr1ovx84cKFEt9VsO2lSJHC4zaSJ08eZZuO247Hu8NVv27evGkJKLkXz+7FHTxyAgAAABASbt++bdmOSeVrx3N0Xm5U10ic2PPxSFf9iu463EuiKK/hDkaOAQAAgEATC5WhfSG+R4ajc+/ePa+DsIQJreOLjvNnHbcdj4/JNVy1y714di/uYOQYAAAAQEhwnC8bk9FFx3Mc23QcXXUM/Nxx584dp31JkyaN8rrcy90o23QHwTEAAACAkOAYMLkK3KLjeI5joOe4HZNruAoOHfvOvXh2L+4grRoAAAAIMAn8NK3a36VJk8ayff36dY/buHbtWpRVkmPjGq4qOHMvnt2LOxg5BgAAABAS0qdP7/VyP1euXIlyTV7Ha+iIpqfBnuM1NJh0HAnlXjy7F3cQHAMAAAAICdmzZ7dsnz9/3uM2zp07Z9nOlCmTU/DnODLq6XXOnj0b5TUU9+LZvbiD4BgAAAAIwLRqf3z5u1y5clm2jx075nEbjufky5fP6ZjcuXN7dR3H4x966CGnY7gXz+8lOgTHAAAAAEJCkSJFLNv79+/36Pzw8HA5ffp0xLY+EChQoEC019m3b59H13HslzvX4F5OR3sv0SE4BgAAABASdBQ0Q4YMEduXLl2SI0eOuH3+9u3bLevnFi1aVJInT+50XKlSpSzb27Zt86ifW7dutWyXLVvW6RjuxfN7iQ7BMQAAABBoEvjpKwBUq1bNsr106VK3z122bJllu2rVqm5dY+XKlW6vEazFqOwDykSJEknlypXdug73EvW9RIfgGAAAAEDIaNCggWV7ypQp8uDBg2jPu3nzpvz111+WfU2aNHF5rM6rLVy4sKXA1MKFC93q37Rp0yxrA9esWVNSp07t8ljuRTy6l+gQHAMAAAAIGXXq1LFUMt67d69MnDgx2vNGjBhhqYhcvHhxKVmyZKTHP/vss5btIUOGOC035OjEiRPyzTffWPY9//zzkR7PvYjH9xIVgmMAAAAAIUPX2G3Tpo1l36BBg6IcDZ00aZKMHTvWsq9jx45RXkcDwcyZM0ds6xzaDh06mOJRrmiA99Zbb5n5tjYa5NWrV4978eG9RIXgGAAAAAgw8b1kU6Au5WTz8ssvm6JNNpr6++6770q/fv3k0KFDZp+m9O7Zs0e6desmH330kVMKcO3ataO8hhaE6tWrl2Xf6tWrzSjsrFmzTDqwunbtmvz+++/yzDPPmNFSmyRJkjhdl3sRr+8lKgkeuJPIDZ9LXrZdfHcBAHyq44AO8d0FAPCpwU3+m2fpb1I9P178UfhvreLsWo7L/9gHY+44evSoCcZOnTrl9FlYWJipfnz79m2nzwoWLCi//PKLpE2b1q3rfP75507pxUofJqRKlUquXr3q8ryPP/5YXnjhBe4llu7FFUaOAQAAAIQcXT5o/PjxLtfD1ZFQVwFYmTJl5Mcff/QoAOvcubO0a9fOVGq2p2OUroJJTS/+5JNP3A4muReJ0b24QnAMAAAABJj4Tp8O9LRq+0rM06dPN0Ffjhw5Ij0uZ86cJq1YRyYzZszo8XXat29v0o0feeQRk2LsigacDRs2NBWemzdv7vE1uJeM4i3SquMJadUAgg1p1QCCjT+nVaduPkH80dVfX5VAtn37djlw4ICcPXvWpO9myJBBSpQoYZYySpjQN+OKuvbvhg0b5MyZM6ZgVcqUKc1oably5bwe+bTHvXiO4DieEBwDCDYExwCCDcFx6AXHCG2J47sDAAAAADwTiCnMgL9jzjEAAAAAIOQRHAMAAAAAQh5p1QAAAECAIa0a8D1GjgEAAAAAIY/gGAAAAAAQ8kirBgAAAAINWdWAzzFyDAAAAAAIeQTHAAAAAICQR1o1AAAAEGCoVg34HiPHAAAAAICQR3AMAAAAAAh5pFUDAAAAAYa0asD3GDkGAAAAAIQ8gmMAAAAAQMgjrRoAAAAIMKRVA77HyDEAAAAAIOQRHAMAAAAAQh5p1QAAAECAIa0a8D1GjgEAAAAAIY/gGAAAAAAQ8kirBgAAAAINWdWAzzFyDAAAAAAIeQTHAAAAAICQR1o1AAAAEGCoVg34HiPHAAAAAICQR3AMAAAAAAh5pFUDAAAAAYa0asD3GDkGAAAAAIQ8gmMAAAAAQMgjrRoAAAAIMKRVA77HyDEAAAAAIOQRHAMAAAAAQh5p1QAAAECgIasa8DlGjgEAAAAAIY/gGAAAAAAQ8giOY6BVq1ZSoECB+O4GAAAAQrhatT++gEBGcBwDp0+flkOHDsV3NwAAAAAAPkJwDAAAAAAIeUFXrTp//vyxfo1Tp07F+jUAAACAyJDCDPhe0AXHmu7szj8WDx48sGxHdY7jsdEdDwAAAAAILEEXHEcV0EYW4Oqx0R1vfywAAAAAILgEZXBcsWJF+fTTTyP9/Pr169KjRw/ZsWOHFC1aVBo3biwlSpSQzJkzS6pUqUwgrEFweHi4nD171hw3Z84c2b17t9SqVUt69+4tiRIlitN7AgAAAGzIYgR8LyiD4wwZMpggNrLAuHr16nLx4kWZOXOmCYzdMWzYMJk7d660bdtW+vXrJ/PmzfNxrwEAAAAA8SXkqlV36NBBjhw5IitXrnQ7MLZp2LChrFixQrZu3SrdunWLtT4CAAAAAOJW0AXH69evl5EjR7r87MKFC/LTTz9Ju3btJE+ePDFqX8/T88eMGSOXL1/2srcAAABAzNKq/fEFBLKgC47Lly8vBQsWdPnZokWL5O7duyat2hs1atSQmzdvysKFC71qBwAAAADgH4IuOI7K8ePHzXvixN5Ntbadf+zYMZ/0CwAAAAAQv0IqOL53756pQr1582av2tm0aZNJG9FRaAAAACDOJfDTFxDAQio4zps3r3nXOcmXLl2KURs6b9k2p9nWHgAAAAAgsIVUcPzoo49KWFiYSYeuW7euWbfYE7resZ6n52s7DRo0iLW+AgAAAADiTlCucxyZNGnSyLvvvmvWLNblmEqWLGkCZl3SqWzZspIvXz5zTLJkyeTWrVty5coVOXDggEnDnj17tinAdf/+fZNS3b59e0mdOnV83xIAAABCEJWhAd8LqeBY9e/fX1atWiWrV68284/nzZtnXu7Q423Vqj/55JNY7ikAAAAAIK6EVFq10lHhBQsWyLPPPmsJePU9spf9cS1atJC5c+dK0qRJ4/EuAAAAAAC+FHLBsUqePLn89ttvMnPmTKlTp45baSuafq1B8cSJE818YwAAACC+6O+n/vgCAlnIpVXb07nG+jp16pSsWbNGtm/fLufPn5dr165JypQpJWPGjFKqVCmpUqWKZM2aNb67CwAAAACIJSEdHNtky5ZNnn76afNC8Hjv9QbySfsnzZ9/+muNvNH3Z79uu0CezNK8UQWpVraAFM6bRTKkSymJEyWUC5evy74jZ2TFpn0ybf5m2fHvCR/cgUjeHBnl2QZlpWaFQlIkX1bJkDalJEua2FzvxJlLsnrLAZm3apfMX+VZVXdX9Elyw+rFpVHNh6VyqYcke+a0kj5NCrl9556cPHtZdu47Ya4zbf4muXT1hsS2Jo+UkKkj3orY9vXfDyC27Z49Ua6cOuJ1O+VadJQkYSl80qe14wbKiW2rI7ZrvDtQMhcsGeP2rpw+Kie3r5ELB3fL1TPH5Pb1q3L31k3T36QpU0ua7PlM+9lLVpHkaTN61ff79+6avp/Zu1kuHN4rt65elDs3rkuiJEklebpMkjbnQ5K1WAXJUaqqJE4aFlTfNwDAfwiOEZQK5c0i3Vs3DIi2c2ZJJ8O6PytP1CklCRM6z3TQQFJfNcsXkp5tG8vS9f/I+8OnyZY9x2J0vYzpUspnXZvJ843KS+LEiSK9XvmH80q7l+qYYLzn53/IgtUxC5Ib1ywhQ7o1M8G/o6RJEpuvp76erlfGHPfdlOUy8LvZcvXaTYkNmdOnklF9XoyVtoG4cnDVHLkVfsnrdso8945P+nN43QJLYOyNyycOyY6/x8mZPZtcfn772hXzCj9zXE5sXSnbp38veSrWk+KPvSLJUqX1+HqH1y6QXbN+kptXLjh9dvfWDbl6+qh5Hdu0TLZNSymF6jSVgnWekUSJkwT89w2BjRRmwPdCcs4xgluqFMlk4metzbu/t123clHZ8HsveapeGZeBsSu1KhaWZT++J+1erO3x9coVzyNrJr0vLz5eyWVg7EqJQjnkz6/elo/efcLj633e4zmZNvItl4GxKymSJ5VOLevJmkk9zHVjw6i+L0nWjGlipW0gLty4fN4nAZavXLtwWrZN+84nbR1YMVOWfN4l0sA4slHfQ2vmyqKhHeX8oT1un3fv7h1ZM3agbJo8wmVg7MqdG9dMIL30i25y/eJZCeTvGwDAWciPHOu6xTNmzJClS5fKpk2b5OzZs3L16lWz3nHmzJmlfPnyUrt2bTM32d3gBfFH04J/Hd5WShbO6fdtP1KhkPz+xRuSPMy58vnBY+dk35GzcvvOXcmZNZ2UKJjDEswmSZJIhrz3rPk7OfLnRW5dTwPU6V+9LZnTO6/PfercFZPafOPWHcmROa2UKpzTcj29To82DeXe/fvSb/RMt6735QcvSJtnazjt13va/s9xOXnuioQlTSxFH8omubKltxyTP3dmmf1tB6nTarhJKfeV15tWl8drxTzNE/AHl48fFH/x4P592fjzcDPC6q0DK2fJ1qnfuPxMU5tTZsohicOSm1HjKycOOV3z5uXzsnJ0b3mk/WBJl6tANP2+J2vHDpDTuzc6faap1Glz5pekqdLKvVs35PLJw3I7/LLlmMvHD8iKr3tJrU5D3R6t9qfvGwDAtZAOjr///nvp16+fHDv2X3qqbckmW7qKBs3Dhw+X3LlzS9++feW1116Lp94iOimTJ5Upn78pdSoX8fu2db7t+IGtnALjWct2SN+v/nKaV5wpfSrp8mp96fByXUmU6L+HNP07PGXmIm/aFf0ctgmDXnMKjPU67w39XZas+8cp9ViD4bdfqGV5KNTrjcayctN+WbQ26tEZTdl2DIxv3Lwtg7+fK9/8ulSuhFtTpiuWyCufdm0qVcsUsNzzhEGtpMbLQyw/lzGVP3cmcw0g0GlgZi9z4TJS4+1+8dKXfxZNlfMHd3ndzoXD/8jWqd867c9RqpoUbfCCmfNr7/69e3JyxxrZNfMnCT97PGL/vds3ZfX3n0j9HqMkSfKUUfR7mlNgrMcXf6yl5K1YTxIltWYHnd6zyaRva3q1zbXzp2Tzr19KldYfBtz3DUGCrGrA50JyKPTWrVvStGlTefPNN01gHNkv3vb7jxw5Im3atJFmzZrJ7du347C3cEfxAtllxc/dYyUwjo22P3izsZnXa+/zCQukWcdvXBbcOncxXHp9MV1e7jFW7t27bxlB7tfhf4XBoqKFvsoXz2PZp3OXa74yxCkwVmcvhku3IVOlde+fTHaFvc+6NY12hP2zbs0s+3T+cKM3RspnP8x1CozV+h2H5dE2I2T6wi1OaeDNG1cQb+kDhXH9X42VVHsgrl1yCLLS5cwfP/04tl92z/nF63b0/7Xb/vhOh3Mt+0s901Yqv9bTKTBWCRMlkpylq0vtLsNNkGnv5uULsnfBlEivd/PKRdkzd5JlX7LU6aV25+GSv3oTp8BYZS1aznyeIV8xy/6TO9bKuQM7A+r7BgCIXEgGx82bN5c///zTEgAnSZJEChYsKBUqVJAaNWqY90KFCknixIkjjtH36dOnywsvvBCv/YeVzp9d9lM3KZo/W0C0nTZVcmn5VFXLvlWb95vgNzoaPH4/dYXTvGWtPB2V5k2sAealq9dNoH3z1p0oz5s8a718P3WlZd/DBXNI2WK5Iz3nhSYVneb09hg2TdZtPxTltTTob9vnJ5Pibe+1Z6qJt3q0biiVSjn/gg0EIscRyLS54j7Iunfntmz4eZg8uHfX67a0GvXFw3st+/LXeFwKPBL9gz+t2KwBdIoMWZzmLmsfXdHP7t+1/ttX4aXOkipz1HUOEicLk4qvdJOESawZP4fXzJNA+b4BAKIWcsHx+PHj5a+//jKBbpYsWeSTTz6RLVu2yPXr12Xv3r2ybt06WbZsmXnX7Rs3bsjmzZvlo48+Mmsd63kaWGs7iF9a4fi34W3lh34tJWXyZAHTdqMaD0vqlNalQPp/O8vt88dNW+W0r0b5glGeU7tiYcv2b3M2mtFod3w1cXG07dl7tkE5y/aRkxdk/HT3qtiGX78lU+dZUx0rl8onSdwsHuaKjpi/36ZRxLYuU7Xtn5hV+gbi252b1006b3yPQO78e7wlxVhHVmPq+BbrA79EScOkaKMWbp+vAXLRhtbjNb367L/bXB5/bMtyy3aGh4pJliJl3bqWBuGOx57bvyNgvm8ILjr9zx9fQCALueBYg1z9wdW06n379smHH34opUq5XkJH6f7SpUtLnz59zPHPPPOMCZA//vjjOO87/psP+/n7z8vGKR/IE3VKO30+atISWblpn9+1bVO5tHUE8+zFq7J4rXXUJCp7D5122pcra7ool25ynNu849//5uhF59/DZ5yWVdIiYZGlL+sSUPb+WLDZoznDjveXLGkSyZLBuYiYO5KHJZGxA1416ec2b308US5dif21lIHYcPnEQU1jsgSSqTL7vgBhVHQt4P0rZkRsp8yUXUo8+XqM2zu7zxrEZi5cWpKl9KyivK51LA6/lF8+vt9lSvX189Z/Y3KVqenRtVJnyWXZvnHpfEB83wAA0Qupglw6Aqxzh0uWLCmTJk0yqdSeSJkypUyePNlUsN65c6dpr2xZ9542w3d0jeG3mj/itP9K+A0zT/anv9bI3DEd/a5tmy6fTpFPv58jRR7KJsXyZ/e42FQKF9Wt7echu3N84kSejcTeuXvPsp00qeufHe1Hrjo9pEDuzFIsfzYpmj+7LI6meJc7/b17z3p9dw3u0lQK58sasa1rKM9ftVu6vdYgRu0B8e3yMYfU3Bz5JEEcrqRw+9pV2Tjpi4hAT69d/sXOkiiZNRvGXVo1WtcrtpchTyGP20maPJUkSZ5K7ly/GrHv5hXnZZPC0qSXJz+dIuFnT8iVU0fM6HfWYuU9uta927cs2+58/eP7+wYAcE9IBcdbt24172+99ZbHgbGNnqfnt2/f3rRHcOwfZi/fIR0GTJZjpy8FRNunz181r2Ub/vX4XC1S5egfF6PJNucuhZuiWvbZEaWLWEc+oqJLO2VIa636euzUxUiPv3//gRlt1tdfi12nNXpyfxevXDdfK081rFFc3njuvxEhXRKq5/A/PG4H8CdmBNKOLjkUl7ZM+doUvLIpVLeZZHyomFnrOCZ0XnDBOs+YEV1da1jbTp7eOn/YXY7ziCOTMHESSZM9r3nFxMWj1n+3U2XJ6fffNwQnUpgB3wup4PjMmTPmH5JixazVJj1VvHhxM9qn7SF+aWXnPl/+ZQLYQGo7pvTvry7p5DhPd7GLitM2N27ekV37T0mJQv8Vm3mmfhnpPfJPU5U6Om3tAkybJevcTwP3hI7yPlG7lGXfrGXbPW5Hl4H6pu/LEdt3796TNr1/kus3qTSPwKYVou2li8OiTkfWL5LjW/8r0Jc2x0NSzGGur6cSJ0suDz/W0uu+aXCu84zthaXNIL52dt92p+Jh2UtU9uvvGwDAfSEVHIeF/S/tS4tvecN2vq09xL0NOw7J178skV/nbPTJGrhx1bY3kiZJLCN6Pe+0pJT21XFOsKNJM9fJgE5PR2ynSZVcxg1sJU07fCO370RebbZ+1WLSpZU1GF+37WC0ladjoshDWeX3L960zI++c+eeDB033+O2vv6whWTL9N+cxeETFsjabdaRGyDQ3L9311IES6XNWSAi+Dq2ebmcP7BLrp07KbdvhJtCVZpGnD5PYcn2cEXJVryiJEwUs//tX794RrZO+9Yy+lr+pS7m3R+c2OZc9C9NtpiNDEdGv7brJ3zmtDZygZpP+O33DQDgmZD61zZnzpwm2FmyZIk0adIkxu0sWrTIjOBpe4h7A7+bbVJtA63tmEqfJoU0a1DOjBg/lCuT5TMN+LTP0Rn961Jp3ay65M+dOWJfvSpFZcmErmaZpeUbrWmCaVKFSbsX65gqz/bFrHTu9dufeL+uqePSUK83rSavN60uYcmsv2j3/PwP2XPAWuE1Oi2fqiJP1v2vmNqWPUel/zfuVwMH/JUGWPapwwkSJpK7N6/L0hHvyYVDznP7b1+7Yl5XTh6Ww2vnm8JZOkqbs0wNj6774P592Tjxc3Mtm2KNXzbzZv2Bfk32L/3f8ow2ulZxlsLORRU9pb8z6EjxgZWz5NimpeZrESFBQin3QkdJlsq6Zr2/fN8Q/EirBnwvpILjWrVqmXmXo0ePltdff12KFi3qcRs7duyQb775xrRTu3btWOknohabwas/BMY6Qvzzp69J0qSJJU/2DFI4b1ZTBdrRvJW7zFrFUY382qdWN+v0rcz6pr1kz/zfL3K6XvG87zvKybOXZee+E3Lj1h3JmiG1lCmW2/TDnh7Totv3smv/Sa+XstJgWEevdf1oxzWR1a3bd6Tn59Nl9OSlHrWdL2dGGdKtWcS2ruPc+sMfnQqKAYHokkNRJw3cVoz6wO3zdWRy3YRPJd8/W6V0s7ckoZuF+f5dMt2yXFHG/A9Lodr/ZaLEt73zf5Mbl85Z9uUoWdUEyDFxeO0CObFjjdy5Hi5XTh02767SwTUwzlHKuma9P33fAACeC6ngOFOmTPLoo4/K3LlzpWbNmjJq1Ch57rnn3DpX/2emFa61EJeufawjzxkzZoz1PiP05M6e3uUyUjbnL12T7sOmyi8z1nnUro7AVnvxU7NU1dP1ylg+04DZPmh2fGAwbtpK+fSHuXIlPOr0bXdUKZ0/yvvTImWdBv0quz0cMU6YMIGM7d/SBN02H389w+tgHvAXl49bgyx5YK1SnyRFKkmZMZuEpclgArqrZ4/L7fDLTu0cWj3HFL+q8voH0VZM1kJSu2f9ZAkKy7/YyW8qLZ87sFP2Lvzdsi9BosRS+NHnY9zmmX+2yKkdayP9XAPikk+3kRRuFg6Lj+8bACBmQio4VkOGDDFp0RcuXJAXXnhB3n//fXnsscekXLlykj9/fkmTJo2ZS3zz5k25fPmyHDhwQDZs2CCzZs0yy0BpkJw0aVLTDhAbdLQ4Krpucc+2jSRL+tTyzW/LzOiou06duyIvvveDvPNCLRnY+Wmn0WFXwq/dlEtXb9gv0emVPNnTR/l51dL55bNuzWTY+PmyJIpCY450eaaqZf43j09pqviInxd51VfAnzgFWf8vQ75iUqhuU8n+cEWTsmuj/7/StN098ybLmT2bLOec2rlOds3+OcpiWPfu3pENPw8zc2ZtSj7d2gRy/uDa+VOydtwgeWDXP1WozjOSJmvuGLer86ujcmrXBvPvYZFHn5f0uQv63fcNoYO0asD3Qi44LlGihIwbN05eeeUVs33w4EH5+uuv3TpX/4el6dQ//vhjjFKyAXfkzhZ18KgK5skig7o8I683qy4vdB3j9uho0/pl5eP2T5jz3e5P9gzySfsn5Z0Wtc2SVn8v8Xx5Jsf2oqJznLUQmL4mTF8tHQf9KrduR506runhH7zZ2DI3um2fn/2qoBrgLcflgFTRBi9I0YYtXI4k6i/OusxS9Tc/ln8XT5Mdf4+PWJ9Y/bPwdzOPNV0kywrtnDHBzHu10cJQ+ao0FH9w/eJZk5rsOMKaPm8RKdboRa/avnHxbJSf6/zhk9tXy8kda6RwvWeleOOXoxzJjevvGwAg5kIuOFYvvviipEyZUtq2bSvnzv03T8nVL9K2p3L6WebMmWXs2LFmpBmILTv/PSFPvvu1WUrq3MVwUxyreIEc0rR+GWn1TDVL0apCebPInDEdpG6rz806vlGlHH/1YQt57ZlqTinaOq9Xl6vaf+SsmXOcLVNqqVamgLR8qqqlMrZWf548rI28N3SqjJrk2Vxge99MXirdh06Vg8fOyfWb/3+9sgXNPOSa5QtZjn316aqmINkL3b6PNNDVr8fY/q9aRsG7D5smh0+cj3EfAX+jVYx1bVwdLb15+bwpDFWoTlMp1vglt87XY29fD5d/Fkz5b+eDB7J7zi9StfWHTsef/Xer7F/2V8R20pRppOwL7cUf6MjuilEfyvUL1n/zkqfLJFVe6+V1ZWf9mqbLVVBSZMgiCRMmkhuXz8u5/dtl//IZcuWEXaX+Bw/M1/PerZtSqukbfvF9AwB4JySDY/XUU09J9erVZcSIEfL999/L6dOnXR6nv5DnyJHDBNLt2rVjnjFi3cZdR5wCWE0R1tdXk5bI75+/aQpZ2WROn1rGD2olNV8eEmkAOfS9Z50C4zkrdkqrnuPlcvgNy/4jJy/KkZMbZPLsDWY95O8+fkVSpfhfYRvNnPisazM5cPScOT8mps7f7OJ662XyrPWm0vTIXs0lWdL/HgBo5WlNA/960hKX7Q3s9LTl6zFj6XYz4gwEk6TJU0nNdweaP2uaswaGnqY3F2/8khzfvNwEavZpurfCL1sqLmtAt/GXLyyjlWWee0fCUkef1RLbrpw6Iqu+7etUgEuD92pvfeKTtY3zVrIuX5cqcw7zylvpUdm7YIrsnjPR8rXZv/xvyVSolOQoWSVev28IQWRVAz4X0hUdtEBXv3795OTJk7Jr1y6ZOHGifPHFF9K/f38TNOv2nj175NixY9K3b18CY8Q7Hd1t0OYLOXrygmV/+eJ55PmG5V2e80iFQvL2C7WcKl036/iNU2Ds6I8FW+Spd7821aNttHK2BrDJw3y/vumPf66RN/r+7LT/w7ebuLyepl6/+XzNiO2zF6/Kuz5eagrwNzoyqsGap0WZdF5rfsc1eR88kDN7rQ+stv4+2hJ85q5QR3KWri7xTdcCXvbl+06BcbJU6aTGOwO8mmfsDv16F23QXIo3+d+0LHs7NfU5nr9vAADvhXRwbE/nELdo0UI6dOggvXr1MlWpdbtw4cJet33r1i25cuWK5fXgPkvLIGbOXgyXdgMmO+3XFGRXtHiXvctXb8jrH06Q+/fdm4+7assBp3WCdd5w88YVJDb8Nmej/D53o2VfutQpnCpsZ0ibUr77+GUzmm3Tvv9kOXPhaqz0CwgGWYqWddp38ch/65wf3bRUjm1aZklVLt30TYlvRzcukRWjP5Q7160/32FpM0qNdgPjdM3lIvWfM3Ob7YWfPS7n9scsm8YX3zcAgG8QHMeBQYMGSdq0aS2vu6etv/wDntCRX12X2F6V0g85rYes84R15Nje97+vMKnanvjqlyVO5zzbwPVItS98/uNCp32O85G/+vAFy/JTP/+9Vv5ctDXW+gQEAx1d1aWO7N26esm864isjhpHSJBAyrXoJEmSp5T4pPNrTdXsu9bK/Kmy5JJaHT+L9RFjVwrVfsZpn/1a0HH5fUPo0ro4/vgCAlnIzjmOis7b9OUPd8+ePaVLly6WfVlq9vBZ+whNC9fskYcL5ojYTh6WVPLnyiT/Hv6vSE3FEvksI6tq1rLtHl9Ll4tasHq3ZbS4wsN5JbZs2nXEFCPLlD5VxL7iBbJbrv1M/bJODwJ+GdLarfaLFbDO+dMHCI7nTp23yWl+NBAMkqZIZQmsbl+7Yt73LvhN7tz47yFYkrAUcnDlLPOKzr07t5z26dzcAymtc2J17rK782Tv3bktmyaPsIxk22R4qJhUaf2hJEuZRuJDliJlzMMD+7nHV09Z60XE1fcNAOA7IR8cX7p0ySzNtHTpUtm0aZOcPXtWbty4ISlSpDDVqcuXLy+1a9eWl19+2Yz4xkSyZMnMy579moZATLiqxqyVnaNbM/kfu+DZE44j1WlTJzeVtK+E35TYcPTURUtwnC51csuDAFfzj2Mqb46M5mVv5z5dHovgGMFHKybbS5QszLzfu20NcDVQPrFtVYyvc95FmnGJp16XZBL9/0tvX7sqq7//xKz360iXMSr/UhdJlNj3dQ/cpaPp+rpzPdxSyCw+vm8AAN8J2eD43r17psiWFt66fv262Wdf6ffatWvmdfjwYZk2bZoZ/e3cubP06dNHEiUisIV3dNmhvDkySP7cmWT73uNy4qx1rU533L7jPG/99h3resAp/7/KtL3rN25LTFy6+r+fE0v7yZO5DI41SH8oVyYzmjtrWcxSDe843Iur+wVClVY+jsmSRfr/uTsOQZxWevYnmt698ps+cvX0UafPzLrCj7X0OrtLR2DDz58yyzCZUeAYcPz6u/P9CObvG+IeKcyA7yUO1dHihg0byoYNGyJSqCNbAsf2eXh4uKliPXfuXPOK6SgyQpsGjWsnvy85sqSLmB/8/vBpMuKnRR63lTWj8y9Gp89bi9VcuuIc0Oq1o1oTOTJaFMuR4zxkLQo2qPMzESPY9+/flzz1eno8x1llzWS9v9PnSSFE6Nr4y+dmGaPb4VfkVvglSZM9r9TuPNzjdjT113EEMnWWnOIvrl88KytGfSDXzmnmhjXbqszz70q+yo961f7uOZNk35I/5O6t/1XqTxKWUh4b8IvHFaTv37vnlNbsaqmrUPm+AUCwCLng+O7du9KkSZOIwFhp8Js/f37z0qA3LCxMbt68KZcvX5b9+/fLoUOHzLH6Wr9+vTlf07ATJw65Lx+8dPHKdTOaa184q16VYjEKjquWye9UhdoxgHQVUJYtljtGwXGJQv/Nb1Ya8DqOVOs8YfvUbp3vXK9KUVOB2hM5Mqd1SnPed+RsxJ91zefkZdtJTM0d09FSqOynv1wvIQX4ixuXzsulo/siti8fPyh3b92UxB6m1p7917loXcb8D5v38i92Nq+YuHbhtMzr18ayr8a7AyVzwZJut6Hr9q4c3dspME6cLLlUavW+ZC1aTryVNEXKiMBY3bl5TS4c+Ucy5ivqUTsXD+91ClZTZrb+GxlX3zcAgO+EXLVqTaNes2aNCXRLlSpl5hvrPON///3XjAj/9ttvZp++6/a+ffvkzJkzMn78eHO8nqfnjxw5Mr5vBQFq/Y5Dlu06lQqbYNATubOllxrlClj2acEsx+WZ1mw9YEZv7cVkCSZdY9hxTq8GqI427jws9+5Zr/fi45U8vp6rc+asiL1KsIC/S5e7oFN67ontqz1qQ4O5AyusxbXC0mSQdLmsbccHvZ81YweYJZHsJU2VVmq+O9AngbFyXIJJHV3v+cPJIxsWO+3LVrxCyH3fEL80q9ofX0AgC6ngWAPbzz77zIwU6zrGWoBLC22lT++cCmUvQ4YM0rJlS3N8u3btItqJLBUbiMqvszdYthMnTiTvvd7Aozb6dXhKkiW1FqOZ4rA2sC3NeuNOawXVhtWLS+VSD3l0vQ4v1zXrCtubsdS56vWpc1dk2QZr0Pxo1WJSvnget6+VNWNq6dSyvmWfrl28ZN0/HvUZCCa5ytRw2vfPwt/lwX335+IfWDHDKfh8qHoTSegHdTR2/D1eLhzcbdmXNGVqExg7BpjeyJC3iKTM9F/le3Vk/UKTzu2uKycPy+F1Cyz70mTPJ2my5Qm57xsABJuQCo5Xr15tRomrVatmRpAdl7iJjh6vI8Z6vraj7QGemr5wi5x0KMDVulkNqV2psFvnt3+pjtPo74YdhyJd4/cLhzWDNRj/oV9LSyXoqGi/PnijiWXfoePn5DeHIN/mm1+XOv3cjO77kqRyURzMUYqwpDJpaBvJmM4aiA/6brbcum1N4QZCiQaIjiOFOg9158yf3Dr/7L/bTADqOCqbv7r1Zzs+nD+0R/Yv+9uyT4tWVX7tA5cBp7cc7/l/S0aNNPOI3SnktWbcQHlwz/rvUfHHXgm57xsABKOQCo53795tRo1ff/11r9pp3bq1GTXW9gBP3bh5R3p9Md2yL0mSRPLrsLbydL0yUaY2D+7yjHzWrZll/63bd6TrZ79Het60BZtl9Zb9ln0F8mSW1b/0kOplranZ9szPStPq8sfIt03/7H044k+5c9f1L5J/Ld5m1mC2V7JwTpk5up3kypou0usVeSirLBzXWaqWsfZp464j8v3UFZGeB4SKUk3fcMpZ/HfRVNk2/Xu5f/eOy3P0/1WH1syVVd995HRMmWZvmdHZ+LZ9+veaO2zZV7TRi5KpQOzMqc1f83FJnTW3Zd/Zf7bI2rEDzBJSUQXxS77oKtfOWpe1y1aismR/uFLIfd8Q//T/0/74AgJZSFWU0tFeVaBA5AGBO2znnzt3zif9QuiZPGu91K9aVF56vHLEvjSpkptRU53LqwWsdv57Qm7evmOqUtcoV9DMw83uYm7yO/0mybrt1nnMjl7uPlaW/dRNcmb9bwpBrmzpZcHYzmZesqZ6a8GrcxevSoa0qaRCibzyfKPy8nBB5wIzI39eJFPnR73+79sfT5TF47tYrlep1EOybXofmThjnZkfresYJ02SyCz51KRmCfNgQEe17R0/fVGe6/St3L1r/cUZCEUZHypmljL6Z8EUy/79S/+UE1tXSt7KDcwxGjjdvh4ul47tl2Mbl8jlEwed2nqoWmOzXnB8O7dvuylu5WjXzB/Nyxt5KtZ1WWBMR6UrvNJNln/5vqU416ld62Ve/7aSp3J9yVyolCRPk0Hu3r4l4WePyYlta+T0budsmTQ58knFl7uG3PcNAIJVSAXHqVOnjljKyRsXL14076lSuZeWCrjy1scTJU3KMHmiTmnL/prlC5lXdLRSdJdPp8gvM9ZFe6yuo/xUu9EybeRbkid7BstnVUrnNy93jJ22Ut4f/ke0x2ngq9ebMbqdWevYJnlYUmnzbA3zis4/h07Ls52+dUpBB0LZw4+1NEsIHVo912lt4D1zf3GrjTyV6knpZm+KPzi6yToNI66ky5lfqrT+QNb8MMCperUGrfpyp7hXldd6mWraofZ9A4BgFVJp1blz5zapSrNnz/aqnZkzZ5q0EW0PiCkdDX2+yxj56Ou/5c4d94uzKF2KqcmbX8oPU1e6fc7OfSek2oufyqxlnld9vhJ+Q9r1nyTv9pvkdiE6vV7VFoNl6XrPC2lNnbdJHnllqPx72PMlp4BgV/b5dlLmuXclUZKkHp2XKGkyKfVMWynfopNZN9gfnNsff1XoMxcqLbW7DDejv57QNZG1IFbNdoMkLK31YWOofN/gH+K7KjXVqhGMQmrkuHbt2pIkSRIZO3asvPjii1KzZk2P21iyZImMGzfOtFOnTp1Y6SdCy6ffz5XJszZIl1b15dkG5ZyqQtvoEkmbd+v825Xy899rnZZMcoeuTdys4zdSpfRD0rllfalbpWiUhbIOHD0rk2dvkC9/XiSXrv43uuIurV7d6I2R0qjGw9L51fpSrUx+p9Rp+wBc062HjJ0nW/Yc8/haQCh5qFojyV6ysilkpdWWb16+EOmxyVKlk9wVakuh2s94FMzFBV0HOD6lzpJL6nb9Qo5tXi77lv5pUpolkgeAmvac7eHKUqT+c5LKxZrGofR9A4BgleBBiK1H1KJFC/n1118lLCxMPv74Y3nnnXckZUrXwYi98PBwU6m6X79+cvv2bRNc//STe9UmXUletl2Mz0Xw0oyEcsVyS5H82SRTulSSNGliOX8xXE6fvyJrtx00wa0vJU6cUCo8nNfM+82YNqVJe7545bqcuxgum3YdkSMnI//FLSZSpwyTamXzS84s6SVDupRy+/ZdOXvxqhw6dl7W7zzE3OIA13FAh/juQsi6euaYXD52QG5duyJ3blyTREmSmLVw02TPa5YZokiOe26FX5bzB3fLrSsX5fb1q5IoaZgkS5VGUmXOKelyFTCjxr7E983/DW7i3koS8aFw9znij/75rFF8dwGIsZALjo8ePSoPP/ywXLv2vyAjRYoUZgS4XLlykj9/fkmTJo0JnG/evCmXL1+WAwcOyIYNG2Tp0qVy48YNk1Kqx+zcuVNy5swZ434QHAMINgTHAIKNPwfHRXpY57D7i72fNozvLgAxFlJp1UrnCU+fPl0ee+wxMwKsQbLOIdZXVGzPEDRw/uuvv7wKjAEAAAAA/iWkCnLZ1K1bV5YtWyYFCxY02/aD5/pn28t+nypatKisXLlSHnnkkXjoNQAAAAAgtoRkcKwqVqwo27ZtkzFjxkilSpUkYcKETlV4dTtRokRStWpVU4Rr69atUrZs2XjrMwAAAKDiuyo11aoRjEIurdpesmTJpHXr1ual6dUaLJ89e9YU39I1kTNlyiSlS5c285IBAAAAAMErpINje1qxWkeIAQAAAAChh+AYAAAACDAJE5LDDPhayM45BgAAAADAhpFjOzrfWNcyjkqCBAnMclAAAAAA4sbmzZtlzpw5sn79ejl16pRcuXLFTIvMmDGjlClTRmrVqiWPPvqoKbIbE7rE66xZs2TRokWyY8cOuXjxoty5c0fSp08vhQsXljp16sjTTz8tqVKl8uo+9u/fL1OnTjX3cfToUbl69aqpg5QrVy4pV66cPPnkk+bdG8F0L3EtwQPHEs1B4u7du7Ju3TqXn1WrVs3l/saNG8u8efOibXvJkiVSs2ZNr/qXvGw7r84HAH/TcUCH+O4CAPjU4CaFxV89/EH0v7PGh50DGvi0vRMnTsgHH3wgq1ativbYhx56SD766COpUqWKR9dYsWKFuYYG3VFJmzat9O/fXxo08PweteDvwIEDZdq0aU4r5DjSIH/AgAHmep4KpnuJD0GbVj1jxgwTwDq+dI3i+/fvR3qe/TrHkb30LwMAAACA2KMryTRt2tStwFgdPHhQXn/9dfnll1/cvsbkyZOlTZs20QaT6vLly9K+fXsZOnSoeOLChQvy4osvmlFWd8Yl58+fL0899ZQcOnTIo+sE073El6BNq54yZYrLb1jRokVjnG5ho6PL//zzj0lLAAAAACA+HzF+6623TEqwvXz58kndunUle/bsZgRzw4YNJni2/d5/7949+eSTTyRLlixSv379KK+xePFiM9JsHzOEhYWZ84oUKWK29+7da37311RlmzFjxkjevHnlueeecyub9Z133jHt2CtUqJDUrl3bLB177tw505d9+/ZFfH7y5Elz3m+//eZW+nMw3Ut8Csq0av2hyJAhg/mB0dvTdYq7du0qb7zxhuTMmTPS82xp1WPHjnX5uc5H7tChg2lf0xB69uwZ4z6SVg0g2JBWDSDY+HNadYkP54s/2tH/UZ+0065dOzPqaJMoUSJ577335NVXX3Ua6NqyZYv5Hf306dMR+3R+rZ6fOnVql+1funRJGjVqZAm+K1SoIMOHD5esWbNajtV2u3TpYgJxmyRJksjMmTNNYBmVr776Sr788kvLeX369JHnn3/e5eBev3795NatWxH7mjVrFm3WajDdS3wLyrTqTZs2mQnhSkd3t2/fLh9//HGUgbE9/aFz9dKnV5qqoQH39OnTY/kuAAAAgNDz77//WgJj9f7778trr73mMgNUC3KNGzfOFOiy0UDxxx9/jPQa3377rSWY1NHV7777zimYVLpPB89Kly4dsU8LXI0aNSrK+9BR1B9++MGyTwfYXAWTSkdvNc1ZCwDbaMxx+PDhKK8TTPcS34IyOF66dKl51ydF+oOlk/N9pVu3bhFPqDS1AAAAAIDvaJVlezrY9corr0R5ToECBUzwbM8xwLa5du2amZ/rGOjZB9eOtArziBEjJHny5BH7/v77b1OlOTKTJk2S69evR2xr7SOtEh0VLZD18ssvR2xrxqoGv5EJpnvxBwmDdfK+PqXo3r27z5ddKliwoFSqVMkExnv27PFp2wAAAIA7dEDOH1++4Pg7tgZZ9iOQUU2RdGxHR0Ud6ZJQ9oGeLjdUqlSpaNvXec66PJF9sKdtReaPP/6wbDsG75Fp27atSSO30Wmfru4j2O7FHwRlcLx7927z3qpVK4/Oc3f6ta6jphwnowMAAADwjlZEtucqPdgVx0Ex/d3esS37LFObhg0but03xwA8stFpTQ0/fvx4xHa6dOmkcuXKbl1D71dTxW10uujq1atdHhtM9+IPgjI4PnbsmFl8OkeOHB6dN378eFOFOjr6DY7shw0AAABAzGmhJ3u2WkLRsS/+ZGM/ammzbt06y7a7gZ5tZDZx4sSWjFXHitpq7dq1lu3y5cu77EtkNFPV3rJly1weF0z34g+CMji+cuWKCY49lS1bNjNfITpaptx2HQAAACCuaZqxP758QZdrsrdx40a3ztOaQPa0/lDGjBmdqjXbB4AaiOtSRO7S+br58+eP2NYBs127dkWbGl68eHG3r+Hq+B07djgdE0z34i+CMji+f/++Wb4pttgmr/tzvjwAAAAQiOrUqeOUOnzgwIFoz3OspqxFoxwD9v379zulYtuPnrojT548lu2DBw86HeN4HfsgNLauEcj34i+CMjjWkd3z58/HWvtaylzpWsoAAAAAfKdatWpSsmTJiG0thKvrGJ89ezbSc4YNGyZr1qyJ2Na03zfeeMPpOPu5s7bMUU85zoF2bFOdOHEiynOikyVLFqe1jLUydbDei78IyuA4c+bMZt5xbNGnHfoUSq8DAAAAxLVgTqvWdjTYtR+I0qJQunSQ1gjSJYdu375tpjjq/FWtnKzr+trTVWuKFi3q1LZjzSDHtGt3OA6QuZqn63gd27RMd6VPn95pTWfH6wTTvfiLoAyOtXy5jhxv2LAhVtqfOXOmeX/44YdjpX0AAAAglOXNm1d+++03S6Vjzd4cNGiQ1K9f34wsV6xY0SwVtGrVKss8408//TTSVWt01NJeqlSpPO6b4xrCly9ftmzrqKgG795cRx8Q2K9D7KreUTDdi7/wLCk9QDz66KPy448/yrhx46RChQo+bVsnqeu8B82d1wXJAQAAAPxPvXr1ovx84cKFbrelc2gnT54s33zzjYwcOdLUFYpKiRIlZNSoUVGm/TpWtHYM2tzheI5jm66qZsfkOlpDyT79+ObNm0F7L/4iKEeOdX0vrb6m6RWbNm3yWbu6OPbbb79tfjCfeuopn7ULAAAAeEIzmP3x5UtaffrFF1+UL774ItrA2FYF+bnnnpM//vgj0mMcR0E9LWClHJcxcizS66pory+uo3Ovg/Ve/EVQjhxrHvybb75pnjA1adLELGhtP6k/JvQb2Lx5c1m+fLmEhYXJe++957P+AgAAAMHAk5HhqPz8888ycOBAMzhlH2BpVqius6vzWHX94927d8vKlSvl+vXrEcsbvf/++7JixQoZPHiw05rJ9u0px7mw7nA8R5dAiuoavrqO4wOCYLoXfxGUwbHq1auXSa3WqnZVq1aVHj16mIBWA1tPaXDdsWNH2bt3r8mZb9++veTMmTNW+g0AAACEMq3v069fP8s+nXvcv39/l+v4asEoLeD1+++/R+ybMWOGySTVANtedMGyOxxHPR3bdDWyqtfxdMTVcdTW8TrBdC/+IijTqm0lw3/99VfzhOnGjRvy0UcfmfkHr7zyivzyyy+yffv2SNcp1hLms2fPlj59+kiRIkWkUaNGJjDWJym1atVy+iEDAAAA4lKwVqvWKsaffPKJZV+VKlXMoJerwNhWcXnAgAHSpUsXy/6pU6fKkiVLLPuSJk1q2Y4sHvAkoHRs03E7rq4TyPfiL4J25NhWmEsn8L/11lvmCYemXmhgrC/7yeFacU2/QeHh4eYY+6cu9qkF+sRKf8gcc+YBAAAAeE8rVNtXYU6bNq2Zc6yjwNHRaZVbt261pHZ/9dVXUrt2bUs1a3u2dGxPOK7R61jxWa+hDwrs4wg9x9Mqz+5cJ1juxV8E7cixzeuvv25+QOyr1uk31/bSb5TOTdD10vRJlT7VsH1mT8vBa5l4nd8AAAAAwPfmzZtn2daCXJ78/t2pUyfLtmaLHjlyJGLbsS3HpYvc4XiO41rBOpCWJk0ar5Yu0mrOjgW3HNcxDqZ78RdBHxyrmjVrmiWYNE06Xbp0ls+iSgfRALlOnTqyYMECGTt2bIzmKwMAAAC+FozVqnWQSqcy2qtbt65HbehSq7pGsmPVa5vs2bNbPjt//rzH/dT1lu1lzpzZ6Zhs2bJFeU50tG6SPc1y1VF0e8F0L/4iqNOq7WlQrPOOtSiXjiQvXrxY1qxZY0aN9S+SPtHQJyX6FEN/qDT9QhcYL168eHx3HQAAAAh6OorpOJ/VMdB1R/78+eXw4cMR2/r7vv3ayfaOHTvmcfuO5+TLl8/pGL2OfaDv6XXcvUZU5wTSvfiLkAmO7fPbn3zySfMCAAAA4B9cLe8Tk1o/jvNZ7VN6NXDWSsm2IFwDZ6075Mkc2gMHDli2CxYs6HSMFvXV7FOb/fv3e3QPjtcoUKCA0zHBdC/+IiTSqgEAAIBgEozVqnUOrWMbJ0+e9LgdXdopsvmtmtKrwZ79NEqdl+wunb9s375mpz700ENOx5UqVcqyvW3bNvGEfSq4Klu2rNMxwXQv/oLgGAAAAEC807Vzc+bMadmn0yA9nbfsGCDmyZPHsl29enXL9tKlS91uf9myZZbtypUrS8KEziFVxYoVLWv5ahVtdwtm6co5K1eutOyrVq2ay2OD6V78AcExAAAAAL8ppGtv2rRpTqvIRFftWpdmtV+2tUKFCpZjGjRoYNn+66+/TP2h6Gg/dKkpe02aNIk0tbtGjRqWoF3vxR1aH8m+uJau7xzZGs/BdC/+gOAYAAAACDDBWK1aPfXUU5ZtXXFm/Pjxbp2ry7IOHTrUsq9hw4Ym/dheiRIlpFixYhHbGryNGDEi2vYnTpxoKUyVKVOmKKtpP/vss5btb775Rk6cOBHlNXSZpCFDhlj2Pf/885EeH0z34g8IjgEAAAD4BZ2Pqkup2hs2bJhMmjQp2uWC3njjDTl+/HjEPg2K27dv7/L4d955x7Kty7ZqwBiZRYsWyaBBg5zacAy87dWrV0+KFi0asX3p0iV56623Il0K6dq1a9KxY0fLusy6XFPz5s0jvUaw3UtIBseae67V1G7cuBEflwcAAADgp3T5Vfv1drUas+57/fXXTdVk+7Tpo0ePynfffSePP/64U6GoDz74wGkOs306cq1atSz7PvnkE+natavs3r07IpVbl4Tq37+/vPvuuyad2L5IVXSBnhYX037bz+PV0dqnn35apkyZYipLq1u3bsmcOXPM6OyqVassbfTu3VuSJUsW5XWC6V7iW4IHniTxR8H+qYDSv4iOpddPnTplvkl//vlnRGCs6wh36tRJWrduLaEkedl28d0FAPCpjgM6xHcXAMCnBjcpLP6q4oAl4o/Wf1DbJ+1ooNu2bVszQumKLlekSzTZL9NkT0eRNe6Iirb9yiuvyD///OP0mY6iaizjajAvS5YsZiQ7V65cbt3Lr7/+Kn369HH5WerUqU1g6Soke/PNN6VLly5uXSOY7iXgR45XrFhhyn7bXrrmluP6VzpSXLVqVZk8ebJcv37dfNH0pfMI9C9vmzZtfNEVAAAAAAFORzN///13y3xaexqEuQqMkydPblKGowuMbUsX6XxmV0sLaduugkmNdX788Ue3g0mlo7I6khsWFub0mY6COwaTOjrbrl07j4LJYLqXgA+OJ0yYEBHs6lOJkiVLmspw9nT4Xofylf36Zbbzxo0bZ745AAAAAJA7d25TFVmLOj388MNRrqOcIUMGadWqlUm7btq0qdvX0DWQf/nlF5My7GqNX/vjNMibPn16lMdFFVTOmDFDGjdu7DKwtF+aSecLRzZXOlTuJaDTqrNly2YmwT/xxBMm51+H5x3TIsqUKRPxF1r/on/66adSunRpM0/g448/NjnpBQsWdJkKEIxIqwYQbEirBhBs/DmtutJA/0yrXtfLN2nVrly4cEE2bdpk4g5dZ1cDs/Tp00uRIkXMK6rg2V3//vuvmUur19C5zjoiq4WodCqorsPsC5pFu379epNZq/ek95EjRw4pV66cqRrtK8F0L3HF66/Kzp075cyZM+ZpjqY+uPpCf//99+Zd43BNdVi8eHHEUwr9Bul6ZhoYayr2jh07TElyAAAAALAfHa5fv36sXiMu1uHVDFvHAlqxIZjuJWDSqrds2RIxydpVYKwBsQbN+iRHXzqx3nH4Xp8waClwtXnzZm+7BAAAAABA3I4cawVqDXojG+3VdGk9RulxtiDYkZ6vgbSOQgMAAACInC9SiAH4eORY89dtaxe7oute2X6Ay5cvb1k82p5tLbPIyrEDAAAAAOC3wbFOgne1zrEt0NV1s2xeeumlSNuxrWGm62MBAAAAABBQwbEu26Tp0Lp+sSOtXK3V0ZQu8dSiRYtI21mzZo0ZXfZknS0AAAAgFGlWtT++gJAOjitVqmSWbtI1xd577z0zgnzlyhWzCPX7778fUYjrsccec1riyX7U+IcffogItgEAAAAACKjgWCtUd+vWzYweDx8+3FSi1lTr1q1bm3WvdH/ChAnlww8/dHn+ypUrpV69eqZoV548eaRAgQLedgkAAAAAgLgNjlWXLl2kadOmJhC2vez17t3bFOOyN3r0aEmTJo088sgjZjkoHV1++umnfdEdAAAAIKjZsjP97QVIqAfHOjKsVanHjBkjVapUkVSpUknSpEmlQoUK8vPPP0ufPn2cztHU6/DwcEtArWsgAwAAAAAQ1xI8cBzmRZxIXrZdfHcBAHyq44AO8d0FAPCpwU0Ki7+q+uky8UerezwS310AYixxfHcAAAAAgGfIYAb8NK0aAAAAAIBA5jfBcePGjU3lawAAAAAA4ppfRaNMfwYAAACiR2VoIIhHjgEAAAAA8OuR40SJEsV+TwAAAAAA8OfgOK7SnUkPAQAAAKLHr81APKZVE7gCAAAAACTUC3I98sgjMn78+FjryKuvvirLly+PtfYBAAAAAPA6OE6ePLnkzZtXYou2DwAAACB6ZHUCQVytmmWcAAAAAAB+PXJ88ODBWB/Z/fHHH+XGjRuxeg0AAAAAAGIcHMdmOrVNlixZYv0aAAAAQDAgrRoIwLRqTZe+fPmyHDlyJLYvBQAAAABA7Bbk8sSaNWvk559/lrVr18qOHTvk9u3b5unW3bt3I47p06eP3L9/X95++23JmTNnbHQDAAAAAIC4HznetWuXVKtWTapXry6jR4+WTZs2ya1bt8zosWPBrX///VcGDRokBQsWlIEDB/qyGwAAAEBQ06xqf3wBgcxnwfG8efOkQoUKZrTYFgxHVYFaj02XLp0Jnnv37i1vvvmmr7oCAAAAAEDcB8f79u2TZ555JmKUOGnSpFKjRg1p06aNvPfee1KgQAGnc7p27SrHjx83o8ZJkiSR77//XiZPnuyL7gAAAAAAEPdzjrt162aWYUqRIoX07dvXjAKnSZMm4vNt27bJgQMHnM4LCwuT999/X4oUKSLNmjWTfv36yQsvvOCLLgEAAABBi2rVgB+OHF+4cEFmzpxpRovnz59vRortA2N36KjzU089JXv27DEFvAAAAAAACKjgeOnSpXLv3j1p27atVK1aNcbtPPvssyYlW4t4AQAAAAAQUGnVOm9Y0zoaNmzoVTt58+Y176dPn/a2SwAAAEBQI6sa8MOR42vXrpl3T1OpI2sHAAAAAICAC44zZ85s0qF1vrA3Nm7caEags2TJ4m2XAAAAAACI2+C4ZMmS5v3rr7+WO3fuxKiN69evy5gxY8yfy5cv722XAAAAgKCmg0r++AJCOjiuWLGi5MqVy1SZbtq0qVy8eNGj83UJqObNm8vhw4fNesglSpTwtksAAAAAAMRtcKz69OljUqtnzZolBQsWlB49esiaNWuiHEnet2+fDBs2TAoXLmzO0ydNH330kS+6AwAAAABA3FarVq1bt5a///7bvC5duiRDhw41r8SJE5tRZV0LWVWqVEnCw8Pl2LFjEQW4NKhWzz//vLz44ou+6A4AAAAQ1MhgBvx05FhHfadMmSLPPPNMRLCr7zpyfPDgQbly5UpE0S0t3KUBsn5uO1bTqn/66SdfdAUAAAAAgPgJjlXSpEll6tSpMnbs2Ig1i23sA2Z7+fPnlwkTJsikSZMkSZIkvuoKAAAAAABxn1Ztr1WrVvLqq6/KvHnzZPHixbJp0yY5d+6cGS1OnTq1ZMqUyVSkrlOnjtSvX5+qdgAAAICHEvI7NOD/wbHSgLdhw4bmBQAAAABAyKRVAwAAAAAQqGJl5BgAAABA7CGrGgig4PjMmTOydu1a2bZtm5w/f94s3ZQqVSrJmDGjlCpVSipXriyZM2eOrcsDAAAAABB/wfHChQvNGscLFiyQ+/fvR3pcwoQJpUGDBtK1a1epW7eur7sBAAAAAEDczzm+deuWvPzyyybg1UrV9+7dc1q6yUb36+dz5syRRx99VFq2bGnOBwAAAOBeAVx/fAES6iPHt2/fNpWply9fbrbtg+LIAmT7zyZOnChHjhwxQbWulwwAAAAAQMCNHPfu3VuWLVsWEexqoDxixAiz7+jRo3Lp0iW5efOmedcgeMmSJfL5559HrHOs52lg3adPH190BwAAAAAAjyR4ENXQrhuuXLki2bJlM2nRJUqUkF9++UUefvhht8/funWrScfeuXOnhIWFyalTpyRNmjQS7JKXbRffXQAAn+o4oEN8dwEAfGpwk8LirxqPXiv+aPbbleO7C0D8jRzPnz/fjArnypXLjAh7Ehir0qVLm/P0fA2wtT0AAAAAAAIqOD506JB5b9++vaRPnz5GbejyTnq+Onz4sLddAgAAAAAgbgtyJU6c2MwbLleunFftlC9f3sw91vYAAAAARI7K0IAfjhznzJnTvN+5c8erdvR8/SHX9GoAAAAAAAIqOK5Tp44Z7V21apVX7axcuVKSJUsmdevW9bZLAAAAAADEbXCs84VffPFF+fLLL82yTTGhyzt99dVX8vrrr0u6dOm87RIAAAAQ1DSr2h9fgIT6Osca2ObOnVuqVasm8+bN8+hcrU5do0YNKVmypAwfPtwX3QEAAAAAwCNuVb9atmxZtMcMHjxYevToIY0bN5ZixYqZd13WKUuWLJIyZUozn1gLbl27dk3OnDlj1jWePXu27N69W2rWrCm9e/eWNWvWyCOPPOLZHQAAAAAAEBfBce3atd2uiKcB8K5du0zQ686xavny5dKgQQNzjbt377p1HQAAACBUJRBymAFf82jdJFswGxkNbm1BdHTH2o53t20AAAAAAOI9OA4LCzMp0rHl9OnTcuvWrVhrHwAAAAAAr4PjWrVqyaxZsyS26BxlT4t5AQAAAKEoIVnVgH9WqwYAAAAAIOiD4zx58kjWrFljtSOasq3XAQAAAADAL9OqDx06FOsdmTBhQqxfAwAAAAgG7q4kAyAA06rPnj0rR44cie9uAAAAAABCkN8Exy1btpT8+fPHdzcAAAAAACHIo3WOYxtrHQMAAADRI6saCJDg+MaNG7J582azdnF4eLhbQe/x48djoysAAAAAAMRtcLxlyxb5+OOPzXrId+/e9ehcDaApLAAAAAAACOjgWKtNv/XWW3L79m3SowEAAIBYlJBBJcA/g+OVK1dK27ZtI0aLM2XKJAUKFJCwsDDZtm2bXLp0SR555BHLOTdv3pR9+/bJ+fPnzYhxmTJlJE2aNL7oDgAAAAAAcR8cv//++yYwzpMnj3z33XfSoEGDiM8aN24s8+bNk8WLF7s8d8aMGfLOO++YQFrTsQEAAAAACLilnHRtYh05Tps2rSxdutQSGLvj8ccfl2XLlsmePXvko48+8rY7AAAAQNDTrGp/fAEhHRyvXr3avLdu3Vry5s0bozby5csn7dq1k5EjR8q1a9e87RIAAAAAAHEbHJ88edLMGa5Vq5ZX7dSsWVNu3boVafo1AAAAAAB+O+f4+vXr5j1dunQuP0+aNGnEcSlSpIi0nSRJkpj3Q4cOedslAAAAIKixBCrghyPHOtdYHT16NMrPd+3aFWU7O3fuNO/h4eHedgkAAAAAgLgNjgsWLGjWNV6wYIHLzwsVKmQ+HzduXKRt6NrIX3/9tXkClj59em+7BAAAAABA3AbH5cqVM0HtTz/9JIsWLXL6vFq1aub922+/lS+//NIEyvbOnj0rzZo1k927d5vtsmXLetslAAAAIKjFd1VqqlUjGHkdHGfOnNkEtPfu3ZNGjRpJhw4dZMWKFRGf16lTR3Lnzm2C4k6dOkmuXLnkmWeekZYtW0r9+vVNhWtd31gD7Pz580vFihW97RIAAAAAAHFbkEu98MILsmnTJrl796589dVXMn36dLP+sUqYMKEMGzZMnn/+eRMAa3Xrv/76K+Jc20iyfqbHUVwAAAAAABCQwfFrr71mRo5t0qRJY/n82WeflcGDB0uvXr1MMOyYWp04cWIZMWKEPPnkk77oDgAAABDUEjKgBPhncJwxY0bp0aNHlMd0795dGjZsaOYeb9iwQS5fvmzOq169urz55pumsBcAAAAAAAEbHLurdOnSMmrUqLi8JAAAAAAA/hUcAwAAAPAeSdWAH1ar9pWFCxfKjz/+GN/dAAAAAACEIL8JjocOHWoKewEAAAAAENdIqwYAAAACDMufAvEUHMdFuvPx48dj/RoAAAAAAMQ4OG7VqlWsP53StY95AgYAAAAA8Pu0ag1gAQAAAMSvhIwpAfEXHKdPn15KliwpsWXbtm1y6dKlWGsfAAAAAACvg+NKlSrJrFmzJLY0btxY5s2bF2vtAwAAAAAQGapVAwAAAAGGWj1APAXHjzzyiJQqVUpik6Zs37x5M1avAQAAAABAjIPjJUuWSGz77LPPYv0aAAAAAAC4Qlo1AAAAEGDIqgZ8L2EstAkAAAAAQEAhOAYAAAAAhDzSqgEAAIAAQ7VqwPcIjgEAAAD4tfv378uGDRtkzpw5smXLFjlz5oxcunRJUqVKJdmzZ5eKFSvKk08+KSVKlIhR+7dv35ZZs2bJokWLZMeOHXLx4kW5c+eOpE+fXgoXLix16tSRp59+2lzPG/v375epU6fK+vXr5ejRo3L16lVJliyZ5MqVS8qVK2fuQd+9EUz3EtcSPHjw4EGcXxWSvGy7+O4CAPhUxwEd4rsLAOBTg5sUFn/V8pdt4o9+fNH3y79qgNenTx/ZuXNntMfWrVtXBgwYIBkyZHC7/RUrVsgHH3wgp06divK4tGnTSv/+/aVBgwbiqfDwcBk4cKBMmzZNogu/Hn30UXMPej1PBdO9xAfmHAMAAAABJmEC/3z52uTJk+X55593KzBWOlqqo6I6kulu+23atIk2mFSXL1+W9u3by9ChQ8UTFy5ckBdffNGMsrozLjl//nx56qmn5NChQx5dJ5juJb6QVg0AAADA7/z+++/y0UcfWYKwJEmSmLTgkiVLStKkSU0QrAHY6dOnI47RP7du3Vr++OMPSZkyZaTtL1682Kn9sLAwqV+/vhQpUsRs7927V+bNm2dSlW3GjBkjefPmleeeey7ae7h796688847ph17hQoVktq1a0umTJnk3Llzpi/79u2L+PzkyZPmvN9++82t9Odgupf4RFp1PCGtGkCwIa0aQLDx57TqVpP8M616fAvfpFXrSHHz5s3NXFkbnb86ZMgQM6fV3q1bt+SLL76QsWPHWvZrgNy9e3eX7et85UaNGpn5uDYVKlSQ4cOHS9asWS3HarDdpUsXM+fZPkifOXOmCSyj8tVXX8mXX35pOU9TxHU03NGUKVOkX79+5n5smjVrZlKYoxJM9xLfSKsGAAAAArBatT++fKVv376WwLhatWoyYcIEp8BYaRGoHj16yOuvv27ZP2nSJLl27ZrL9r/99ltLMKmjq999951TMKl0nwbepUuXjtinfRs1alSU96CjqD/88INln87zdRVMKh291TRn+6/j9OnT5fDhw1FeJ5juJb4RHAMAAADwG5qWu3379ojtzJkzm5FhTaOOSocOHSyFuK5fvy4LFixwOk4DZp2f6xjoRZWCrQH4iBEjJHny5BH7/v777yjnNmtwrn2weeSRR8x86KhogayXX345YvvevXsm+I1MMN2LP/Cb4Fir0C1btiy+uwEAAAAgHv3666+W7W7durlV7ViDvccee8yyT5d9cqTLQdkHepquXapU9OngumSULk9kH+xpW5HROc/2XnvtNXFH27ZtJVGiRBHbOk/YfhQ9WO/FH/hNcPzee++ZyfUAAAAAopbAT1/e0rVyly9fbgniHn/8cbfP17m3OmKp85Xffvttk47taOnSpZbthg0but1+48aNLdtaDMyVf//9V44fPx6xnS5dOqlcubJb19DU5zJlyli+JqtXr3Z5bDDdiz+gWjUAAAAAv7Bq1SpTFdk+gEuc2P2QRQtR6Ssq69ats2y7G+jZRma1P7Y+btu2zcz3TZ8+veW4tWvXWrbLly9vGUGNTqVKlWTjxo0R25phq6nMwXwv/sCtv2lxke6sa2YBAAAACF2bN2+2bFetWtWn7Wu1ZvviVVpxWZcicpfO182fP7/8888/ZlsX/tm1a5dUr17dctyePXss28WLF/eon47H6xTUYL6XgAqOdd0qX1afc0W/GbF9DQAAACAYJAzS35t1CSdvArHo7N+/37KdO3duj0amVZ48eSICSnXw4EGngNLxOhqEenoNe3qNYL4Xf+HRV48lkQEAAADEFvulflKkSCGZMmWK2NZR0j///NPMs9WA7vLly5IqVSozL7lGjRryxBNPSOHCUa9NbT93VmXLls3jPjoukeTYpjpx4kSU50QnS5YsTmsZa2Vq+yrUwXQvARcch4WFOd2Yo/DwcJMebQuiNRddK8vpX1odFdb9eoz+RdaKaEr36xdYh/UBAAAAhKbbt2/LmTNnLEs4qfv378uYMWNk9OjRcuPGDcs5GjDrS9OBv//+e3n22Wele/fukjp1aremcmbMmNHjftovF2XrQ3TXsQ/y3aHzfhMmTGju3f469gFlMN1LwAXHtWrVklmzZkX6+ZIlS+Sll14yC3O/++67ZvJ80aJFTe67Iy3frbnrs2fPNn/JNfCeOHGimRQOAAAAIGr+mlVdr169KD9fuHBhpJ9pwGSfqaoDbLdu3ZL27ds7VWV2RYOv3377TbZu3WoCZVcDezpqaU+v4SnHoE4H/uzpqKgG+t5cRwcQdWkqbcvmypUrQXsvQVWtetOmTdKkSRN5/vnn5bvvvot2gW4NmEuWLGlenTt3ljfeeEPq1q1rKqEVKVLEF10CAAAAEEAcgz2NKXS5V/vAOEeOHGb5V51fqwNuml69ePFik51qs3fvXrMO7++//26CMnsabNtz/Nwd0bXpuB3T62hauX1AefPmzaC9l4AKjnUifL58+SL9vHXr1lKiRAkZN26cx0W1NFD+4YcfzOR7/Uus5dsBAAAABJ6oRoaj4xgwaVVjDYBtMYMGyi+//LLTMkIaVA8YMED++uuviH379u2TTz75RAYNGmQ51nEU1NMCVsrx+rY+Rrbtq+vYL3EVbPfiLxK6c5D+xRw1apTLzzRtQV86+hvTatOag67n68ixY4U6AAAAAFb6e7c/vrwRWWCmgZVOxXz11Vddrq+bLl06GTJkiDRv3tyy/48//jBBsj1b3SP7OMRTjuc4Fi12vIavrmM/ZzfY7sVfeH5nDrZs2WJ+EKKrDBcdPV+/GZqiDQAAAADq7bfflpo1a0Z73IcffmhZZkhji7Fjx1qOcayH5Cr4i47jqKdjm65GVmNyHceHBY7XCaZ7CZrgWBefdjV521O280+ePOltlwAAAAAEGFeBmFad1qmX7tA5yq+//rpl37Jly5yOiS5t2NOA0rFNV/WX4uI6gXwvQRMcp0mTxjyVmTlzplftzJgxw4xAa3sAAAAAIqcZzP748oauYOOoevXqHlVHdqyWffbsWTl06FDEtuMST9evX/e4n/aFpVxVfNZrOKaYO57jq+sEy70ETXCshbiUpizMnz8/Rm3MnTs3IuXB1h4AAACA0KHr4TryNDbQdXuzZ89u2Wefmep4jZhkvzqe47hWsM6Ldhzw83TpIi1O5lhwy3Ed42C6l6AJjmvUqCF58+Y1ueePPfaYvP/++26nRp84ccJUnXviiSfMpGytiK3tAQAAAAgtGpg5Fm7SYluecgwadf1kG8fA+fz58x63f+7cOct25syZnY7Jli1blOdER0e8HdOQ06ZNa9kXTPcSVOscf/XVVybA1QBZK8UNHTpUSpUqJWXLljUBrz5tSJYsmVknS580HDhwQDZv3myqYGtKtr50uF7bAQAAABC1hN7mMPshLdKkAd/x48e9Wg83qgrMuj6yvWPHjnncvuM5rpa81evoessxvY6714jqnEC6l6AKjnXEeNiwYdKtWzezraPAtiWeomL7i6qB8YgRI6Rx48a+6A4AAACAAKQr2NgHx2fOnPG4Dce0X/tRSq1mrUG4raiUFhcODw/3aF6zDvTZK1iwoNMxRYoUkQULFkRs79+/36N7cLxGgQIFnI4JpnsJmrRqm86dO5uFt/PkyeNyjSxHts8feughmTVrlrRr185XXQEAAAAQgEqXLu20bKwntCiVfXDtOFKpKb0a7NnHJNu3b3e7/SNHjsiFCxcsad8azzjSLFp727ZtE0843rdm5DoKpnsJuuDYNoK8Z88emTBhgjRq1CiikrXjS5/eNGnSRCZOnCi7d++Whg0b+rIbAAAAQFALxmrVyrH+0MaNGy0BXHQ2bNhgWYdX59DmypXLqQK2vaVLl7rdvuPSUJUrV3ZK41YVK1a0rOWrGbXuFszS/q9cudKyr1q1ai6PDaZ7CbrgWOnc4ldeecWMBuvk98OHD8umTZtk+fLl5l239S+4Lt3UokULv13jCgAAAEDc0urUtkxUW3A1fvx4t8+fNGmSZbtu3bpOxzRo0MCyrdmv7sxt1kG+3377zbJPB/xc0aWK7AN9Xed32rRp4o6FCxdaimsVKlTIvFwJpnsJyuDY1QTuMmXKmKca+u44cRwAAAAAbLWIXnrpJcs+XfJ137590Z67ePFiWbRokWXfCy+84DIAL1asWMS2Bm9a/yg6mvVqX5gqU6ZMLoNvm2effday/c0335jVeqKbL60Fju09//zzkR4fTPcSEsExAAAAAN8Hkf748oUXX3zRkgqtBadatWplpm9GRjNUbcWBberXry/Fixd3efw777zjFIBrwBgZDboHDRrk1EZUWbD16tWTokWLRmxfunRJ3nrrrUiXQrp27Zp07NjRzAW20erdzZs3j/QawXYvQR8c6xMFzUt3zGkHAAAAAEcapOmIo32wpmvl6pTMkSNHytGjRyP26591GdmWLVuaSs32xaV69eoV6TU0HblWrVqWfZ988ol07drV1ESyFQ/WKaH9+/eXd99916QT2xepii7Q04cFH330kWUer47WPv300zJlypSI/upyt3PmzDGjs6tWrbK00bt3bzNtNSrBdC/xLcGD6MpKe+j27dsmB/3nn3+WtWvXRkyg1y+o/TdBnzToF7FTp05SoUIFCTXJy1KdG0Bw6TigQ3x3AQB8anCTwuKv3v1jt/ijr5/5L8XXW1pcqn379ibgcjUPVsMYrU7tSAOwb7/9VqpWrRpl+zr6qbWS/vnnH6fPNDBPlCiR3Lhxw+mzLFmymLnNjoW+IvPrr79Knz59XH6WOnVqExO5CsnefPNN6dKli1vXCKZ7CZrgeP78+ebG9amEsm9ag2P7ynH65Ee/uLq/devW8uWXX/r9kwRfuvnfcwIACAr37vv0WSsAxLuUSX2TJhwb2vtpcPylD4NjtX79ejMCbJ+eG5WsWbPK8OHD3R580zm6OpK6efNmt47XpY5Gjx7tcsmjqGjcM3DgQLeKZenorKY564MBTwTTvQR8cKzLN2mQa1uuyelCDsHxjz/+KIMHDzZzB/QzrY72999/S6ggOAYQbAiOAQQbguP4D46Vjhz/8MMPMn369IhBOEcZM2aU5557Ttq0aWNGMD1x//59E/BpPHPw4MFI29fBvbZt20pYWFiM7kNTwIcNG2YKh0UWWGoR43bt2km5cuVidI1gupeADY51/TFdF8sWGGfLls1MgNdJ2+nTpzdPJHbu3GkJjm0mT54sb7/9tqlmpnMI9GlHKCA4BhBsCI4BBBuCY/8Iju3pwNqBAwfkzJkzJmjWucVFihQxVZsTJ07sdfv//vuvmUurc5y1EJi2rzGNFvbyRftKU8F1RPz06dNmCqoGqDly5DBBpFaN9pVgupeACo5r165tCm5pzrqmR+sEbPtqdY0bN5Z58+a5DI6VTtbWNvQLeejQIQkFBMcAgg3BMYBg48/BcYfpkVdujk8jn/6vojEQaLyuVn3y5ElZvny5SV/Qd01n8LSMe7Vq1cwaZDo8r6PQAAAAAAAEVHCsI8Y6+Kzp0IUKFYpxO0888YRpZ8uWLd52CQAAAAAAj3idbH7q1CkzUvzII4941Y6mVNuqrAEAAACIXEL/zfgGQnfk2LbuWEwrndlcvnzZvOsaXAAAAAAABFRwrGuJaTr01q1bvWpHi3LpCLRWugYAAAAAIKCC4/Lly5v3ESNGyNWrV2PUhqZSf/fdd+bPVatW9bZLAAAAQNCnVfvjCwjp4FjXFCtcuLBZkLtu3bqyb98+j84/ceKENGnSRM6dOyelS5eW/Pnze9slAAAAAADiNjhWgwYNMqnVmzZtkocfflief/55mTx5slmz2NUyyjpSvGDBAmnfvr1ZtFsXjtaUam0HAAAAAIC4luCBq+g1Bt5++2359ttvndY4Tpw4sdl3584dyZgxo4SHh0cU8VK2y3fu3FmGDRsmoeLm3fjuAQD41r37PvnfCQD4jZRJ/TdPuOvfe8UfDXuiSHx3AYjfkWM1evRoE+DaB7z6rkGxvpSmTt+8edPyuQbOPXr0CKnAGAAAAAAQpMGx0gB3/vz5UqNGDUs6tf7ZcYBat2vVqiWLFi0inRoAAAAAEK8S+7pBLcqlr71798rixYvNPGQdMdZ06tSpU0umTJlMhes6depIoUKFfH15AAAAIOhRGRoIgODYRgtt6QsAAAAAgJBIq/7xxx9l4cKFvmgKAAAAAIDADI5btWolw4cP90VTAAAAAKKhC8T44wsIZD4ryHXmzBm5ePGir5oDAAAAACDwgmMtvJUjRw5p3ry5zJ0716k6NQAAAAAAQR8cp0+fXpImTSpTpkyRJk2aSN68eaVPnz5y4MABX10CAAAAgKlWncAvX0Ag81lwXKlSJTl58qSMHTtWqlWrJseOHZP+/fub5Zrq1asnEydOlJs3b/rqcgAAAAAA+F9wrFKkSGGKcy1fvtysc9y9e3fJli2bWe+4ZcuWkj17dnnnnXdk/fr1vrwsAAAAAABeSfDAB5ODJ0yYIDlz5pT69es7fXb//n2ZOXOm/PDDDzJr1iy5e/euJEiQQEqUKCGvv/66vPzyy5IxY0YJNTfvxncPAMC37t2n1gSA4JIyqf+mCfea9Y/4o4FNCsd3F4D4DY49qWitgbSmXuvIsgbJSZIkkSeffFJee+01adSokdkXCgiOAQQbgmMAwYbg2HMExwhkcRoc21u9erV89tln8ueff0YExDr6fOTIEQkFBMcAgg3BMYBgQ3DsOYJjBLLE8XHRefPmmdHjOXPmRATGGqMfP348ProDAAAABJQQSbYEgjM4PnTokIwbN86kVR89etTymW3wuly5cnHVHQAAAAAAfBscJ0qUyMwX1sJb9m7duiVTp041o8RLliwxQbBjFrcW43rppZdMca5SpUr5ojsAAAAAAMR9cOwY9G7cuNEExJMmTZLLly9HHGMfTDdo0MAExFqMS4tyAQAAAHBPQvKqAf9Nq7569aqMHDnSBMXbt283+xxHiQsVKmSqUr/66qtmzWMAAAAAAIIqOF61apV5OQbFqVKlkueee86MElevXt1XlwMAAAAAwD8LctkHxTVq1DABsQbGKVOm9OVlAAAAgJBGVjXg58GxrlPcsmVLkzpdsGBBXzYNAAAAAID/B8c1a9aURYsWScKECX3VJAAAAAAAgRUcp0iRgsAYAAAAiAMJSasGfM7raPbUqVOSN29eWbduneTPn9+8Bg8e7JveAQAAAAAQCCPHmzZtksOHD0uCBAnkwoULZp/tHQAAAACAkAiODx06FPHnFi1aSN++fc3oMQAAAIDYkZBy1YD/BcdXrlwx7/ny5ZOffvqJeccAAAAAgIDjdSSbLVs2816qVCkCYwAAAABAaI4clyhRwrxfvHjRq3bOnj0rN27ckDx58njbJQAAACCokVUN+J7XQ70VKlSQ0qVLy5o1a+T8+fMxbqdly5bMVQYAAAAAxAuf5EF/++23kjhxYmndurXcvXs3xu08ePDAF90BAAAAACDug+NKlSrJjBkzZPPmzVK9enVZsGABgS4AAAAQSxIm8M8XENJzjtXrr79u3itWrCjTp0+Xhg0bStq0aU2RLi3YlSJFimjb2L59uy+6AgAAAACAxxI88MEQr1apTmBXFcDWpP2+6Og5evy9e/ckFNyMefY5APile/fJGAIQXFIm9d+h0AEL94k/+qBewfjuAhC/I8fKVYxNajUAAADgewnEfwN3QEI9ONYlnZo1axbj83/++Wc5cOCAr7oDAAAAAED8BMd9+/aN8fm6FBTBMQAAAAAgoINjb5GCDQAAALiHytCAnwbHHTt2lPLly3vVRrdu3aRFixa+6A4AAAAAAHFfrRqeo1o1gGBDtWoAwcafq1UPXrRf/NH7dQvEdxeAwE+rBgAAAOAe0qqBAAuOw8PDZdu2bXL27Fm5fPmytGzZMuKz27dvS9KkSWPz8gAAAAAAxE9wrIHwDz/8YJZm2rNnj6XQln1w/Nprr8nhw4elU6dO8uyzz/q6GwAAAAAAxE9wrEHxe++9Z0aJlX1gnCCBNffj/v37smrVKlm9erU8+uijMmnSJEmfPr0vuwMAAAAEJcffrQF4L6H4SP/+/eWNN94wgbEGxdHV+dJR5AYNGpg/z58/Xxo3bix37tzxVXcAAAAAAIjb4HjhwoXSp0+fiKC4UqVK8uGHH5rU6pkzZ0rFihWdztFgeM6cObJixQrJkSOHrF+/XgYPHuyL7gAAAAAAEPdLOZUrV062bNkihQsXlh9//NEEx46B8Lx58+TevXsuz9e5ybpOcqpUqeT48eOSOHHwF9FmKScAwYalnAAEG39eymnY0gPij7rWyh/fXQDib+T4wIEDJjDOkiWLLF++3CkwdkfRokWlVatWcu7cOVm3bp23XQIAAAAAIG6DYy2opdq3by+ZM2eOcTs6/1gHsXfs2OFtlwAAAAAA8IjX+cunT5821fJiMmJsL1OmTOb9woUL3nYJAAAACGoUqwb8cORYl2RSiRIl8qqd8+fPm/ewsDBvuwQAAAAAQNwGx9mzZzfp0GvWrPGqncWLF5sRaG0PAAAAAICACo6rVq1q3r/44gs5efJkjNo4dOiQfP/99+bPNWvW9LZLAAAAQFBLmCCBX76AkA6O8+fPb5Zh0krT1apVk6VLl3p0/ubNm6VevXpy/fp1ExjrmscAAAAAAMQlnywoPHToUKlTp44cOXJE6tata4Llpk2bSpUqVaRAgQIR6xvfuHFDrl69KkePHjVB8Z9//imzZ88285YTJkwon332mS+6AwAAAABA3AfHtWrVkgEDBsgHH3xg5g1v3LjRvOzpvORUqVI5nav7bQG2txWvAQAAgFCQkAxmwP/Sqm169uwpI0aMkGTJkkUEvPpu+7MGzbZt+8+TJ08uo0aNkk6dOvmqKwAAAAAAxE9wrNq3b2/SpV9++WVJkiRJxH77gNgmadKk8uqrr5rj33rrLV92AwAAAAAAjyR44Bi1+siVK1dk1apVsmnTJlOsKzw8XFKnTi2ZMmUyc5K1eJerNOtQcfNufPcAAHzr3v1Y+d8JAMSblEn9N3f5y5UHxR+1r/5QfHcB8L/gGFEjOAYQbAiOAQQbgmPPERwjkPk0rRoAAAAAgJCtVg0AAAAg7iQU/x3VBgJVnI4cawb3mDFjpEGDBlKsWDGpXLmyKeK1e/fuuOwGAAAAAAC+n3O8b98+E/BGNJoggSxYsEAeeui/OQd37tyRp556SubOnet0vla2/uabb6RVq1YSKphzDCDYMOcYQLDx5znHX688JP7o3er54rsLQPymVY8bN04OHToUsZaxLRi217dvX5kzZ475s/1x6vbt29K2bVspWrSoVKlSxRddAgAAAIJWAv+N24HQTqueNm2aCXjz5csnv//+u1y8eFEKFy4c8fmpU6fk888/N8foK1GiRPLmm2/KqFGjpGfPnpIxY0a5d++e9OjRwxfdAQAAAAAgbkeOjxw5Inv37jXrF69cuVKyZcvmdMzYsWPl1q1b5s8aHP/111/SqFGjiM/btGkjJUuWlBUrVsixY8ckV65c3nYLAAAAAIC4GznetGmTeX/nnXdcBsZq0qRJEYGxzju2D4yVzk1+7bXXzJ/Xrl3rbZcAAACAoJYwgX++gJAOjg8fPmyC3qpVq7r8/J9//pGdO3dGbHfo0MHlcTVq1DDzkHXkGAAAAACAgAqOr127Zt6TJ0/u8nOdg2yTJ08eqV27tsvjcuTIYWkPAAAAAICAmXOcOnVq837y5EmXn//888/mXUeXW7RoEWk7WrE6qiAbAAAAwP8kpFw14H8jx1qVWtOh58+f7/SZLt20Z8+eiO1XXnkl0na2b99uAuisWbN62yUAAAAAAOI2ONa5xmFhYTJx4kSZMWOGZa7xu+++a/6sQW+FChWkWLFiLtu4f/++TJgwwfy5ePHi3nYJAAAAAIC4TatOkyaNGREeM2aMqUSdN29eSZcunezatUvu3LkTcdx7773n8vzr16+bIl1bt24155UqVcrjPui6yn///XfEdrNmzSRlypQxvCMAAADAv5FVDfhhcKw+/fRTWbp0qRkt1urV+tJUax0xVo8//rg8++yzlnNmzpwpo0aNktWrV8vly5fNsY0bN5aECT0fzNZR565du1oqX+fPn98HdwYAAAAACAVep1UrHfFdvny5vPTSS5IkSRITGKtEiRJJmzZtZPLkyU7n7NixQ2bPni2XLl0yx+vLttaxpxYuXGjOL1mypPz444+SM2dOr+8JAAAAABA6EjywRbI+Eh4ebkaQNaVa5xhr2rUrR48elQMHDvzXkQQJ5JFHHonRNYsUKSInTpww7WXOnNnpcx1F1iWkxo4dK/7i5t347gEA+Na9+z793wkAxLuUSf03d/mHdUfEH7WulCe+uwDEb1q1vVSpUkm5cuWiPS537tzm5QunT582o8auAmN16NAhOXXqlFfXaNWqlRkd379/v1ftAAAAAACCNK06vt28edOkc8cmDcA1yAYAAAAABB+fjxzHBx0x1mrX165do0o1AAAAgh7VqoEAGTnW+b9Dhw41SyoVKlRIMmTIIMmSJZOMGTNK4cKFTeXqYcOGycmTJ31yPV1D+erVq9K8eXPZs2ePT9oEAAAAAIQOnxbkOnPmjFlSSatT379/3+xz1bxtiSetZt2iRQsZMmSIZMmSJcbXnT59ujRt2jSiXR09Tp8+vWlfaTp08uTJJWvWrDG+hs5ZvnXrlty7d098gYJcAIINBbkABBt/Lsg1dr1/FuR6vSIFuRC4fBYcr1u3Th577DG5cOFCxBrHUTVt+1zfdUR5xowZUqlSpRhf/4UXXpDffvvN0r6N/ZrLMWVrg+AYAFwjOAYQbPw5OB7vp8FxK4JjhPqcY126qV69enL9+vWIgFgDyYceesi8UqdOLWFhYaZw1pUrV8ySS0eOHIlY3/jcuXNSv3592bhxo0nDjolffvlFypYtKyNHjjTp2o6BuY9XrAIAAAAABBGfjBzXqlXLLHOkdPS3c+fO0rBhQ0mXLl2k51y8eFFmzZolI0aMkA0bNph9us7xkiVLvO2OCb61uvTt27dNUFy3bl3Tr08//TTGbXbv3t30k5FjAHCNkWMAwYaRY88xcoyQDo61AFbx4sXNSHGvXr2kX79+Hp2vl//ggw9k8ODBpo2dO3dK0aJFxZcSJkwojRo1MsF4TDVu3FjmzZtHcAwAkSA4BhBs/Dk4nrDhqPijVyvkju8uAPFXrXr16tXm/dFHH/U4MFYaEA8cONCkVatVq1bFKK379ddfN6/WrVubNG1fIy0bAAAAAIJXYl9UqNYA99VXX/Wqnddee00WLFggZ8+e9fjcn376ScaPH2/+rH3RkehMmTJFfL548WKznJQ3tKK2FhsDAAAAAAQfr4NjW9CZK1cur9qxna+Vqz2l8501KH7llVdkwIABkjNnTsvnWhRMl3LyRsmSJb06HwAAAPAV/034BkI4rbpgwYIm5VjXAfaGnq8BbuHChT0+VytfZ86cWcaMGeMUGNuC41atWnnVPx3R1usAAAAAAIJPYl9Uqs6WLZtZY/i5556LcTu//vqrGT3WitWe0srUWo06SZIkLj+3LRnljZYtW8r8+fPl7l0qaQEAAAD+QmsOrVixwvxZB8oWLVrkcRv379+XhQsXmgK827ZtMwNjuvJNmjRppECBAlKzZk1p1qxZjLJc7emSs7///rusXbvWrLCjy9xqDKPxVJkyZaRJkybmWt4IpnsJuOBYK0EPGjTIzBn+4YcfzF9OT40dO1b++OMP88WNaR+uXbsmsY2iXAAAAPAHCROQWK2mTJkSERjH1Pbt2+X999+Xffv2OX12/vx581q3bp18/fXX0qNHD3nxxRc9voYGp19++aWJexwH2+7cuWOCS31NmzZNKlSoIEOHDpXs2bOH9L0EZFq10mJc/fv3l7ffftt8gdevX+/Webpu8EsvvSTt27eXUaNGyTPPPBOj6+fIkUO2bt0qhw4ditH5AAAAAAKLTsv89NNPvWpDC/e2aNHCZTDp6ObNm/Lxxx9L165dPRo00/PeeOMN+e6779zKQtUY6amnnpJNmzZJqN6LX48c6xJJ7ihUqJBJj9aXDtPr+sdZsmSRlClTmvnE+oXXEV6tcL1r1y7z5EJVrFjRDMfrUwwdffaUDtf/+++/UqdOHfMERNvTQmGJEiWKOObGjRtezRnW8wEAAAD4h969e8vVq1djfP7OnTulQ4cOZrTTRtOCdZpniRIlJFmyZLJ//36ZM2eOJUt1xowZZjpo586d3bqOxie25W9tNP1bl8LVEdWLFy+a5Ww1Bdrm8uXLZgBx6tSpJk05lO4lPiV44MajAk1b1uDWXbYmozonsmPu3bsnntqyZYsJiDW/PrJredL/qNqISf9cucnUZQBB5t59pp4ACC4pk/pv6vLPG4+JP3q5vHcr2LhLU3Z79uzptN/dOccaRD7xxBNy8OBBy0DfiBEjzLxcexqA9+rVy8zhtffzzz+bGCQq06dPNwGljcYTGihqxq3GWPZ0nrCmROvcXZsqVarIhAkTQuZeAiqt2lbYKrqXO8e7OiamdML3sGHDIr2mJ32Pqq8AAACAP0jgp6+4oMV4teaRNzTT1T6YzJo1q5lD6xhMqtSpU8vIkSPN6Kg93ReVW7duyeeff27Zp8Hku+++6xRMqnr16pnVd5ImTRqxb82aNeYVKvcSMAW59Iur84Njiz6t0InbMaVpBFqxWr+xOilff2js0wq8QYAMAAAA+Ie+fftGjEjapm56Qo8fN26cZZ+Ocup00MjodXR+s2asavVnpVNCdU6tFp1yZebMmZblbnXJWh1ljW7Qr0uXLjJ48OCIfaNHjzajrsF+LwEVHOt6xvoXMbboUwRvgmOlX2hXX2x9mtGoUSOZNWtWjNtu3LixU/oBAAAAgLijqb1aeMqmefPmMnnyZI/a0FpHx479l5auc2U1VoiO1lHS5V1tGau2ObuRBZSa+m1Pz3U1yupIi2ppsWLbAwANXDWIzZw5c1DfS9BUqwYAAAAQd7Scjj++YpMW9R04cGDEthaaiskyskuXLrVsa4qxO4Gecgw8FyxY4HLkWuf22ldo1kLB9evXd+saYWFhUrt27Yhtrauk1wn2e/EHbn3ldMQ4NlOq1csvvyx9+vQRf8X8YwAAACD+aEyilY9tlZg1UHY3EHQcbbVXuXJlt8/NkyePpeKyjoLu3r3b6ThNUbYv5KsFstKnT+/2dXS6qL1ly5YF/b0ETFp1bKZT28Rm8B1ZFWtPaNlzAAAAAHHvr7/+slShfvPNN6VIkSKWlGJ3aJDnuA6wLj/riWLFilnm3+7YscOpjT179nh1Dcfj9RrBfC8BN+cYAAAAgH/wdpnSQHLu3DkZMGCApRiUBscxocG0Vl62T/vVebqe0BFXe/aVom10TWF7Dz30kFfX0JRyXZ9Y5woH470EZXCsTwG0sJZWita/xDdv3pSMGTOaCdc6/K755ilSpPDlJQEAAAAEsY8++kguXboUMd9V06ntlwjyxIkTJyzbuuyRpw8a9Bx7x48fj/Y69unL7tAllzRuun79uqVNjamC8V6CJjjWpwufffaZTJ06Vc6fPx/lsTo3oGrVqtKpUyd56qmnJC5p4L5kyZIog3edwF6zZk3z1AUAAABA/NIlhObPnx+x3apVKylZsmSM23OMVzQW8FSGDBks2xcvXoz2OpkyZfL4Ojqv1z6gvHDhQtDeS8AHxxpYapCrC0xrvrt9sSrHJxa2z27fvm0mYOurbNmy8u2330r58uUltmi/Jk6caNbxcsyVt/XJvq9aylwD4zfeeMOsD+b4JAUAAADwB6Gw5IwGZf369YvYzpcvn3Ts2NGrNm0j0DapUqXyuA3HdGBbkbDYvo5tOaRgvJeADo4177xp06ZmNFaDzMiC4ahoOXAdpdUA+ZVXXhFf27t3rzz33HOyc+fOiD7Z99NVyoEec+PGDRk5cqSMGTPGLFjdrl07n/cNAAAACEb16tWL8vOFCxe63dbHH38cMZKpv7vrvONkyZJ51T/7OboqefLkHrfheI5jm7ZBQW+v4zgdVQcng/VeAjY41mpm+pf+6NGjEUGw5vxXr17drDWm1ch02FyfKOj+8PBw8zp8+LAJpnXh5wMHDkR8UTQ1Qp8cvPvuuz67qb///ttUv9aJ3srWT0+WYtJhf30ytXnzZvnmm29MSjgAAACA2Ddr1iyZO3duxPaLL74oFSpU8Lpdx0AvcWLPxwodz7lz506019G50p5yPOfu3btBey/+wqOvoH6xHnvsMTly5IjZLliwoPTu3VuefvppM9HaXbaA05aS3blzZxNU16lTR7y1atUqad68uXnqYRstrlKlijRp0sSt4F3XCvvzzz9NHryeP378eNNHfQcAAAD8gb9Wq/ZkZDgy+nu4fTp1zpw5pWvXruIL9uv1qpisk+xO1qzjdWISUDr2zXF52mC6F3/h0VdQA1oNbPWL2KtXL5OyrCnRngTGyjbfWFOrCxQoYJ4ctGnTxusnCDovQQt92YbpW7ZsaUapNWD+8MMPTRCvpd+1AJemA+g3Nm3atOYHrlq1amau8Q8//GAKdulc5bx585q/ID/99JNJtQYAAAAQuz755BNLwSYNlH217I9jNqhj4OcOx5jFVYap44hsTOKc6K4TTPcScMGxphnrX0wNjAcNGiT9+/f3+qa00pwW59K1sg4dOmTm+XpD+6cBso4Kz5kzx4z2aoDrKQ2aW7RoIbt375YnnnjCBMg6Qu6vVdUAAACAYDBv3jyZPXt2xHazZs3M9E1fcVwCylUasaeBnqtlpXxxHcdzHNsMpnsJuOBY/6Lq8kc1atSQ7t27+6wDulC1jiJrAPr999/HuB2dCz169GgzZD99+nSzLJO3tHL1tGnTTLq3pl4PGTLE6zYBAAAAbyXw05c3tPiWrmlskyVLFrOCjC85ZrzaLy/kLltdIxtXo9pp0qSJ9esE070EXHCsk+J11Lhnz54+70T9+vWlYsWKsnXrVjlz5kyM10DTJxJa4Ktu3bo+65uOImvwrqPkkydP9lm7AAAAAJyzQG00UHYMzLyltYeiW7ooOo7nOK4V7Oo6MVm6yPEcx3WMg+leAq4g18aNG02Er4FsbHjmmWdkw4YNpiCWpjJ7StMvNHh/6623fN43LTymFbo1VVuXiCpSpIjPrwEAAACEqtWrV5vBLhutCaSDZpMmTYryPMc1eHWE0vGcypUrS/78+SOyVu3ZB+Pu0mxae1rPyFG2bNlk165dkZ4THZ0/bFvGyiZTpkyW7WC6l4ALjrVIlc7fjUmJcHdooSxNrdb06JjQoFW/yL4o8e6KVunW4Hj79u0ExwAAAIhX/lqtOqZOnjxp2T5+/LglxdpdGiw7nqf1kmzBce7cuS2faQCuSxV5Mgf22LFjlu18+fI5HeN4HcdzonPixAlLRWcdpNQ086iuEcj3EnBp1fqEIDZvwvaUIiZPPGx/GXLlyiWxJU+ePCZ4j2naNwAAAID4pfN0c+TIYRnVPHjwoEdt7N+/37Ktq+84chxMczzHF9cIpnsJuOBYI/yrV6/GWke04JXtOjGhT4kc8+F9KV26dDHOsQcAAADgH3TFHHvbtm1z+1xdMlYzVm20GHCZMmWcjitVqlSMr6G2bNnitBRusN+LP3A7R1pHjTW9IbZo25oeEtPRaZ087mn+uydsI9qxGYADAAAAPh3hChBNmzY1L09piq/WBrKfq7xo0aIoz9GloebOnRuxrUvLPvfcc27PjbZflqh48eKSNm1ap+MKFSpk4hpb1qlOHfWkdpH2yV61atWC/l4C6udK5wTrF2Lnzp2x0hFdKkoVLVo0xmnZR44cManPseHAgQMmeM+aNWustA8AAAAg9mkwbV9HafHixW5Pnfz1118t202aNIn02AYNGli2p0yZ4tY1NN6yj7k0gzWygDKY7iWggmP9gmjgOX78eJ93Qot96VJR+kSidOnSMWqjfPnyphT58uXLJTb89ddf5r1cuXKx0j4AAACA2KdFfGvXrh2xraOn/fv3j/Y8DTz1ZZMsWTJ5+umnIz3ecQRXl4XdsWNHlNfQglq6pJU9vUZkRbaC6V4CKjh+8sknzVOJkSNHmorNvtShQwe5ceOGPPXUUzFuo2HDhiZ4/+KLL8TXNm3aZIJuHT3XwlwAAABAfNKMRn98BYq3337b0l9NTR46dGikWag6z7Zbt26WfS+99FKU6/VqRmydOnUsges777wjhw4dcnm8fv7BBx/I5s2bI/alSJFC2rZtGzL3EjDBsZbwbtWqlbnRRo0a+Sy9WgNjHZbXJwi9evXyaqklnQ/8559/Rrsemid0rTT9Jupfrpdfftln7QIAAACIHyVKlJAXXnjBsm/MmDHSpk0b2bhxo6n8bMtw/fLLL03waCsgrHSVHA0Oo6MBogaFNtpes2bNZNy4cXLhwgWzT+OrFStWmGvYslVtunTpEu2awMF0L/EtwQMPJulq0SytVqaVofUL0717d/PUIXny5B5feN26ddKpUydZu3at2X7vvfdk8ODB4g1dw0y/aTrC/e2338prr73mVXtnz541o9lr1qwxc5p13nFMq2k7unnXJ80AgN+4dz92aj4AQHxJmdR/R0L/2HZK/NEzpbLF6fViUpDL5tatW/Lmm2+awlSONJ7Qwbvr1687fabxwIQJE5wqRUdmyZIl0q5dO0vxK5tUqVKZDFpbAGvv8ccfl2HDhoXcvQRMoTv9y6b55VrmW7+4usB2tmzZzIjqxIkTzRC95pa7osW8FixYIAMGDDDlu6tWrWoCY43N69atKwMHDvT6ZjTY1icnd+/eNU9K6tevLytXroxRZerPPvvMVGbTPmqawueff+6zwBgAAADwRgI/fQUSnWc7atQoE4s40njCVTCpNZLGjh3rdjCpdE7wiBEjXFaC1hFcV8Hk888/b+KRULyXgBk5ttG05datW5snFHq64/wCHVXWJwf6hEK/SLo+suMXynbZWrVqyfTp011+gWNC894rVapklnWy9UuDep2TrN/4YsWKmWWfHPunla51UrkGw0uXLjX9tfWxa9euMmTIEPElRo4BBBtGjgEEG38eOZ7upyPHTwfQyLG92bNnm1TkyKaOauygKcSafqwVl2NCB+B0wE2vZZ/WbE+LE+s17ItshfK9BERwrDR/XdciO3r0qAlC3W3G/tj27dvL8OHDJVGiROJLu3btMpXQ9u3bZ7muu+zvRdO0P/nkE58XGCA4BhBsCI4BBBuCY/8Pjn1NYxstPqzTK2/evClp0qSRggULmkDPV1WWNdNWYymdsqpBpraro7hlypQxwb2vBNO9+H1wrDSn/OuvvzajqvpFj2jURSBpfxkdxdWAs2LFihJbdFknTa2eOnWqpU9R3a79MTrHWFMT9KlKbCA4BhBsCI4BBBt/Do7/3O6fwfFTJQM7OEZo8yo4ttEnETo5W+cU6yRwrVymac26X1OYtSqZPqXQHHhdL1mXRIor69evN4G4ljTXfPvoZM+e3VTQ1lFt+2psvkZwDCDYEBwDCDYEx54jOIaEenAcCDQXXgP46IJ3LegVFwiOAQQbgmMAwYbg2HMExwhkIRMc+xuCYwDBhuAYQLDx5+D47+2nxR89UTJrfHcBiJulnAAAAAAACEYExwAAAACAkJc4vjvgD1q1amXWOdZq1QsXLozv7gAAAABR8vEqowAIjv9n7dq1snfvXp+vZQwAAAAACAykVQMAAAAAQh4jxwAAAECASSBkPAK+xsgxAAAAACDkERwDAAAAAEIeadUAAABAgKGOLOB7jBwDAAAAAEIewbGIPHjwIL67AAAAAACIR6RVi8iePXviuwsAAACA2xJSrRrwOUaOAQAAAAAhLySC408++UR++eWX+O4GAAAAAMBPhURw/NFHH8nPP/8c390AAAAAfFat2h9fQCALieAYAAAAAICohExBrn379pn0am+EhYVJxowZpWjRolKpUiVJkiSJz/oHAAAAAIg/CR6EwDpGCRMmlAQ+zvNIkSKFtGnTRj744APJlCmTx+ffvOvT7gBAvLt3P+j/dwIgxKRM6r95wvN2nxV/1KBY5vjuAhBjIZNWrc8AbC/H7cheUR137do1GTlypJQrV062bNkSz3cHAAAAAPBGSKRVt2zZ0owc79y5UzZs2GCCW02PLl68uGTOnFlSpUplPtf94eHhcvbsWdm1a5ecP3/enF+iRAkpX758xOfHjx+Xbdu2yY0bN+TYsWPy+OOPy8aNGyVr1qzxfasAAAAAgBgIieB4/PjxMnr0aJk8ebI899xz0rVrVzNnODrr16+X4cOHy9SpU+Xll1+W7t27R3ymgfGECROkZ8+ecvLkSVMRW68BAAAAxLYE4r8p30CgCok5x3/88YcJir/55hszT9hTY8eOlbZt28rEiRPlhRdesHy2du1aqVmzpiRKlEguXLggyZMnd6tN5hwDCDbMOQYQbPx5zvH83efEHz1azPNaPIC/CPrgWG8vX758ZqR4ypQpMW5Hg+vVq1fL0aNHnYp7vfLKK/LLL7/IvHnzpF69em61R3AMINgQHAMINgTHniM4RiAL+oJcy5YtMwHt888/71U7zZs3N+nTS5cudfqscePGJgjX5aIAAACA2JYwgX++gEAW9MHxv//+a0Z6s2XL5lU7WmxLA2Btz1GuXLnM+8WLF726BgAAAAAgfgR9cGyrOK1Vpb1hO1/nFTu6efOmedd5xwAAAACAwBP0wXGWLFnMiO+PP/7oVTvjxo0zI9DaniNd2kmlS5fOq2sAAAAA7lar9sf/gEAW9Es5Va1a1bxrsay+ffvKxx9/7HEbvXv3lgULFpjguFq1ai6rYetnBQoU8EmfEVi+/+4b+XLE5+bPTz71jPQbONir9jQ7YcG8ObJ500bZs3u3XLx0Ua5euSrJk4dJ2nTpJFfuPFKhQkWp+UhtKVqsmMQmXdf7uaZPyon/fwCktu7cG2vX271rp7zcorncvXvHbFeoWEl+GP9TrF0PAAAACJnguGjRolK9enVZuXKl9O/f3wTJnTt3lgYNGkQ50qsByty5c+WLL76QDRs2mOBXl2wqUqSI5bjffvtNZs2aZT4vXbp0HNwR/Mmhgwfk++++9Ulbly5dlJGfD5cZf/8pt27dcvr86tU7cvXqVTl29KisWbVSvhr5hVSrXkM6du4Wa0HypwP7WwLj2KTTE3r1eC8iMAYQey5fviSzZ/wtGzeul7179ph/f27euCEpU6aUnLlyy8MlSkntunWlStXqTis0eOqiPvCbP1e26AO/PbvNtfSBX1jyMEmXVh/45ZZyFSpJzUdqSZGisf/A74Vnn7L8u7Zp+55oz/tr+jT5qHevWOlT+QoVZcw4HgICgD8I+uBYjRkzRipUqCA3btyQdevWSYsWLSRhwoSSJ08es8xTmjRpJFmyZCYguXLlihw4cMBUuLatcqXvqVKlku+++y6izY0bN8pHH30ks2fPNp+XKlVKMmbMGI93ibh27Vq4dOvSUW7cuO51W5s2bpDu3TrL2TNnPDpv1coVsmH9Onm/V29p9px3FdkdLZg3V/768w+JK58PGyIHDuyPs+sBoUj/Pzf665Hy2+RfTDDs6PLly+a1a+cOmfLrL5I7T15p16GzPNqwkcfX0iD4yy+Gy6wZf7l84Bd+9Y6E6wO/Y0dlzepVMurLL6Rq9RrSoVPXWAuShwyKuwd+QGzz8rkVgFANjnX0WEeBn3jiCbl06ZJ5Cn7v3j05ePCgHDp0yOl4W1Csx+mfM2TIIDNmzJDChQtHHLNkyRKZOXNmxPYLL7wQR3cDf6C/6HXu0E7+/ecfr9vasX2bvPtWW7l+3TnITp06tRQsVFjSpk0r165dMyPVZ8+etRxz+/Zt+eSj3ubPvgqQz549I/0+7iNxZeWK5fLrpIlxdj0gFJ08eULefbON+XfEXUePHJYe3TrJkkWPS99+AyVp0qRuP/Dr2b2Lxw/8Vq9cIRvXr5PuPT+Ups/69oHfwvlz5e+/pvu0TQBAcAmJ4FhpavXOnTulU6dOMnXq1IgAOCoaHGvQO2zYMKeloHTdYx2Ntilbtmys9Bv+5/q1a9Kx/Tuybu0an4w+d2r/jlNgXLRYcWnfsZNUrVbDqQr6tm1b5esvR5jUansD+38shQoXllKly3jVJ/3Z6PNBT/MgKS7o6FLfD3u69TMJIOYPvNq+9orLUVOdYlSwcBFJmSKlSbfW1GfHUeXZs2aY7KthI76KNs16547t0uGdN1w+8Etle+CXJq1cu/6/B37nXDzw6///D+d8FSDr/Q/4pK/4owqVKsd3FwAAoRYcq+zZs8uvv/5qUqYnTZokq1atku3bt5vlnnRUTudaaWq0pkhrMK3p1zlz5nTZlq5tbFvfGKHj33//kfe6dJSDB9wfeYnKmG+/cRoJbtT4Mek/cLAkiWSEplSp0vLNdz/IyC+Gy9jv/0v1v3v3rgz5dJD89MuvXvVp8i8TTbp2XOn3UV+nrwEA3/q49wdOgXG+h/JLl249pHrNRywBrwanf//5h4z4fKhJe7ZZsnih/PLzj/LSK69G+cCvcwfXD/zebd9JqlSr7vTAb/u2rTL6qxEmtdre4AGfmEDaFw/8dL6wNw/8nny6qXl5Y8mihdK1UzvLg8BHGzaWN95616t2EbqoDA34XkgFxza5c+eW7t27x3c3EGD+/nO69O/3kct5ejFNzdZ5f/aKP/xwlIGxjf4i27FzVzly+LApdGOzbesWk85Yrvx/WQ2eOHhgv3wxfIjElb+m/2HpPwDfW7RwvqxaudyyT/+N+HL0GEmePLnT8Zo63ey55qZa/OuvvmQKatl8N/prebppM0mZMpXLa/3w3bdOI8ENGzeRTwYMliRJXP+7VrJUafn62x/kqxHDZdwPYywP/IZ9NkgmTPTugZ9O2dB07fikI+R9PuhhCYx1XrV+XbwteAYA8J2gX+cY8MUvNZr6/GGvHj4LjNWK5ctMxoK9du07RRsY2+vc7T2nX6yWLl4Uo/7cuXNHer3/nqkabVO9Rk2JLSdOHJdPB/WP2E6ePIWULVc+1q4HhKqffxxv2U6dOo18NmyEy8DYXt58D0mPnv+rZ2Bz9eoVWTh/XqQP/LSIl71ixR+OMjC20X/H2nfqKvUebeA0qqwP/GJKs3xGfj5U4pOOxHfv2slUyrZJkSKFDB4y3BQDBQD4D4JjN+3YsUOWLVsW391AHNJ0+4H9PpZmTz8hixctdPq8xUuveBXMOc5ZTpMmranU6olcuXJL4SJFLft0vmBMfDvqK9m1c6clvbthoyYSG+7fvy8f9uxh+WWxa/cekjt3nli5HhCqzp45bZZQsvf8Cy9KBjdXV9BgVf9tsrdxw3qXx65c4fzA7x194BdNYGyvU5fuTg/8li1dLDF94PdhT+sDv2rVY++BX2R0RHzfv9bije9/0Mc8fAC8kTCBf76AQEZw7Kb33ntP6tSpE9/dQBz64btv5NfJv5jUPns6N/3j/gPl/V4fOs2d88SB/fucUqp1iTFPaYBs79y5cx63sWXzJhlrl86YOUsW+aB37BWvGT/2e8sv2DVqPiLPPU/Fd8DXtm7Z7LSvQaPGbp+v/8blyZvXsu/0qVMuj13v6oFfteriiZy5cjk98Nu7O2YP/DQFfPeunZb0bk/u3Rd01HviTxMs+x6pXUcef/LpOO0HAMA9ITnnGIipmo/Ukg/7fCzZsmf3uq069eqbXzp1qROdo6fFcWLi9m3n9UM9rb79Qc/uZnkzm4/7DZQ0aa2jRb6yZ/duGfXVyIjttGnTyUf9BsTKtYBQV79BI1m+ZoMc2L/fPJA7cviQKXLlCcfpJIkSu34o6LhOuaZUx+SBnwbIe+0yYM6f87xg39Ytm2T8WOsDv54f9DVFxeKKjlwP6v+xZZ6xVuvu9eFHcdYHAIBnQi441qq4GzdulAMHDsjVq1fNHCl37NtnHeVDaNFfJjt06iK1avsue+DFl17xSTv7Hf5uZs6cxaPzPx08QI4dPRqx/XzzFrE211h/3nRes/7SaPNBn74e9xmA+7R4lha90pen9P+TR48esezLF0k6cJ069SRPnrxm2aT/PfCLWdrw7Vu3xRvXr1+T3j17WB749f1kQKw98IvMxB/Hy/59/1r2tevQWbJkzRqn/UDwolo14HshExxv3rxZevToIYsXLzbzHT2lT36pKBl6Hi5RUl56paU0bvJ4jEZAYpumDGphK3sFCxVy+/xFCxfI9GlTI7b1F9vO3WKvkvuI4UMtvyzq1zW25jUD8N7En8Y7PUSuVaeey2Nf8NUDv/3WgDJTFs8eng0ZPFCOHfvvgd9zzVvE+Vzj8+fOyfffjbbsK1S4iKkCDgDwXyERHC9YsECefPJJ8z94+/QmICpvvv2upE2XTvzZuLHfO+2rXaeu27+8ffJRb8vcwv6DPjVVVGPD2jWr5ZeJP0Vs6+hJrw/7xMq1AHjv998mm9oL9sqULSeVKleJ1Qd+J0+csOwrWND9B36LFy6QP//474Ff7jx5pVOX9ySufTPqS6e1nt97v5dXdSoAALEv6INjTd9s3bq1pVpl5syZpWjRopI1a1YJCwtz639W8+fPl5MnT8Zyb+FP/D0w1mrXc2fPsuzLnj2H2xW0+/b5wLJ+6Wut20rpMmUlNly5fFl6f/B+xMMpzcKIzXnNAGK+7NCqFcvlpwnjZPMm6xJK6dKlk08GfBqr158w7genfbVqu//Ar/8n/z1w0/+36zJSyWPpgV9Uy//ZB+iqdp16UqFi5TjtB4IfCY2A7wV9cKzLLx09etT8Ml62bFkZNWqUVKpUyeN2GjduTHAMv3HhwgXp+2Evp/1vvP2OWw97fvt1kixfuiRiu0jRYvLWO+0ktvTv95Glwq0uJVPNw2WrAMSO4UMGy6FDB+XC+fNm2oOrWhw6Ajt8xFeSK7e1Or4vrV+3RubNsT7wy5Y9h5Rx84Hfx32tD/xefb1NrD3wi8r3331jWeVAf/94u12HOO8HAMBzQR8c79q1y7wnT55cZs2aJVk8nLsE+Bv9xbVLx3ZOc4013fGZps9Ge77+EjxsyH+jP0mTJpWBnw6RJEmSxEp/Z874yzLCnTdfPuncNe7THAG4NnfOLFM13xV92Nbq9bbyeps3YnUEVoPaj3q7eOD3lnsP/DQFfMWypZYHfm++HXsP/CKjxQ3nzp5p2fdow8ZmvjEAwP8FfXBsS6euUqWKV4Fx165d5YUXWIcV8evO7dvStVN72bxpo2W/LoekAW50ReN0NOOD97tblmZp17GzR3P6PKFzBwf1/8RhXvNn5mEVgPh3585tk44cGa34PHXKZLl2LdxMvcicJWusPPDr2rm901xjfeD31DPNoj3/8KGDMnyo9YGf/jsTWw/8oqLLR9lXydZ/k994+9047wdCA1nVgO/5X/ldH8uXL595T5MmjVft1K9fX1599VUf9QqI2VzArp07yHK70RGVOHESGTL8C8mZM1e0bXz3zSjZsX1bxHb5ChXllZatYqW/Or9Y5xnrUjA2OvpUKgbLyQCIHadPnY52BYdLly7J5F9+lqZPNpGF8+f6PDh/r3MH2eL0wC+tCXDdeeDXu1cPywO/dzt0kgKx9MAvutoKs2b8ZdlXvcYjkj9/gTjvCwAgZoJ+5LhOnTpmlGrv3r3x3RUgxsLDw6Vju7dlw/p1lv26vNSAwZ9J5SpVo21j27at8sOYbyO2U6ZMKf0GDo61Jap+nDBO1q9bG7FdrPjDpgI4AP+RLFlSGTzkcyn+cAnJnCWLeQh34vgxWbF8qUz6+Se5cOF8xLHXrl2THt06y+Ahw6V+g0ZeX1uv1b1rR3Mtxwd+nw4bITnceOA35lvrA79y5SvIS6/EzgO/6Pw1fZql+Kd6KZYePgIAYkfQjxxnypRJOnToIHv27JHZs2fHuJ1WrVpJgQI8/UXcO3v2jLRu9YpTYGxbeqlR4+jXCdYlRTSd2r5IjC4r4s5oc0z8+89e+WrE5xHbyZIlkwHxlOYIIHKaJt2gUWNTaEt/TlOnTm3m67Zu+5b8OWuu1Klb33K8jjLr3OAzp097/cCv3VttZNmSxZb9+rCu36BP3Vouavu2rTLu++8sD/y0OnV8rUk/9fdfLds6XcWdB5dATCVMkMAvX0AgC/rgWA0cONDMF9bXlClTYtTG6dOn5dChQz7vGxCVvXv2yEsvPCd7dv+vsJyNBpmfDhkujz3+pFvtDP1ssBw5fMiyFrI7xbtiOhrUs0c3827TrkNnKVCwYKxcD0DsSJkylQz5fKRJDXZ82Pbt6K+8euD3xustXT7w06WiGjaK/oHfjevXpXcv6wO/rj16uTXaHBt09Pqww+8IT8XSv7EAgNgT9GnVavny5fLmm2+aecctWrSQvn37yuOPPy4lS5Y0ax6ncKMCpy6d402xEcelMR4kSmae0gORWbpksbz/Xhfzi6g9HR35fOTXbo9IaDtTp/w3opE+Qwbp81E/iS1fjvhc/v3nn4jtChUrySuvkloIBCIdhdXR2Cca17f8W6QVmd97/wMJCwvzqL1/9u6Rju++JadP/7e0m+2B34DBQ9xO1x42RB/4Hbashfy0G8W7YsvsmX87pYY3cfPhJQDAf4REcFy7du2Ioh5aJEhTrD2dg6znRVcYJDKDBg2Sjz/+2LLvg9595cM+H8WoPQS/nyaMN9VXHQvl6MOcL0d/J8WKFXe7rS+GDbFsp06dRgbaVZCOykmH5aJU107W9TozZMggH/z/3+VzZ8/KTxPGWT6/e+eOdOvc0a3r7dq5w7Kta646Xq9ipcrywosvudUeAO/pA7XHn3xafpv8S8Q+DZR379opZd1cg1gtW7pYenXv6vKB39AvvnL7gZ+2M+333yz9+7Cve/+mxQb9/WD+vDmWfTVr1Zb06dPHW58QGkhgBnwvJIJj2/+8lH2QHFd69uwpXbp0sfYnEaPGcKbBsC599Nuvk5w+K1iosHw9+jvJlj27R206FojR9Gr7FGtPLXCoVpsjR86IP9+6fcvpZ2vLls0xvtbFixedrudOpgcA36parYYlOLY9vHI3OP75x/HyxbDPnB74ZcqcWUZ+/a0U9eCB34jhQy3bOk968EB3H/hZl4tS73VxfOCXUXp+2Nft/uzetcM8GLT3aIOGbp8PAPAfIRMc65NpLc4VUzrn2DE12l2aPu2YQn3zv2lSQMQaxu937+YUDNp+MR36+QhJlSpVvPQNQGjLbvcQzObqlSvRnqfB8KcD+8kUVw/8ChaSkfrAL5unD/z+W7ZJaXq1fYq1pxbOn2fZzp4jh0fnr1i2zCmlunrNWjHuDwAg/oRMcPzEE0/IL79Yn3p7onHjxjJvnvV/oIAvA+MunTqYdEFHzZ5rLr0+7COJE4fMjysAH9IA9dSpk3L82FEzrcKTUVobV5Xmo6s+r2sY9+rRzSn4VFWqVZfPhgXHA79VK5dbtitWrmxGs4FYR1414HP8tg34wS+uWt3ZVWDcoVMXad32Ta/anz1/UYzP/fOPadLnw56WfVt3Rj5fX5eGiurz6PT+v/buA8yJcv37+LOAFKVJk14EUaSoSFMUVCwUj9hBRUAFkUOx9wI2VBQVRQEb9npsqBwUERXEAggISFPpCCpNOgh5r9/zfydnMpm03ewmm3w/XpFkd2Yyk7a5576f+7ntFjP+w/dDmnk9/+Irud4ekO0GXNXHzPzhe7N3797gWNiRo8YkvJ0NG0LLhqVilGosBcY3XDvYTP3qy7DfnXv+heaW2zPjhN/OnTvNzwsWhPzsuOPapmx/AAB5U/j/MsVBXapVVp0X6mztHbsJJIPGz0367NOwKU2G3H2f6XrOuSnbLwCFX8mSpYKBscyeNdNOs1a8ePGEtjNndnjvgNp16kY84Xf7zTf6BsYDr77WXN4nbyf8Pvk09yf8xn/wnp2n2e3HeYtyvb358+aaf/753+Mrx7ZslevtAQBSKyuC482bN+d5G8OHD0/KvgBuU7743Lw47vmQn6lp3P0PDDedupyZsv0CkBmaNm1mpkyeFLy9bds2+7kTz1zC7mB34oSPQ35WsWIlc2TjJr7LP/H4iLDeCTrhd+fQe81ZZ2fWCb+5c+aE3C5V6kBz+BGNUrY/yC451FUDSVck+ZsEEI+tW7eae4eGd0S9+trrCYwBJMUZnbuETUP4wrNjw7pGR/P+u++Y3379JeRnp53R0Xd6wy+/mGxe9jnhd++whzIuMJYlixaG3K536KF2bmgAQOHEJ3gCDbkyYXwU0sfzz441Gzb8FfKztiecaC67om/K9glAZqlWrbpp1/7kkJ8tXbLYPDv26bjWnztntnnkoWFh06ld7tMLQSf87r8n/ITfoGuuNx07Z+YJvyVLQkuy69dvkLJ9AQDkHdFeAgpybmRktu3bt4XNGSrfTJtqjmp8eJ62rXmH89KEC0Bmue6mW8y306fZscaOsU+PMvv37Td9r/q374lf/b376MP3zYP33xM2jeFVAwabSpUqh60z7rlnwk74Hd/2RNP78j4mE2ks9+pVq0J+VrVaYtNAAXnhU7wBII+yIjheuXJlUjpSAsny9Zdfmu3bt6d6NwBkgVq1atvu0PcMuSPk58oe/3fCx7bxX9NmR9vmlVu2bDELf15gxxgvWRzeqKrrOeeZHj17+57we+et132nOWre9Ig87b/mHc5LE678sn7durDy9EqVw08aAAAKj4wJjidNmmT69u1r9u3bZ0aPHm3OPPN/JVx169b1HRuVCJ1Fz+s2AMfMmT+kehcAZJGzzz3fNqd88vERIVVQq1etNE898Xjc27j1jvCyaVFn6mw74bdu3dqwnx188MEp2RcAQHJkTHDcu3dvs27dOvtHv1+/fmbNmjVJK4smKEayrV+/PtW7ACDLqLz50Pr1zdA7bk1oFofSZcqYQVdfZy7odlHEZWbNnGGyzda/t4b9rETJkinZF2Qnvp0CyZcxwbHmMXaCXzULSeZ4YcYaI5LnX3wlV+uNenqsKQxUblmQcy3fO+xBewGQP9Sca/x/Pzdvv/maefedt8zva8Ozn46atWqbTp3PtGXUZcqWjbrd9evXmWzjN9yqePESKdkXAEBy5AQyJPKbOXOmufbaa+34nxEjRpg2bdoEf6dpFTp27GgmTJiQp27Vn332mS3bToZd/yRlMwCQNvbtz4g/J1ll5coVZuGC+WbTxo1m+47tpkyZsqZChQrm8EZH2rHKQLY7qHj65mdn/LbFpKOWh5ZL9S4AuZYxmeMWLVqYqVOnpno3AAAoNGrXrmMvAAqh9I3bgUKLeY7jpAR7hiTZAQAAAACZmjmOxjvVQm5MnDgxKfsCAAAAAEg/GR8cb9y40Zx//vkhP+vWrZvtaA0AAAAURjnUVQNJl/HB8Y8//mi+/PJLOx2TUxat8ckAAAAAAGRNcPzLL78Er7dv397ceuut5phjjknpPgEAAAAA0kvGB8ebN2+2/1atWtVO5VSqVKlU7xIAAACQJzlUVQNJl/HdqitVqhQspSYwBgAAAABkZXB8+OGH23937NiR6l0BAAAAAKSpjA+OTzzxRFO/fn3z3Xffme3bt+d6O506dTLFimV8FToAAAAKgZw0vQCFWcYHxzJy5Eiza9cuc+211+ZpO063awAAAABAZsmK4Lhz587m5ZdfNm+99ZY599xzQzpYAwAAAACQFXXC99xzj/33/PPPNy+99JL58MMPTZMmTeyUTupifeCBB8bcBgE1AAAA0gY1zEDS5QSyoFa4SJEiJsfV716H7L4dD2edffv2JWWfdv2TlM0AQNrYtz/j/5wAyDIHFU/fCPTHFX+bdNS8TtlU7wKQa1mRORbvOYAsOCcAAAAAAIhT1gTH9erVM+3atcv1+pMmTTK///57UvcJAAAAyI0c6qqBpMua4Lh169Zm3LhxeZrKieAYAAAAADJTVnSrBgAAAADAZHvmuGvXrqZly5Z52kaPHj1MmzZtkrZPAAAAQG4l2FsWQByyolt1OqJbNYBMQ7dqAJkmnbtVz1m51aSjo2uXSfUuALlGWTUAAAAAIOsRHCfQkKtYsayoQgcAAECay0nTC1CYERwngAp0AAAAAMhMWZsKXbt2rVm/fr3Ztm1bXEHvxo0bC2S/AAAAAAAFr1i2BcQPP/yweeeddxKes1gBdA5tAQEAAJAO+FoKJF3WBMeTJk0y3bt3N5s3b7a3KZEGAAAAAGRVcLxgwQJzzjnnmJ07d9qguEiRIqZKlSqmZMmStrR69+7dpnbt2iHr7Nq1y/z5559m//79NmNcrVo1c8ABB6TsGAAAAAAA+ScrGnLdfPPNZseOHaZs2bJmzJgxdvywyqqXLVtm2rdvb5fRdfdFv9+wYYN54oknTOnSpU2rVq3Mr7/+mupDAQAAAExOmv4HFGYZHxwrMzxhwgSbJZ4yZYq58sorbZAcj3LlypmBAwfa9T799FPzyCOP5Pv+AgAAAAAKXsYHx9OnT7f/9uzZ0xx99NG52kbz5s1Nv379zLBhw8yePXuSvIcAAAAAgFTL+OB41apVdszw6aefnqftaP2///7bfPXVV0nbNwAAACA3NIlKOl6Awizjg2PNYyxqwOXHabKlBlzRHHTQQfbfpUuXJn0fAQAAAACplfHBsZppOXMc+3HGH//yyy9Rt+MExVu2bEn6PgIAAAAAUivjp3KqV6+enb5JY48vvPDCsN/XrVvX/v7NN9809913n+829PvnnnvOlmfH28wLAAAAyC/ZVMGsqVU1tHHq1Klm9uzZdrrVzZs3mxIlSpiDDz7YNGjQwLRp08Z06tTJHHLIIbm6D/UVUhPfL774wsyfP99s2rTJ7N27126/YcOG5uSTTzZnn312MPGWW5r95t133zUzZsywwz+3bt1qj6NmzZq2z9FZZ51l/82LTDqWgpYTUOSXwdasWWNq1aplu1XriWvcuHHI7z/++GP7xBUvXty888475l//+lfYi2vQoEHm2WeftcGxOle3a9cuz/u16588bwIA0sq+/Rn95wRAFjqoePqGoPNX/9/QwXTTpGbeAi6vyZMnm+HDh5vly5fHXFaBWbdu3cx1111nSpUqFfd9TJs2zdx+++1m3bp1MWeyUTItN72MNNRTzX3fe+89m3iL5rTTTjP333+/vb9EZdKxpELGB8dy5JFHmkWLFtmzI0OHDjXnnnuuzRiLzqJUr17dzn0sLVq0MMcff7wpU6aMLcX+73//a19cepiqVatmVqxYYYoVy3vCneAYQKYhOAaQaQiOUxscP/TQQ+aFF15IeL1GjRqZMWPGmKpVq8ZcVtWjig8SCYn69u1rbrjhhriXV5zRu3dvs3jx4rjXUdzx4osvBmOWeGTSsaRKVgTHQ4YMMffee6+9ruxvjRo1zMqVK4O/Hz16tBkwYID9nZfz8Oh3Y8eONX369EnKPhEcA8g0BMcAMk1aB8dr0jQ4rpGc4HjUqFHmySefDPlZkSJFbCJLpboVK1Y0O3fuNEuWLDFff/21nVXGTeXDChadprp+VBHav3//kGBS1aannnqqOfzww+1tBYGfffZZ2HSuyrpecMEFMY/jn3/+MT169LDl4G6HHXaYOemkk0ylSpXMX3/9ZffF2wOpfv365u23346r/DmTjiWVsiI4Xr16tU3nO1Rvr1IAt3//+9/2DJO4g2Tn4bnpppvMgw8+mLR9IjgGkGkIjgFkGoLj1ATH8+bNs8GaO0xRJai+izuBnpvGuo4YMcK88cYbIT9XvyEnQealMcsdO3a043EdCrwfffTRsHHL69evt6XaM2fODJnx5pNPPjF16tRJKMjXenfddZdvLyQN8dT+7t69O/iz8847LyxuyeRjSbWsCI7j9dFHH9kssl4s6kqtM1Jt27Y1AwcONO3bt0/qfREcA8g0BMcAMg3BcWqC4169epnvvvsupEz69ddfNwceeGDU9R577LFgskuKFi1q+wsdeuihMUu2FXQruI6UaVaQd+mll5q5c+cGf6amVtpOJMqiasztjh07Qu5X60WizO7gwYODJwZ0DBrmGS1wzaRjSbWMn8opEWrGpc5uf/zxh33RaMyxznokOzAGAAAA8iInTf/LK33/dgfGquhUEBYrMJarr746JLO8b98+M378+LDltm/fbkuuvaXF0Uqw1exr5MiRIY2+lFhTl+ZIFKC6g0k19Y0WTIoaZKl02X0MGtoZSSYdSzogOAYAAACQFj7//POQ261bt/YtpfajMckXXXRRWPdmr4kTJ4YEehrD3KxZs7gaS2mWG3ewp21F8v7774fcvuyyy0y8TbKUZXVnYNVE2E8mHUs6IDgGAAAAkBZ+/vnnkNuavzgR3sBQvYe8NGey2xlnnBH39jWXstukSZN8l1u6dKmdUtZRvnx5G+jHQ+OEjz766JAx1d9++63vspl0LOkga4NjTSa+YMECO35BZQX33HNPyO9///33lO0bAAAAEI36x6bjJa+838Fr1qyZ0Pre+Y29Xazlhx9+CLkdb6DnZGbd07r+9NNPIY2wHN9//33I7WOPPTYkgxpLq1atQm6rI7efTDqWdJD3CXsLGQXE6rKm2nyduXBTtzWHurh98803dhD5oEGDbG0+AAAAgPzz0ksvmW3btpl169bZi6YJyktwXaZMmbBuze4AUB2XE7kPxQRq8KUppETNppTtVhNft0WLFoXcVrftRHiXnz9/ftgymXQs6SKrMsd33nmnPUPy7LPP2rNITue0SA27VYZx880327Md7nmRAQAAAOQPzYXboEEDc8IJJ4RNRRSLd4xx1apVQ27/+uuvIbdr1aoVkj2NR+3atUNuL1u2LGwZ7/34dcxO9n0U5mNJF1kTHPfr18/Oq6XJq93BcKTA+PrrrzdXXnmlnTxbc61pAm1vphkAAABIhZw0vaTSzp07zXvvvRfys+OOOy7ktnvsrF/wHA9vwO7dptN1O9o6sVSpUiVsLmN1ps7UY0kXWREcv/322zZbrEC4ePHidqLq5557zp5ZUpm1WpF7aeJszZOmtH/Tpk3tGZMhQ4akZP8BAAAARKdpghR4uXXo0CHk9saNG0NuV6xYMeH7qVChQshtv3G63vupVKlSQvdx8MEH2+7b0e4nk44lXWTFmOPbb7/d/qv6eTXgUslBtIH7bvXq1bNtzZs0aWKef/55c//990ddHgAAAEDBUjMpJb/cGjVqZFq2bBnyM2/wrBLuRHnnEN6yZUvIbWVF9+zZk6f70fzOijncGVZvc7FMOpZ0kfHBsTLDyvqqNv7TTz+NawJxv3nArrjiCjNixAg7KfnJJ5+cL/sKAAAAxCXVNcwReDO1XpMnT076ff7555+2ga53/lz1DvLavXt3yO3cJL2863i36b2d2/tR3OIOKHft2pWxx5IuMr6setasWfbfAQMG5CowdrRv396WZS9cuDCJewcAAAAgt5TpVBJLna3dunXrFjbeWLxZ0EQbWIl3GiNvUO69naz7Ue+kTD2WdJHxmeM//vjDpvLdk0/nRrly5XxLDQAAAADkX2Y4EpXm9unTxyxevDjk540bNw4Oq/Tat29fyG3vWNh4eNfxNvj13key7mf//v0ZeyzpIuODY+cshd9Zj0RoHrHc1vIDAAAAyZSTrnXVBWTDhg02Y+yt6qxRo4YZPXq0ncPXj+YCjhX8xeLNenq36ZdZ1f0kmnH1xi/e+8mkY0kXGV9WXb16dXsG5Msvv8zTdtSUSxloveEAAAAApMaqVavMJZdcEhYYV65c2TbQjTbVkGaucctNAs0bUHq36b1dUPdTmI8lXWR8cKxpmhTUPvnkk7Y5V27Mnj3bvPzyyzYLfdJJJyV9HwEAAADENm/ePNO9e3ezbNmysLl09X1dM81EU6ZMmZDbO3bsSHgfvHP0ejs+6z4Uf0RbJ1n3kynHki4yPjhWp2l1l9YTokD5pZdeCqulj+bDDz80p59+uj3b0alTp7C5wAAAAICCpnglHS/56YsvvjA9e/Y0f/31V8jPVdn52muv2dlp4plz1y03/YS863jjAyXUypYtG/KzRKcuUjdnb8Mt7zzGmXQs6SLjxxyLpmDSHGeaC+zyyy83t956qznrrLNMmzZtTP369c22bdvscirN2Lp1qy3VULZYgfHPP/9sg2mNWxg+fHiqDwUAAADIOq+//rq57777wsbVNmjQwJZSV61aNe7EmXfscqK8wbnKub20P+7AU+scdthhCU1P5S1DdhoEZ+KxpIusCI6POuoo+6bp3bu3va1W788++6y9OBQAN2nSJGxd/Vzd1VSmcfjhhxfofgMAAADZbtSoUXaIpNcxxxxjxo4dm1CgVatWrZDbq1evTnh/vOvUrVvX937cXbQTvZ947yPaOoXpWNJFxpRV33PPPfaMUiSXXnqpee+998JS+E6JtWrpdd257VzX2RNlkC+44IJ8PgIAAAAgPjlpekm2Rx55xDcwPuWUU8yLL76YcAZSpdfuTsmakcapIo3Xb7/9Fpa99vIm1X799dc83YeqXTP5WNJFxgTHQ4cONa+++mrUZbp27WrLpO+44w7bxc4bCDt0XV2uhwwZYpfv0qVLvu8/AAAAgNCMsbvS09GtWzf7u5IlSya8TZX0uoM9fe9Xk694rVy50mzcuDF4u3z58r5NwJo1axZy+6effkpoP+fMmROWJc/kY0kXWVFW7VapUiWbZdZl0aJF5scff7R18zrLom5s+v2xxx5rGjZsmOpdBQAAALLS+++/75sxvuqqq8y1116bp223bdvWzJ8/P3j7q6++Mscdd1xc63799dcht1u3bm2HYHqp35Gyus60R3PnzrXjduPJdGtc9TfffBPys+OPPz7jjyUdZEzmWD777DP75N1+++12XuNYc3AdccQR5uKLLzaDBw82t912mxk0aJC56KKLCIwBAACQ3jK4rnr58uU2keV1/fXX5zkwFs1E4zZ+/HjbUTkWZWbffvvtkJ917tzZd1lNVXTCCScEb2vmGw3xjMfkyZNDmmup+VWkBliZdCzpIKOCY5UWqMv0Aw88YDp06GBbkZ955plm5MiRtjwaAAAAQPpSpvHGG28Mm7O3X79+5sorr0zKfagJb6NGjYK3FbwpXohF00W5G1Op4lRjnyM5//zzQ26PGTPGrF27Nup9aJqkhx9+OORnF154YVYcSzrIqOD4pJNOsiXSOgvSp08fOxn4hAkT7Bmmpk2b2k5rmsrpjTfeCGspDgAAACC19N3dO6b1xBNPTErG2O3f//53yO0XXnjBBozR5lhWAs67DSXnIlGyTpWqDk0rq7Jw7/RJju3bt5urr77ajgV2T9ekMdbZciyplhNwd6IqxFQf37FjR/uG8nZTmzRpkvn0009tqbXq49WZWhcNLj/ttNNsOYLedNFeEMm2658CuysAKBD79mfEnxMACDqoeH70X06Opet3mnR02CGl8rT+v/71L7NkyZKQn/Xv3982083LNkuXLh32c2WiNUbXTVWnSrIpEFS8sGLFCvPKK6/YYHP//v3B5RRHKOFWrFj0Fk6qatUwTve6mg1HgWOnTp3sfu3evdtMmTLFZny9nZ2ffvppG5jGkknHkkoZExwra9ymTRvz4IMPRlxGT+QPP/xgxybrouuqmdeLRd3u2rVrZ0499VQbLCvTnJ8IjgFkGoJjAJmG4Lhgg2M1esqPsluNe61Zs2bYz5X91HSv3mBclDQrWrSo2bkz/HFWdaqCSb9t+nnrrbfMXXfd5fs7NQRWY2C/kEyl5Nddd11c95FJx5JKGRMc58bWrVvtmQ0FysouL1261P5cwbLOTilQVmZZl6pVqyb1vgmOAWQagmMAmYbguGCD42eeecaMGDHCFFRw7IzRHTBggM2KxkNTHY0ePdp3yqNYQeWwYcPiapaliliVOatZcCIy6VhSJauDYy/VxDuBst5EmzZtCv6ucePG5owzzggbVJ5bBMcAMg3BMYBMk87B8S9/pGdw3KBK7oPju+++27z++uumIINjp7pUAd9LL71kli1b5rtMxYoV7aw2ffv2zdX8yrJq1Sob/Cs5Fymw1NRMAwcONM2bN8/VfWTSsaQCwbHH+vXr7fjkiRMnmv/85z+27NqhjLI66CUDwTGATENwDCDTEBwXbHCcDlRJqi7Oat6raWHLly9vx+weeeSRMcfkxkuduGfMmGHjjo0bN9oAtXr16jaIVNfoZMmkYykoWR8c79mzx0ydOtVmjBUUz5s3z3c5PUwExwAQGcExgExDcJx9wTGyW3JOGRQyixYtsoGwAmJ1dXMPTvc7V6AzK61atQqbZBsAAABIhfQN24HCKyuCY3Vv0zhip0v16tWrw4JhZYXdgXH9+vVtMKxmXJoQu2zZsinZdwAAAABA/svI4FgD0b/99ttgqfSsWbOC83FFCoYV/CoIVkCsS6Jd2wAAAAAAhVfGBMfqxuYEw+qa9vfff4eNF3YHw5rryymV1kXX1WocAAAASHvUVQNJlzHBscqgFQBHGjesnzml0rooS6yJqgEAAAAAyJjg2M0JksuVKxcsldbYYUqlAQAAAAAZHRxrYm93o60DDjjAdOnSxXTq1MkGxpUrV07p/gEAAADJkkNdNZB0GTXPsaZocjpSa4qm7du32yyyLk2bNg2WVJ944ommePHiKd1X5jkGkGmY5xhApknneY5/+3OXSUeHVi6Z6l0Aci2jgmO3vXv3mm+++SY4n/GcOXOCjblKlSpl2rVrZ0499VQbLDdp0qTA94/gGECmITgGkGkIjhNHcIzCLGODY68NGzbYuY4VLH/++edmzZo19ucKlqtWrWqDZAXLKsGuUqVKvu8PwTGATENwDCDTpHNwvOyv9AyO61UiOEbhlTXBsdfPP/8cnPpp6tSpZseOHQVagk1wDCDTEBwDyDQEx4kjOEZhlrXBsduePXtCSrDnzp0b/F3JkiVtgOwEy8kqwSY4BpBpCI4BZBqC48QRHKMwIzj2sXDhQnPzzTebjz/+OGRqKP37zz/JiWoJjgFkGoJjAJkmnYPj5WkaHNclOEYhljFTOeWFAl5ljp1O17Nnzw4273JwDgEAAAAAMlfGBMcvv/yyqVGjhunQoUPC0z59/fXXdtondxDsBMbuoLhBgwb5su8AAAAAgNTKmLLqIkWKmI4dO5oJEyb4/n7Tpk22W7WCYf27evXq4O/cAbH74ShXrpw55ZRTguON69Wrl7T9pawaQKahrBpApknrsuoNaVpWXZGyahReGZM59iuVnj59ekip9P79+32zw+4Au1WrVsFguHXr1vZnAAAAAIDMllHB8caNG82oUaNsMPzVV1+Zbdu2BX/nFxDrZ8oGO8GwSrLLli2bkn0HAAAAAKRORpVV+zXQ8pZKK/g9+eSTgwFx/fr1U7K/lFUDyDSUVQPINOlcVr1iw26TjupULJHqXQByLaMyx5GC5hYtWgSD4TZt2piiRYumercAAAAAAGkk44JjZYnr1q1rTjvttGCpdPny5VO9WwAAAACANJZRwfHRRx9t3nzzTXPYYYelelcAAACAfOPpKwsgCTKqFfMhhxxCYAwAAAAAyN7guHbt2jY4BgAAAAAga8uqly9fnupdAAAAAAoEVdVA8mVM5hgAAAAAgNwiOAYAAAAAZL2MKasGAAAAsgXdqoHkI3MMAAAAAMh6BMcAAAAAgKxHWTUAAABQ6FBXDSQbmWMAAAAAQNYjOAYAAAAAZD3KqgEAAIBChm7VQPKROQYAAAAAZD2CYwAAAABA1qOsGgAAAChkqKoGko/MMQAAAAAg6xEcAwAAAACyHmXVAAAAQCFDt2og+cgcAwAAAACyHsExAAAAACDrUVYNAAAAFDI59KsGko7MMQAAAAAg6xEcAwAAAACyHmXVAAAAQGFDVTWQdGSOAQAAAABZj+AYAAAAAJD1KKsGAAAAChmqqoHkI3MMAAAAAMh6BMcAAAAAgKxHWTUAAABQyORQVw0kHZljAAAAAEDWIzgGAAAAAGQ9yqoBAACAQiaHftVA0pE5BgAAAABkPYJjAAAAAEDWo6waAAAAKGyoqgaSjswxAAAAACDrERwDAAAAALIeZdUAAABAIUNVNZB8ZI4BAAAAAFmP4BgAAAAAkPUoqwYAAAAKmRzqqoGkI3MMAAAAAMh6BMcAAAAAgKxHWTUAAABQyOTQrxpIOjLHAAAAAICsR3AMAAAAAMh6lFUDAAAAhQzdqoHkI3MMAAAAAMh6BMcAAAAAgKxHcAwAAAAAyHoExwAAAACArEdwDAAAAADIenSrBgAAAAoZulUDyUfmGAAAAACQ9QiOAQAAAABZj7JqAAAAoJDJMdRVA8lG5hgAAAAAkPUIjgEAAAAAWY+yagAAAKCQoVs1kHxkjgEAAAAAWY/gGAAAAACQ9SirBgAAAAoZqqqB5CNzDAAAAADIegTHAAAAAICsR1k1AAAAUNhQVw0kHZljAAAAAEDWIzgGAAAAAGQ9yqoBAACAQiaHumog6cgcAwAAAACyHsExAAAAACDrUVYNAAAAFDI5VFUDSUfmGAAAAACQ9QiOAQAAAABZj7JqAAAAoJChqhpIPjLHAAAAAICsR3AMAAAAAMh6lFUDAAAAhQ111UDSkTkGAAAAAGQ9gmMAAAAAQNajrBoAAAAoZHKoqwaSjswxAAAAACDrERwDAAAAALIeZdUAAABAIZNDVTWQdGSOAQAAAABZj+AYAAAAAJD1cgKBQCDVOwEgf+zevds88MAD5tZbbzUlSpRI9e4AQJ7xuQYAyC8Ex0AG+/vvv025cuXMli1bTNmyZVO9OwCQZ3yuAQDyC2XVAAAAAICsR3AMAAAAAMh6BMcAAAAAgKxHcAxkMDWrGTJkCE1rAGQMPtcAAPmFhlwAAAAAgKxH5hgAAAAAkPUIjgEAAAAAWY/gGAAAAACQ9QiOAQAAAABZj+AYQIGZOXOmycnJCbvUrVs31bsGAFlv9uzZ5oorrjANGzY0pUuXNgceeKCpV6+ead++vbnjjjvM4sWLw9b54IMPzNlnn21q1qxpO4iXK1fOrn/mmWeaxx57zGzYsCElxwIAuVEsV2sB8PXnn3+aTz/91EyaNMn89NNP9vZff/1lihQpYsqWLWu/PDRq1Mg0a9bMftlo3ry5KVYse96G+tJ0xhln2OsbN240M2bMSPUuASF0ombFihVRlxk3bpzp3bt3xN/Xrl3brFq1yl7/5ZdfTP369SMue9JJJ5mvvvrK93earmjo0KEm0+lz4JJLLjHbtm2zj63zGYH/+fvvv80nn3xi/77MmjXL/m3RZ2j58uVNlSpVzOGHH246depkunTpYqpVq5ar+3jiiSfMddddZ/bt22f/Lh111FHmoIMOMgsXLjRff/21vaxevdq8+OKLdnktp+ftrbfesrfLlCljWrVqZfbu3WvmzZtnli5davf54IMPjvp+AYB0kj3fyoF8tH79evPAAw+YMWPGmN27d9ufVaxY0QbD+tKyY8cO+6VCX2p0cejLhM6uX3DBBfZLTfHixU0mO+yww8zEiRPt9S+//NKcfPLJqd4lIIROWun9rMucOXOCP2/ZsqWpUKGCvV6jRo2I6yuQcAJj+eyzz0z//v0jLq9gomTJkva6gmR9fpx++un2doMGDUw2UECmQEr69u1rVq5cmepdShv62zFy5Ejz8MMPm02bNgVPMuoEzJFHHml/pr8tCxYsMO+995454IAD7OvtzjvvNJUqVYr7fr799ltzzTXXGM3uqW1/8cUXwZM6ek1eeeWV5uWXXw5Z55FHHgkGxh07djRvv/22/Zsmev/odayTxABQqGieYwC599lnnwXKly+v+cIDRYoUCfTr1y/w/fffB/bv3x+27KpVqwL33ntvoEyZMnZ592Xq1KmBbDJlypTgsdepUyfVuwOEWLx4ccj7c+TIkXGt9/jjj4es17Vr17jW27hxo/38aN68eSDbHHfcccHHq1q1aqnenbSxbNmyQNOmTYOPzVlnnRX44osvAv/880/Icvpbo785l112WSAnJ8cuW7FixcC0adPivq/u3bsH72fUqFG+f7v0u169egV/pufKWWf+/Plh67zyyiv2d+PGjUv42AEgVRhzDOTBCy+8YDp37mw2b95sz9J/9913NnusbJDG0nopk6xxWyo5UxYVQHrSmEn3WHhlgOPhXW7KlCnmn3/+ibne5MmTzf79+4NZ42wyYsQIc+ihh5pDDjnEjB49OtW7kxZ+/vlnW62gvxVFixY1r7zyivnwww9ttY1uu+lvjf7m6O+RXn8qhdY431NPPdWuE49p06YFr2tbfn+7lN0fPny4vf3rr7+a33//3V7X/TVu3DhsnfPOO8+uo38BoLAgOAZyaerUqaZfv372i2+pUqXsOGN9mYlHnTp1bHmxmp0ASE+nnXZa8LpKnvfs2RN1ef1ey7n7CGisqEpWY9Hnh/c+s8Vxxx1ng61169aZrl27mmynk61qcKV+FaITrj169IhrXQXEKq9WwLxr1y47Jlil/rGoDNrhDB/wUpm/xjd7l9eYYj/6u6h1nFJrACgMCI6BXNA4rwsvvDCYEbrpppvM0UcfndA2lCm5/vrr82kPAeSVO4urZlHTp0+Puvw333xjtm/fbj8b1CgpkayzgmOdLGvbtm0e9xqFncZdO2Ow1bCtT58+Cb9uL730Untdr0f1tFCTrGjcv/dmpv24TxTFszwAFBY05AJyQQ1SlOUQTXeh4Dg31OTk3nvvTXi9LVu22IZWavyzdetWU7lyZdsFWxkYdcbODXU/VdZrzZo1NuOgDIG6laqjdm5oH/WFX51/9eVJTYxOOeUU26gMKAw6dOhgX7vqyusEuQpWInGCYHUN1ntIGTxRh+Fo73N1tF62bJltaqSpcCJZu3at7Risf7VPeo8ee+yxpkmTJgkfm5o4/fjjj/Z+Ffjrc6xWrVrm+OOPN1WrVjXJoOZOqrDR9D/KguqEgTKJ+kzJj88BfYapjH358uW2yZkaVrVr1y5XjQ6VbVXG/48//rD7qmEw2lZuP18T6dz9n//8J3j77rvvztV2tJ5KsfUcqFnXa6+9RsdoAIhHykY7A4XU1q1bAwcffHCwEcnFF1+cp+01atQo7oZcK1assI1TDjjggLCGXrpUrlw58PDDDwf27NkT9/3Pmzcv0LFjR9sMyG+btWvXDrzwwgu+Dcb87Ny5M3DDDTcESpYsGbYt7ffll18e2LZtGw25UCi0bt06+Do99thjoy6rZlpqiLRu3brAmDFjguvpvbVhw4aI6z399NN2uUcffdT393PmzAl06NAh2GzJe6lfv37gzTffjHksK1euDNx1112BI444wnc7zqVz5872cyEaNRrzW3fIkCH295988kmgQYMGvsu0b9/eLhPp/tWIyqtcuXK+y+pzZN++fYFbbrklUKpUqbDf16pVyzZNjNfChQsDJ5xwgu99aVvvvvuuXU6NqaIdf26deeaZwW3VqFEj7s9dP23atAluS8+5d1vRXgN+z4n7MzvWhc90AIUVmWMgQWqc40yp4WSJ8mL+/Pm2EU+s+Y41tYbG4ynLo2VVeqdmYMrGaLyemrGo7PPGG2807777rpkwYULEsWCO119/3WYTVFKnks6rrrrKNnzRdWVONNZN+3f55ZebDz74wE7b4Uw7E2naEY2ZdMpP1cRl0KBBNlOkEnSVnY4aNcpOZzVs2LBcPmJAwVGJ6vfff2+vz5492zY68st6KjOq3zdt2tQ2lnKPHdb7W1UU3bp1i5px9htvrOyf3n96/+h9OXDgQPse1ZQ9mmrqqaeesu//7t27m88//9yMHTs2Ynbz/vvvt78XZaj1GaIy7urVq9sMqfZD0/Xos0OVKcp8R5pz+MQTTwx+FujxUbbW/bnSs2dPex+qFtF+z5w5M1ht43BvW9n1aNTUSSXC8tFHH9nPGodKiHWfRxxxhJ06T+O81Rxx586dtrrmX//6l/3sUZY9Gi2j59vZtp6PXr162c8x7bumKjr//PPtZ5ibpjxypt3Ky/RbqgJyprpzHh+/xo7x0t8HPQ6yaNEi29yrWbNmIdv3e/yVIdd4YTfd1lhkv3nq9TrQFGhueg8AQKGU6ugcKGyuvvrqkDPkyurktx9++CFQokQJe3/6V2fwvZQ9GThwYHC/WrRoETWD/MEHHwQzURUqVPCdimPXrl2Bc845J+5paS644ILgss2aNQv89ddfYcsoA1G9evVAkyZNyDIg7amiw/1+f+ONN3yXe/311+3vVTXhUEbXWU8VE340LY+yonpPRHuParq4uXPn+laytG3bNng/t912W8Rj0TRzWuaggw7y3ZbMmjUrmKXVfWoKn1jcWVRNJ6Sp6nS8f//9d3AZVYsoY+zOHLvFyhy76fPCWVbHVLp06cBHH30Usszvv/9uM/nOcsq8R7NmzZrglHy63H777b7LjR071n4G6/M1Wdlix/jx40Meh8ceeyxP23vvvffino4skcdfqPwBkKkIjoE8lFnqogAyP6lMuWHDhsH7e+CBByIuqy/aCkqdZW+99Vbf5f74449ApUqVYn7hd758H3LIIcFl9eXQz4QJE4LL6At9tLJMlVxSgofCYO/evYGyZcuGBH9+evfubX/vLuHt379/cL2aNWv6rjd9+nT7+549e0Z9jz7//PNRh1s4J8+KFSsW+Omnn6IGx8OHD496zO6S8MGDBwcSCY5VQq75eP3KgSdOnJj04FifNZE+v7777ruQ/VK5eyQXXnhhcNlWrVpFLWd2nwRMZnCsz2v3dvV45cWiRYtCtnfRRRdFXJbgGAD+D92qgQS5p7BQuWC0BjrJoEYqS5YsCd7fgAEDIi6r5kE33HBDSOMwlb95PfHEE8FpQjSXq7rrRqJGPe77VGMhv3lbH3nkkeB1lSNGaxKkcj+VQALpTkMYVMbsnXLJSz9X6anKjf26XasBluaujVRS7Z3f+Mknnwy+R1WiqvLeSGrXrh2cAknvTa3rR8Ms1Bgv1ryzKtF2SrPfeecdkwiVkGsuXL9y4GOOOcZ26I9UXp7b+ai1v35at25tmxU6+6XhHH5WrlwZ0gTrmmuuiVrOnF+zDLj/tkSbUile3mE13u0DAMIRHAMJ0phDd+CY35555pngdX1JjzVnZJcuXYJfbDV2TmMI3ZQkePbZZ32Xj+Sss84K+ZL/8ccfh/z+999/t11iExmHndex2kBBiRXkqhuwury7x+GKxtu6ewn4jatVUK1ATPPTurnfo3r/xZoux72Pb775pu8JrAceeMDuv6aRi6ZcuXLBoFLvba0TL50U07hfP+qurZNo/fv3N8ly5plnRv29+yTcb7/95rvMG2+8YYNn0WdhpHHWjlatWuVLt23nZEiy/r541/duHwAQjuAYSJCmaHHkZoqQRKj5ljvbEc+0Sso21KtXL3hb0zO5qTGLO4MQzzb1hdd9rN5tqunL/1Xm/S9DFM82gcLAm9X1zlscqaFW2bJlbSAVaT01jlIzKzVJcjcwUjM8d/OqNm3axNxHdxCoxk7aRl64g/xEMo7xvPeTSQ3QonE/rnpc/Ljnr1YWPlbGViczNE1Ufv5tScbfF+/63u0DAMLRrRpIkL44OV8WFbzGSxmYyy67LOoyL730UsiXuZ9++ik4x6rEyvi4l1MHW9Fcpm7qqOtdNhZlrerUqWOWLl3qu011QXVTqXYsTmYKSHfqQKwTTpoT2AlyVXobqzTa+ZkTfOmkkgIUJ/BUtYUyvN6g2vv+UjfkREto586dGzFw3LNnj81i66SWukwrSFfHejd3QJzI51yy5kiOV6zPEXeQv3v3bt9l3J9f8Xx2xXO/ueENyhN53P1412eOeQCIjeAYSJC+YDhfHCNlIvxoGpJY05Vo6hG3P//8MywTFQ+VRUbaRn5s011qHu82C6IkHUgWBbnONEhff/21DTCVmVPApdsKCt3T5LjXGzp0aPD9PXXq1GAw7Ixf9gbV3vLX22+/Peb7JdZnh6i6Q9Oz3XnnnWHv2WjcVSGxqC9CQYp1f7HK0cX9WMT7eRjP51esvgqqKnAPe6lUqVLI7xP5+xJPcMwJSQCIjeAYyEUDGGfMobK6mkezVq1acWWfvF8yX3zxxajZZO+Xm2hzDEdaTl+atZ/Ol8RkbNP7pc2Zf9QRT5OyvMzfCaQyONbrXXPiqgeA/tXY/khNrhQA6cTSli1bgllmJzjWdb2v3E28/N6juo9EOffnpsZ6o0ePttc1T7IaS1100UX2s8kbZCqDumLFCpMN3J9f8TZYjOfza/HixQll2b1zJKtRWF54n7/DDjssT9sDgGzAmGMgQSeddFLIbZU+5xdv8614x4y5l9OXXnf2JBnb9GZXDjrooJDbkcoXc5uNAlKtQ4cOIe8jp5Q60nhjh9ZRYy6HUz2iwEXDFLxNvPzeoyr7/f9TL8Z9cbLVjo8++igYGMvbb79tG3Qp213Q2d504/78iuezK78+v9yvE5k/f36etuddP9JrFADwPwTHQIK8XWW//fbbfLsvb5mdXzbIj3s5byldfmzTO5ZNYxhjyet4OqAgKfvr11xL/yqLGC3wcJdNK9BV/wGnpNpvPe97NBnvlaeffjp4vUWLFubss8/O8zYzhfvzK57Prnifk1gnML788suQ5TVGvFq1asHbataWF+71/SoUAADhCI6BBDVu3Dhk3tO33nor3+7rqKOOCpkKJtJUJF5OMy459thjQ37nvR3PNlWWrcY9kbbhHWsZzzb9xkQC6cwd5KqxnYZXzJkzxwY10RpR+XW7jtbEy/v+0tCNvJo5c2bw+vHHH5/n7WUS9+dXvJ+x+fX5NXjw4OB1NXDL7f2o0duHH34YvN23b9+srxAAgHgQHAO5oAY5jl9++SVmo628lPu1bNnS9wtutOYy7kDWWwauOUirV6+e0DaV7XJ3s/VuU1PNuOdK9nbE9pPXkkGgoLkDWWX+br75ZvuvX4Dr7Qjv7jg9ceJEM3nyZNuZ3q+Jl/c9Gs/7SWbMmGG6d+9uL5p3OVLlR6y50rNt2p+2bduGnIiINR+wnnPvXNfJMmjQoGBljk5KPv/887nazjvvvGM2btxor5cqVcrceuutSd1PAMhUBMdALscf9u7dO3j76quvtt1r88OVV14ZkkmIVfb3ySefmP379weD6x49eoQtoyyCY8KECSHTRfkZP3588Lqaj3Xq1Cnk98qa6TFx/Pe//zWxKEAACpPWrVuHdG3/+OOP7b+xgmPvMv/5z39s4KIhGpEaO7nfo+4MYDQKpFTJMm3atJDg2ls6vHbt2qjb2bx5c1ZVdqgpmXNyT4FvrJOdOgmRSLfvROgz210CP2zYsITmmXaaMLqDYY0td5drAwAiIzgGcklfYI4++uhgV9Ju3brZUrZEeKdf8XPxxRcHpwTR8k888UTEZRXkjhgxInhbc7F65z+VgQMHBrMT6oj6xhtvRB1b5/6ydtddd4WUejtuuOGG4HVlxaI1KtOXz4ULF0b8PZCOvM21EhnL6R5b7HxORBun7H6PKkv5/vvvR92+5mB2pgVS9tEbdLuzozp5FS0z/OqrrwZPsGWDmjVr2s9vx+OPPx614dZjjz2Wr/tz/vnnm9tuuy04M0DXrl3jHneu15YqB5xO1b169bInbwEAcQoAyLW//vor0L59e32LspcTTzwxMH/+/JjrLVmyJNCvX79AsWLFguvqsnz5ct/lZ82aFShZsqRdpnjx4oHJkyeHLbN///7AoEGDgttq0aJFYM+ePRH34aOPPgoUKVLELlu+fPnATz/9FLbM7t27A+eee25wm127do16XBdddFFw2aZNm9rHx2vFihWBmjVrBtq1axdctk6dOlG3C6SL0aNHh7xnTzvttLjW27x5c9j7fc2aNVHXcb9HK1SoYD8H/KxduzbQrFkzu1zjxo0DO3bsCFtmypQpIffdp0+fwL59+8KW032UKVMmZFmtG02vXr2Cyw4ZMiSQG+77W7ZsWdRl9XmR7H3TY6jH2Fn2tttu813u+eeft8+jHue8HnM0em6uu+664H0cc8wxgZkzZ0ZdZ+nSpYFTTjkluE6PHj0Cu3btSvrj73098fkNIJPk6H/xBtIAwmksrs7yP/nkk3YaEGWX2rdvb7p06WLq1atnO88q46txbGre8/XXX4d1IVUGSdvwjuV1U2fTs846y2YSdB+aH1n3ocywmsiopNKZD1Xln8oO+WWN3d58803Ts2dPewxq1nLVVVfZzJiuK7M7ZswYO95YdN8q2Yw2L7KOU+WjKut0MjJqMNO8eXOb0dD+6XFSAyNloJ3Mmbapx0w0DvOll16K+/EHCpLea+7xww8//HBI1UQ0yt5Onz492NgvnnH3es/pPaphG5qbWNc7duxo3ycaR6zPk+eee85s2rTJjm3+/PPP7eeOn5tuusnur7tXQJ8+fez8t5rrVx209Z7Xe1ilw075tfoeVKhQIWQ4hLLLuog+I5xl9di45+uNNnxCx+FwlzK3a9fOjpN1r699d6pRNLzEyXw7++b+3NBxOBU0kfZt+PDhYeO9NfOAPpOceY9V9q7PWX2OqbRZ01+pJF5lyosWLQre35AhQ8KmzkoWPcbXXnut/fuh0m9VKeizWM+1SuVVAq/qHw2P0XOv10np0qXNPffcY9eLJp7HX3Scenz1+Ot5EA0L0GvE+/ktfIYDKNRSHZ0DmWLlypU2c1u7du2Qs/B+F2UelNm97777AgsXLkzoPi6++OLAAQcc4LvdypUrB4YPH24zvvFasGBBoHPnzsEMlfei43nuued8s0x+du7cGbjxxhuDmW73pUSJEoEBAwbYbIY3k0UWAoVFgwYNgq/XuXPnxr3e0KFDg+tde+21ca/3888/B84888xA0aJFfd8zpUuXDgwePNhmp2MZO3ZsoGrVqr7bUcZ42LBhgb1794ZkZ90Xh7KlsT7nYn3FSGR9d4VOrM+NcePGxdxupIyzPo9VAeS3TrVq1QKvvvqqXa5nz57Bnz/wwAOB/PT3338H7rnnnkDDhg2jHpM+q/XZ++eff8a13Xgef3cmOdJnNp/hADIJmWMgHyirsGDBAtvURmfYlfEpW7aszXCoE63GEBcvXjzX21fGaMqUKbazqsaiKTvdqFEjc9xxx9mscm5oX5WdVpdbZWWqVKlip5LyTiuTyD5quhqNfdMYZWVf1LQrVjYbgD9lD533qN73ag6m970ywGrkFC9lF5XBVlZVDf60HWWPlf2LVhmSTVQ5o8fojz/+sJ/bzuPjfL6ed9555r333rPXn3nmmZAGavlJMxH8+OOPNpOtagH9XdFntapx9FoAAOQNwTEAAEACdELCGR6j0vZ4mrIBANIfwTEAAMhqqsLR+G71fWjRokXUZXfs2BHsJaH+DKoOKlGiRIHtKwAg/zCVEwAAyGq//vqrufHGG21zrVg0ZZYzDd8VV1xBYAwAGYTgGAAA4P/PAa0u/pGolPqWW26x16tXr27uuOOOAtw7AEB+K5bv9wAAAFAIaKTZJZdcYl577TVzzjnnmBo1atgmZatXr7bTSilw1rR0VatWNePHj7fNsAAAmYMxxwAAIKupu/7TTz9tg1918Y701UizDPTq1cvcfffdplq1agW+nwCA/EVwDAAA4JrWbu7cuXYc8ubNm82+ffvsFHQNGjQwxx9/fELTZgEACheCYwAAAABA1qMhFwAAAAAg6xEcAwAAAACyHsExAAAAACDrERwDAAAAALIewTEAJGDmzJkmJycn7FK3bt1U71pGKF26tO/ju3z58jxtV8+P33a//PJLUxD87jsZx5Vsejx4fQMAslWxVO8AgPSjL+z16tVLaB1Nb1KpUiXTvHlz07lzZ9OjRw9TsmRJk2nKlStnzjjjDHt948aNZsaMGXGt99tvv5nzzz/frFixwjz66KN2rlSEO+2008zOnTvt9U8//TRp223fvr1Zv369vf7VV1+ZXbt2mYLkvGaSfVzJVqFChVy9vgEAyARM5QQgjIIId/DmDiaqV69umjZtGrK8fqeAWoGfo2rVquaFF14wnTp1MplKWbaTTz7ZXq9Tp07ULOCll15qXn31VXu9RIkSZtOmTaZUqVIFsp+PP/64na9VevfuXWiygMpYOpYtW5a0/dZ2nNfqlClTzEknnWQy4bhS+foGACATkDkGEOaQQw4xEydO9A0mlNl78cUXfdebM2eOGTBggJk+fbpZt26d6dKli3n99ddN9+7dTbbbt29f8Pr+/fvtpaAoOHaePwWC6RqMAQAApBJjjgEkzdFHH22++OILc8wxx9jbKkxRppKMkzFDhw41zZo1MwcffLB54oknbBk6AAAA0gfBMYCkUsnw8OHDg7d3795tHnjgAZPtGjZsaObOnWvHcV511VWp3h0AAAB4EBwDSLpTTjnFdh12fPTRRyndHwAAACAWxhwDSLoiRYqYBg0a2DHI8vvvv5tt27aFBMzxdHf+7rvvzOrVq03x4sVtIzCVbR922GEhDY3clKVW87Bff/3VNqBS51113W7Xrl2uOmdv2bLFTJo0yY7XLVq0qKlRo4YN/CtWrGgK0tatW21zpJUrV9rjKlOmjKlZs6Y56qijTP369QtkH1Qir87F8+bNM3/++actC9fjoS7QuXk8/vnnH1uCv2TJErNjxw5TrVo107p1a5thT0d6Hf7444+2gZbzWq5Vq5Y5/vjjbfO5ZN3H1KlTzdq1a+3rTc/tqaeemqvGbRrjPm3aNLN48WKzYcMG22Vd+6sx53r95Bc9l3rfLly40L5/9L7T60RDLdL1uQUAIEjdqgEgmjp16qirvb306tUrrnXatm0bXEeXtWvX2p+///77IT93LroPWb9+feCss84K5OTk+C63bNmysPvaunVr4KabbgqULl3ad50DDzwwcM011wQ2bdoU177v3LkzcMMNNwRKliwZtq0DDjggcPnllwe2bdsWmDJlStj+R3vs3BetG8vKlSsDPXr0CBQvXtx3G7rUq1cvcN111wWWLl0asq6ep0jrxPu4yr59+wLPPvtsoGbNmr7rFS1a1D5fS5YsCcTrhRdeCFSuXNl3e+3btw/88ssvdrl49i833M9JtOdBj/9dd90VOOKII6I+dp07dw7Mmzcv7vv3Hte6devsY1ikSJGwbZcpUyYwfPhw+zzEY/fu3YEHH3wwULFiRd991WupZ8+ewfdjNPG8vh07duwI3HLLLYGyZctGfJxq164dGDx4cODHH3+M+7ECAKAgkTkGkC80VZGbk11UxrNbt272+h9//GGn0nEow3zCCSfYrLGyxJo+RtnS2bNnR7wf/V7ZtaVLl9rbHTt2tNNQKRO5Zs0a88Ybb5iPP/7YdmweP368zVZqu9EyX+rIrY7bzv4OGjTIzt+sbOc333xjRo0aZWbNmmWGDRuWb/PrKlPctWtX8/fff9ss4mWXXWa7f1euXNn89ddfZvLkyWbcuHE2k6l5kx977DEzf/58c+SRR9r1Nd2WM1+t+35btmxpM+peftlJZeIvvPBC+7hJ48aNbTfyRo0a2f3SfL3PPvus/b0y7O+//37IfL5+rrnmGjNy5Mjgffbv399m43Vd+//UU0+ZY489Nvj4p9L9999vxo4dGxxL37dvX9O2bVtbxaDX7meffWZefvllM2HCBPt8vffeezGP30uvDc1/rUzvvffea58fdTL/9ttvzZNPPmnHqN90001m5syZ9rWsqoxo7znNMa7MrRx33HHmyiuvtNUTyvZ/8MEHtnu89vmTTz6xz5nTPC8v9J45/fTT7XtD+3fOOefYizLGOi69V55++mn7XlUzOl2YRRIAkJYKNBQHkBWZ4+3btweKFSsWXKdJkyZxZaa6du0aaNiwYVhmadSoUb4ZxM2bN9vMqfO7e+65x/d+Hn300eAyDRo0sFmuSC644ILgss2aNQv89ddfYctoH6pXr26PK97MWiIZyxkzZgRKlCgRzPRNmjTJdzllKytUqBDc5uzZs/N0v17nnntucL1OnToFdu3aFbbMtGnTbGZey2ifo2VQn3rqqeD2lOX3yyDquenQoUPIY5uqzHG/fv3sMgcddFBg7ty5vsvMmjUrUK5cObtc+fLlA6tWrYp5/+7j0nHqEu115ix76623Rtzm3r17A61btw4u26dPH99s8zvvvBPMUOu18/vvv+c5c3zHHXcElxs5cqTvMlu2bAm0bNkyuBwAAOmIv1AAkh4cjx07NiQAuO+++2J++dYXdgVMy5cvD1tu//79gWrVqoUFSe7S4RNPPDHqPim4c5a9+eabfZeZMGFCcBmVdUcL9D755JOQY0xWcKwAVCcInOWGDRsWdZvPP/98vgTH48aNC66joM8veHM89NBDwWUVoPlR6bC75FYnPCJRab23RD6VwbHKmqMZM2ZMcHsqG47FfVx63Ud7nX388cchJf0LFizwXW7IkCHB5erXr2/LqyPp379/cNlu3brlOTh23ps6kRPtfmfOnElwDABIa3SrBpBUarB06623Bm/Xrl3bXH311THXUynpwIEDfUue1YDrlltuMddff71tLCS//PKLeeWVV4LLqPQ0GpVGO8aMGWN27twZtswjjzwSvK7S6iZNmkTcnspXjzjiCJNsr776qn0M5cADDwzZbz+XXHJJ0hss6bm4++67g7evuOKKqE23+vXrZ5umyffff+9bEv3MM8/YUmzRc6htRlKlShXTo0cPk2qak1qlweedd17U5bp37x4sd37nnXcSug+VI0d7namU/vDDD7fX9+7dGyxJd1PjqxEjRoSUrjvPhx/3a0r7u2rVKpNbaval4RCi0vho96tyeef9CwBAOiI4BpBnGpuqrrgPPfSQ7TiscZKi8bEajxlvl2qNvYxk8ODBNnhVwCLPPfecDeKcIDLWWE+Na9XYXSeY8E4vpS/47vHPnTp1irm/8SyTKAWRjpNPPjnmY6exsG3atEnqPmgs7fLly4O3zz333KjLK+Bp1apVSIDvpbGuDnVMjtU9PD8e20Rpfm51kD700ENjHr9e687rSOvESydZElnmzTfftGPf3TQWWR20432+NGZcY+lF7yGtn1sK2B16X2lMfzQaf6xO1gAApCOCYwAJeemll2wm131RoKMsqrK7mmpIWTRl2+bOnWubOMWjWLFitolUvNyBrDJSBxxwQMwgUo2JHMpwuqmJkbtJUDyNiqJl/HJDAY6CB4eagMVj4sSJNkhRE7NkcD+2el70+MbizqJ7H1udLFm0aFFKH9v85g72nQZs8Yjn/eF+vJR9X7BgQcTnS9M1qWFYXp6vRBxyyCE20+9Qsz2dCFEjLj+anio/Ki4AAEgGulUDSIi+eHuDWAXIKqmsVKmS/SKvjtHuQDQeyghHK8l0UxDr7mAd71y/TtZZFLi7af5et7p168bcnpMtTJaffvopJKiIlbF06GREtC7GidJ8vg5lGHViIZHHVl2ndRxOpl63U/3Y5sWePXtsZ26dQFFGXQGqO2PqDYjdWdxY3IFlJN73kl4nmuPa7/lKxnshEXrvq6rjjjvusLfVSV2l/hpaoX8vuOCCpHTEBgCgIBAcA0iIxuK++OKLSd+uSqPj5Q1ONI2OAvJYNE7ZoaltvGMn3cqWLRtze/GWi8fLu0/x7EN+UIDjzvom+tgqmNRz5ARg6fDY5oZOwmh8+p133hl2DLHWi9dBBx0UcxnvmHLvvrifL5Usx/N8uU8GeV93iVLFiE4aaKiDQ9M2qSxdFwX3yij36dMn7uAdAIBUIDgGUOh4M3P6Yu4eIxsPjY902759e8jteLKlyprl53HFGpebX9z74cxnnCg9vk5wnA6PbW5oTufRo0fb6yrbV0O4iy66yDRo0CDsZI6y4StWrEj4PuI5Tu/rwPt4up8vZbATfb62bt1qxx7ntvpAFQKa71pzYisY1skq9wkCzcX94IMPmocffthcfvnltndAqk78AAAQDWOOARQ63kyagpb/PzVd3BdvMO3N4KnJWDIzhLk5rl27diV1+7nZD403TvSx1cVdOp0Oj22i1LDNCYzl7bfftoFfs2bNEqpySMZxel8H3qy6+/nSWP9En6u8BMbeqhI15Pr111/NvffeGza2WKX2CqLbt2+fUOk5AAAFheAYQKGjrJN7fHIyvmh7pypyph2KJtlf8DVmO9F9yA/u/ciUxzZRTz/9dPB6ixYtzNlnn50v9+PNAvvxPl7exzPZz1deqYxaY5BV4q1mXz179gyOP5c5c+aY+++/P6X7CACAH4JjAIWSu5NzXuZpdSgj6Pbbb7/FXCevYzW91GRJ3aEdysClgrs7taYlymsW19vALRWPbaJmzpwZvH788cfn2/388ccfMZfxPl7e16r7+UrGeyGZNMWXOtwrSHaXUic6HzQAAAWB4BhAoaQ5gN2ZqHhdccUVpnv37iHz7ormCnaXlrq7YUfi7cKcVyo/btmypW8X4miuueYam9nUPNPJGL/rfmyV2Vy6dGlc62ksqR5bp3OxQ2OPjzzyyJQ+tolyj0n3lrv7yW0JvHdaJj/ux0sBpnf6J/fzpecqnmy03Hzzzfb5GjlypMnL46TxxK+99lrU5RTAq4N1ugbxAAAIwTGAQkmdb51gdu3atWbGjBkx19FUPC+88IJ56623wkqYq1atajp06BC8/d///jeu+YWT7corrwxeV2MjNUuKlWF96qmnzIcffhixgZe7BN07/6zGXiu4GT58ePBnp556asg0Utp2LDt37jTDhg2zj63GsHppWh/3cWn5gn5sE+EuXdbrKxrN7Z3bTHes15my9hMmTAjeVkMwd4myKMB1Anh1cXcvH8maNWvsyQw9X5qGLbc2bdpkg9777rsv5rLu6adoyAUASEcExwAKJQVvvXr1Ct6O58v53Xffbf9VFlPNg7xuuOGG4PXJkyfb+WQjUUdgjalMtosvvjjYyGjHjh3mySefjLq8fv/PP//YJlGXXnppzDmDveNXdcJAwY0CZIdOOgwZMiR4+/HHH4+ZjVT2UYGSAvH+/fv7nswoV66cva6A3z3tj5emJnr11VdNKrVt2zYkgI2WGda++p0QiIdeRz///HPUxmBO5l4ds6+++uqwZRRoul+7ahwWa3/UMEvL6CSR+8RFbi1evDhmt253tljl1gAApBuCYwCFloI2Tasj48ePt8Gv3/hYBQEqIVU2UoGfMq1+pcann366zcyJttOjRw/f+W01h6uCvXbt2iX9mBRcqkTVyQLrmNQB2I+CNqeUWsFshQoVfJc75phjIpYr6ySAN6snaqKkqXmczKmuRwqQ33///WAwrZLqWrVqhS1TpUqVkOz0bbfd5ls2riBUwZp7n1Nh4MCBwevr1q0zgwYN8g04dQw6lrwE4XrNaT5pL2X1r7rqquDtG2+80TRq1Mh3O9oHZ2y0yrD79etnT5r4GTVqlHnmmWfs9UcffTSuuZZj0ftF9xnpJILeR5rKyeEX5AMAkGo5gVTPlwEg7WiuVHdW9quvvgp+6a1evXpIgyUFkLrkZtsKCJxyaAWDmuLFPT2TX3bXrzxUQa2TfdPYYW2/YcOGNgDWmM5x48bZIEblqAoKNNdqJCr31famTZtmb9esWdMMHjzYNgBTsPHNN9/YbK0eg7vuuiu4j+79P+SQQ2wTItG+6Ji9j6PGFjvBrJbVOm5a9qyzzrKZXu137969TZcuXWymT8GaMooKohWw6fHXNiJNx6PmUsrU6eO+fPnyNqCuX7++mTJlis0Yq9T6jTfesOW5bnv27LHbdpon1alTx/Tt29eOH1VApUzhu+++az744IPgeG49vtGmBdLzqoBMVM7773//25xyyin2ugJ3nbjQOFZltN3TQelEhFP+6/d4xRLP86Dg3d3s6qabbgoJ6PTa0kmRww47zJ4omDRpkhkzZox9veh17JRfu7fplId37NgxuB33PMQaL9+tWzebTVcArs7Yek6nT59uX2dO0HzBBReYN998M+pjq8dNr5mvv/7a3tbYZD0nTZo0sSddlIHWa0Zl7TJ06NCQCgFRtYSOO9r70/361mvA/TzpdaX3l94veo3otar3nl4XzrHofeNUcQAAkFYUHAOA27Jly3TSLK7LkCFD8mXb48aNi3ub27dvt/tx8MEHR9zeSSedFPjhhx/i2t7OnTsDN954Y6BkyZJh2ylRokRgwIABgV27dgWmTJnie1916tQJbkvXYx2rHhM/q1atCvTo0SNQvHhx3/WqVasWeOqppwL79++PeUxPPPGE3XfvNooVKxa44447Iq6nbb/yyiuB+vXrR9z/ww8/PPDqq68G4qXntkqVKmHbycnJCZx++umB1atX2+USfbyiied50PPpNXbs2EDVqlV9ly9Tpkxg2LBhgb1790bcviPasWzatClw4YUXBooWLep7Hw899FBg3759cR2n9mXkyJH2tRHpPps3bx6YOHGi7/qRXtORXt8yffr0wOWXX+77nLovRx11VGD8+PEJP3cAABQUMscAMoYyu8r4LlmyxI5bLVGihC3xPe6443xLfWNRJu6zzz6z2TFNsaQsspp2qftyQVL2WNk+lXNrn5T9VYZTmUyNQ42XmkapjFrHo+ykjkdZ2xo1asS1vrKKs2bNCk4/pAyiMoTeqYXiocZRKhfXWFVlcVWRoOdJmcd0owy6Mrnz5s2zz4XGTit7rExqpCZouaHMs7K+qoZQ1YMeC2Wlc9MwS3/aNX2SsvF63vX61WOsCgLte37QfapSQxcdi7Lr2vdq1arZjLiqOQAASGcExwAAAACArEdDLgAAAABA1iM4BgAAAABkPYJjAAAAAEDWIzgGAAAAAGQ9gmMAAAAAQNYjOAYAAAAAZD2CYwAAAABA1iM4BgAAAABkPYJjAAAAAEDWIzgGAAAAAGQ9gmMAAAAAQNYjOAYAAAAAZD2CYwAAAABA1iM4BgAAAACYbPf/AGjHce7R/eqbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from photonai.base import Hyperpipe, PipelineElement\n",
    "from photonai.optimization import FloatRange, Categorical\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "tested_methods = Categorical(['RandomUnderSampler', 'RandomOverSampler', 'SMOTE', 'BorderlineSMOTE'])\n",
    "\n",
    "final_pipeline1 = Hyperpipe('5 - Final Pipeline CI + FS + GB',\n",
    "    outer_cv=StratifiedKFold(n_splits=5, shuffle=False),\n",
    "    inner_cv=StratifiedKFold(n_splits=3, shuffle=False),\n",
    "    use_test_set=True,\n",
    "    metrics=list(metrics.keys()),\n",
    "    best_config_metric='balanced_accuracy',\n",
    "    optimizer='sk_opt',\n",
    "    optimizer_params={'n_configurations': 30},\n",
    "    project_folder=f'./analysis/{dataset_type}{user}_{frequency}',\n",
    "    cache_folder=f'./cache/{dataset_type}{user}_{frequency}/',\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "\n",
    "final_pipeline1 += PipelineElement('ImbalancedDataTransformer',\n",
    "                           hyperparameters={'method_name': tested_methods})\n",
    "\n",
    "# from sklearn.feature_selection import f_classif\n",
    "\n",
    "# final_pipeline1 += PipelineElement('SelectKBest',\n",
    "#                                    hyperparameters={'k': [5, 10, 'all']},\n",
    "#                                    score_func=f_classif)\n",
    "\n",
    "\n",
    "\n",
    "final_pipeline1 += PipelineElement('GradientBoostingClassifier', \n",
    "                            hyperparameters={\n",
    "                                'loss': ['deviance', 'exponential'],\n",
    "                                'learning_rate': FloatRange(0.001, 1, 'logspace')\n",
    "                            }, random_state=4)\n",
    "\n",
    "# Fit hyperpipe\n",
    "final_pipeline1.fit(X, y)\n",
    "\n",
    "# Optionally print mean validation results\n",
    "# print(final_pipeline1.results_handler.get_mean_of_best_validation_configs_per_estimator())\n",
    "\n",
    "# Optionally print feature importances\n",
    "# print_feature_importances(final_pipeline1)\n",
    "\n",
    "# Optionally debug CV splits\n",
    "# for k, v in final_pipeline1.cross_validation.outer_folds.items():\n",
    "#     print(v.train_indices)\n",
    "#     print(v.test_indices)\n",
    "#     print(len(v.train_indices), len(v.test_indices))\n",
    "#     print()\n",
    "\n",
    "# Write additional reports\n",
    "add_other_report_to_summary(final_pipeline1, with_estimator_comparison=False)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix_from_pipeline(final_pipeline1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03737f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: Built-in GradientBoosting Feature Importances\n",
      "-------------------------------------------------------\n",
      "time_from_last_drug_taken 0.9115\n",
      "light                0.0788\n",
      "heart_rate           0.0095\n",
      "sleep_efficiency     0.0000\n",
      "deep                 0.0000\n",
      "nonrem_percentage    0.0000\n",
      "awake                0.0000\n",
      "rem                  0.0000\n",
      "nonrem_total         0.0000\n",
      "total                0.0000\n",
      "stress_score         0.0000\n",
      "steps                0.0000\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative 1: Built-in Feature Importances (Fastest)\n",
    "print(\"Method 1: Built-in GradientBoosting Feature Importances\")\n",
    "print(\"-\" * 55)\n",
    "try:\n",
    "    # Get the trained estimator\n",
    "    gb_estimator = final_pipeline1.optimum_pipe.named_steps['GradientBoostingClassifier']\n",
    "    \n",
    "    if hasattr(gb_estimator, 'feature_importances_'):\n",
    "        importances = gb_estimator.feature_importances_\n",
    "        feature_names = np.array(columns[1:-1])\n",
    "        \n",
    "        # Sort by importance\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        for i, idx in enumerate(indices):\n",
    "            print(f\"{feature_names[idx]:<20} {importances[idx]:.4f}\")\n",
    "    else:\n",
    "        print(\"Built-in feature importances not available\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6de4c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 2: Sklearn Permutation Importance\n",
      "----------------------------------------\n",
      "Error: 'PhotonPipeline' object has no attribute 'classes_'\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative 2: Using sklearn's permutation_importance directly\n",
    "print(\"Method 2: Sklearn Permutation Importance\")\n",
    "print(\"-\" * 40)\n",
    "try:\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    \n",
    "    # Get the fitted pipeline\n",
    "    fitted_pipeline = final_pipeline1.optimum_pipe\n",
    "    \n",
    "    # Use a subset of data for faster computation (optional)\n",
    "    # X_sample = X.sample(n=min(1000, len(X)), random_state=42)\n",
    "    # y_sample = y.loc[X_sample.index]\n",
    "    \n",
    "    # Calculate permutation importance\n",
    "    perm_importance = permutation_importance(\n",
    "        fitted_pipeline, X, y, \n",
    "        n_repeats=10,  # Reduced for speed\n",
    "        random_state=42,\n",
    "        scoring='balanced_accuracy'\n",
    "    )\n",
    "    \n",
    "    feature_names = np.array(columns[1:-1])\n",
    "    \n",
    "    # Sort by importance\n",
    "    indices = np.argsort(perm_importance.importances_mean)[::-1]\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        print(f\"{feature_names[idx]:<20} {perm_importance.importances_mean[idx]:.4f} \"\n",
    "              f\"{perm_importance.importances_std[idx]:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f056a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 3: SHAP Feature Importance\n",
      "-----------------------------------\n",
      "Error: The passed model is not callable and cannot be analyzed directly with the given masker! Model: PhotonPipeline(elements=[('ImbalancedDataTransformer',\n",
      "                          PipelineElement(config=None,\n",
      "                                          method_name='BorderlineSMOTE',\n",
      "                                          name='ImbalancedDataTransformer')),\n",
      "                         ('GradientBoostingClassifier',\n",
      "                          PipelineElement(ccp_alpha=0.0,\n",
      "                                          criterion='friedman_mse', init=None,\n",
      "                                          learning_rate=0.0020124243438942382,\n",
      "                                          loss='exponential', max_depth=3,\n",
      "                                          max_features=None,\n",
      "                                          max_leaf_nodes=None,\n",
      "                                          min_impurity_decrease=0.0,\n",
      "                                          min_samples_leaf=1,\n",
      "                                          min_samples_split=2,\n",
      "                                          min_weight_fraction_leaf=0.0,\n",
      "                                          n_estimators=100,\n",
      "                                          n_iter_no_change=None,\n",
      "                                          name='GradientBoostingClassifier',\n",
      "                                          random_state=4, subsample=1.0,\n",
      "                                          tol=0.0001, validation_fraction=0.1,\n",
      "                                          verbose=0, warm_start=False))])\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative 3: SHAP Values (if you have shap installed)\n",
    "print(\"Method 3: SHAP Feature Importance\")\n",
    "print(\"-\" * 35)\n",
    "try:\n",
    "    import shap\n",
    "    \n",
    "    # Get the fitted pipeline\n",
    "    fitted_pipeline = final_pipeline1.optimum_pipe\n",
    "    \n",
    "    # Use a sample for SHAP (it can be slow on large datasets)\n",
    "    X_sample = X.sample(n=min(500, len(X)), random_state=42)\n",
    "    \n",
    "    # Create explainer\n",
    "    explainer = shap.Explainer(fitted_pipeline, X_sample)\n",
    "    shap_values = explainer(X_sample)\n",
    "    \n",
    "    # Get mean absolute SHAP values as feature importance\n",
    "    feature_importance = np.abs(shap_values.values).mean(0)\n",
    "    feature_names = np.array(columns[1:-1])\n",
    "    \n",
    "    # Sort by importance\n",
    "    indices = np.argsort(feature_importance)[::-1]\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        print(f\"{feature_names[idx]:<20} {feature_importance[idx]:.4f}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"SHAP not installed. Install with: pip install shap\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bcee040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 4: DataFrame Summary\n",
      "-------------------------\n",
      "\n",
      "Computing permutation importances. This may take a while.\n",
      "*****************************************************************************************************\n",
      "Permutation Importances: Fitting model for outer fold 1\n",
      "Permutation Importances: Calculating performances for outer fold 1\n",
      "Error: 'PhotonPipeline' object has no attribute 'classes_'\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative 4: Simple DataFrame approach for better visualization\n",
    "print(\"Method 4: DataFrame Summary\")\n",
    "print(\"-\" * 25)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Using the original hyperpipe method but organizing results better\n",
    "    r = final_pipeline1.get_permutation_feature_importances(\n",
    "        n_repeats=20,  # Reduced for speed\n",
    "        random_state=0, \n",
    "        scoring='balanced_accuracy'\n",
    "    )\n",
    "    \n",
    "    # Create DataFrame for better organization\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': np.array(columns[1:-1]),\n",
    "        'Importance': r[\"mean\"],\n",
    "        'Std_Dev': r[\"std\"],\n",
    "        'Lower_Bound': r[\"mean\"] - 2 * r[\"std\"],\n",
    "        'Upper_Bound': r[\"mean\"] + 2 * r[\"std\"]\n",
    "    })\n",
    "    \n",
    "    # Sort by importance\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Display top 10\n",
    "    print(\"Top 10 Most Important Features:\")\n",
    "    print(importance_df.head(10).to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # Show only statistically significant features\n",
    "    significant_features = importance_df[importance_df['Lower_Bound'] > 0]\n",
    "    \n",
    "    if len(significant_features) > 0:\n",
    "        print(f\"\\nStatistically Significant Features ({len(significant_features)}):\")\n",
    "        print(significant_features.to_string(index=False, float_format='%.4f'))\n",
    "    else:\n",
    "        print(\"\\nNo statistically significant features found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8f40413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 5: Quick and Simple\n",
      "-------------------------\n",
      "Feature Importance Ranking:\n",
      " 1. time_from_last_drug_taken 0.9265\n",
      " 2. light                0.0631\n",
      " 3. steps                0.0102\n",
      " 4. sleep_efficiency     0.0000\n",
      " 5. total                0.0000\n",
      " 6. awake                0.0000\n",
      " 7. nonrem_percentage    0.0000\n",
      " 8. rem                  0.0000\n",
      " 9. deep                 0.0000\n",
      "10. nonrem_total         0.0000\n",
      "11. stress_score         0.0000\n",
      "12. heart_rate           0.0000\n"
     ]
    }
   ],
   "source": [
    "# Alternative 5: Quick and Simple (Minimal Code)\n",
    "print(\"Method 5: Quick and Simple\")\n",
    "print(\"-\" * 25)\n",
    "try:\n",
    "    # Just get the built-in importances with minimal code\n",
    "    estimator = final_pipeline1.optimum_pipe.named_steps['GradientBoostingClassifier']\n",
    "    importances = estimator.feature_importances_\n",
    "    features = np.array(columns[1:-1])\n",
    "    \n",
    "    # Create sorted list of (importance, feature) tuples\n",
    "    sorted_features = sorted(zip(importances, features), reverse=True)\n",
    "    \n",
    "    print(\"Feature Importance Ranking:\")\n",
    "    for i, (importance, feature) in enumerate(sorted_features[:15], 1):\n",
    "        print(f\"{i:2d}. {feature:<20} {importance:.4f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
