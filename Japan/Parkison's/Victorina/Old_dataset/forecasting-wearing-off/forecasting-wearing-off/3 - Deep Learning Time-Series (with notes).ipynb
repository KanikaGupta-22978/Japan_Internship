{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51decdc8-512e-4706-8552-d5e2de81035c",
   "metadata": {},
   "source": [
    "# Load libraries, configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f92fe-f74a-4871-a5bf-30ad71154ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from datetime import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (25,10)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa894e-67b3-49f5-aee6-e083b013df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedSparseCategoricalAccuracy(tf.keras.metrics.SparseCategoricalAccuracy):\n",
    "    def __init__(self, name='balanced_accuracy', dtype=None):\n",
    "        super().__init__(name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_flat = y_true\n",
    "        if y_true.shape.ndims == y_pred.shape.ndims:\n",
    "            y_flat = tf.squeeze(y_flat, axis=[-1])\n",
    "        y_true_int = tf.cast(y_flat, tf.int32)\n",
    "\n",
    "        cls_counts = tf.math.bincount(y_true_int)\n",
    "        cls_counts = tf.math.reciprocal_no_nan(tf.cast(cls_counts, self.dtype))\n",
    "        weight = tf.gather(cls_counts, y_true_int)\n",
    "        \n",
    "        return super().update_state(y_true, y_pred, sample_weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72cd49f-82c8-4942-ac7d-a8385247ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'participant10'\n",
    "interval = '15min'\n",
    "\n",
    "columns = [ 'timestamp', 'heart_rate', 'steps', 'stress_score',\n",
    "            'awake', 'deep', 'light', 'rem', \n",
    "           'nonrem_total', 'total', 'nonrem_percentage', 'sleep_efficiency']\n",
    "\n",
    "# Include FonLog data\n",
    "# columns += ['time_from_last_drug_taken'] #, 'wo_duration']\n",
    "\n",
    "# Additional data\n",
    "columns += ['timestamp_dayofweek', 'timestamp_hour_sin', 'timestamp_hour_cos'] # 'timestamp_hour',\n",
    "\n",
    "# 'wearing_off' | 'wearing_off_post_meds' | 'wearing_off_lead60'\n",
    "target_column = 'wearing_off' \n",
    "columns.append(target_column)\n",
    "\n",
    "# features to normalize\n",
    "# timestamp_dayofweek, wearing_off were not normalized\n",
    "normalize_features = ['heart_rate', 'steps', 'stress_score',\n",
    "                      'awake', 'deep', 'light', 'rem',\n",
    "                      'nonrem_total', 'total',\n",
    "                      'nonrem_percentage', 'sleep_efficiency',\n",
    "                      'timestamp_hour_sin', 'timestamp_hour_cos']\n",
    "\n",
    "participant_dictionary = json.load(open(f'./data/participant_dictionary.json'))\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "      BalancedSparseCategoricalAccuracy()]\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "MAX_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "SHIFT = 4\n",
    "use_hourly = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a7a409-6bda-40df-afb0-37df2110335f",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3891e-3944-410f-b069-3625beba2b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(f'./data/4-combined_data_{user}_{interval}.xlsx',\n",
    "                              index_col=\"timestamp\",\n",
    "                              usecols=columns,\n",
    "                              engine='openpyxl')\n",
    "# Fill missing data with 0\n",
    "dataset.fillna(0, inplace=True)\n",
    "\n",
    "# Filter data based on participants' dictionary\n",
    "dataset = dataset.loc[\n",
    "    (dataset.index >= participant_dictionary[user]['start_date']) &\n",
    "    (dataset.index < participant_dictionary[user]['end_date_plus_two'])\n",
    "]\n",
    "df = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d5080f-52fe-4f1b-a029-754f23dc6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(df[target_column])\n",
    "total = neg + pos\n",
    "initial_bias = np.log([pos/neg])\n",
    "output_bias = tf.keras.initializers.Constant(initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d79cd2-ff4b-431e-8ec3-d5699ce0d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96545284-a2fa-4caf-85f9-2883e3475573",
   "metadata": {},
   "source": [
    "## Slice to get hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38e2c1-b5be-40cf-8b12-a77aed518e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice [start:stop:step], starting from index 0, take every 4 record\n",
    "# Take every hour record only\n",
    "df = dataset[::4].copy() \n",
    "\n",
    "# Fix columns arrangement\n",
    "dataset = dataset.reindex(columns=columns[1:])\n",
    "record_size_per_day = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6d8fc2-c56e-4d73-a634-564070e8c453",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Encode hour-feature as cyclical features\n",
    "* [Encoding Cyclical Features for Deep Learning](https://www.avanwyk.com/encoding-cyclical-features-for-deep-learning/)\n",
    "* [request: year/quarter/month/week/day sine/cosine for Machine Learning](https://github.com/tidyverse/lubridate/issues/731)\n",
    "$$\n",
    "\\frac{\\text{24 hours}}{\\text{1 day}} \\cdot \\frac{\\text{60 minutes}}{\\text{1 hour}} \\cdot \\frac{\\text{60 seconds}}{\\text{1 minute}} = \\frac{\\text{86,400 seconds}}{\\text{1 day}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a7d6c-0fd7-4569-8206-82a9f5debda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix timestamp format\n",
    "date_time = pd.to_datetime(df.index, format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "# Convert to timestamp\n",
    "timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "\n",
    "# Get seconds per day\n",
    "day = 24 * 60 * 60 \n",
    "# Get seconds per year\n",
    "year = 365.2425 * day\n",
    "\n",
    "# Get sine(), cosine() for hour-feature\n",
    "df['timestamp_hour_sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['timestamp_hour_cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "\n",
    "# Move `wearing_off` feature at the end of the dataframe\n",
    "tmp = df.pop('timestamp_dayofweek')\n",
    "df['timestamp_dayofweek'] = tmp\n",
    "tmp = df.pop('wearing_off')\n",
    "df['wearing_off'] = tmp\n",
    "\n",
    "display(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5501a9-b7ad-40a5-8ecf-deb7448df006",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualize data with wearing-off periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e65ee34-d4a5-4d18-9666-d7138b42cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify columns to plot\n",
    "plot_cols = df.columns\n",
    "plot_features = df[plot_cols]\n",
    "plot_features.index = date_time\n",
    "i = 1\n",
    "# plot each column\n",
    "plt.figure(figsize=(25,10))\n",
    "for group in plot_cols:\n",
    "    if group == 'wearing_off':\n",
    "        continue\n",
    "    ax = plt.subplot(len(plot_cols), 1, i)\n",
    "    plt.fill_between(\n",
    "        plot_features.index, 0, plot_features.loc[:, [group]].max(), where=plot_features.wearing_off, alpha=0.4, color=\"red\", transform=ax.get_xaxis_transform()\n",
    "    )\n",
    "    plt.plot(plot_features.loc[:, [group]])\n",
    "    plt.title(group, y=0.5, loc='right')\n",
    "    i += 1\n",
    "plt.suptitle(f'Input features with wearing-off periods for Participant {user.replace(\"participant\", \"\")}')\n",
    "plt.savefig(f'./results/{user}_wearing_off.pdf')\n",
    "plt.show()\n",
    "\n",
    "# or\n",
    "# plot_cols = df.columns\n",
    "# plot_features = df[plot_cols]\n",
    "# plot_features.index = date_time\n",
    "# axes = plot_features.plot(subplots=True)\n",
    "# for axis in axes:\n",
    "#     axis.fill_between(\n",
    "#         plot_features.index, 0, 100, where=plot_features.wearing_off, alpha=0.4, color=\"red\", transform=axis.get_xaxis_transform()\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b676e3-0655-40a5-870f-705ea7f37db1",
   "metadata": {},
   "source": [
    "## Summary of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea70d6-2e64-49d3-b64e-8e9f9917a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'./results/descriptive_summary.xlsx'):\n",
    "    with pd.ExcelWriter(f'./results/descriptive_summary.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "        df.describe().transpose().to_excel(writer, sheet_name=f'{user}')\n",
    "else:\n",
    "    with pd.ExcelWriter(f'./results/descriptive_summary.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "        df.describe().transpose().to_excel(writer, sheet_name=f'{user}')\n",
    "\n",
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246113f4-f7a4-4963-aab4-c5f6da28bebc",
   "metadata": {},
   "source": [
    "# Split data\n",
    "* (60%, 20%, 20%) = training, validation, test sets\n",
    "* Not randomly shuffled before splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de47ef69-98ea-49f0-8054-251c585022ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_size_per_day = 96\n",
    "\n",
    "# training data 60% \n",
    "TRAINING_PERCENTAGE = 0.6\n",
    "# validation data 20%\n",
    "VALIDATION_PERCENTAGE = 0.2\n",
    "\n",
    "column_indices = { name: i for i, name in enumerate(df.columns) }\n",
    "total_rows = len(df)\n",
    "num_features = len(df.columns)\n",
    "\n",
    "training_end_index = int(total_rows * TRAINING_PERCENTAGE)\n",
    "validation_end_index = int(total_rows * (TRAINING_PERCENTAGE + VALIDATION_PERCENTAGE))\n",
    "\n",
    "train_df = df[0:training_end_index].copy()\n",
    "validation_df = df[training_end_index:validation_end_index].copy()\n",
    "test_df = df[validation_end_index:].copy()\n",
    "\n",
    "print(f\"Training data: {round(len(train_df)/record_size_per_day, 3)} days\")\n",
    "print(f\"Validation data: {round(len(validation_df)/record_size_per_day, 3)} days\")\n",
    "print(f\"Test data: {round(len(test_df)/record_size_per_day, 3)} days\")\n",
    "print(f\"Total data: {round(len(df)/record_size_per_day, 3)} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a57c0-3c17-4585-afba-b9c77a2c7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_size_per_day = 24\n",
    "\n",
    "def split_train_validation_test_set(df, test_set_size=1, validation_percentage=0.2):\n",
    "    test_size = record_size_per_day * test_set_size\n",
    "    test_set = df.tail(test_size).copy()\n",
    "    total_rows = len(df) - test_size\n",
    "    training_end_index = int(total_rows - total_rows * validation_percentage)\n",
    "    validation_end_index = int(total_rows)    \n",
    "    \n",
    "    train_df = df.iloc[0:training_end_index].copy()\n",
    "    validation_df = df.iloc[training_end_index:validation_end_index].copy()\n",
    "    return train_df, validation_df, test_set\n",
    "\n",
    "train_df, validation_df, test_df = split_train_validation_test_set(df, \n",
    "                                                                   test_set_size=1, \n",
    "                                                                   validation_percentage=0.2)\n",
    "\n",
    "print(f\"Training data: {round(len(train_df)/record_size_per_day * 1, 3)} days\")\n",
    "print(f\"Validation data: {round(len(validation_df)/record_size_per_day * 1, 3)} days\")\n",
    "print(f\"Test data: {round(len(test_df)/record_size_per_day * 1, 3)} days\")\n",
    "print(f\"Total data: {round(len(df)/record_size_per_day * 1, 3)} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a25bfeb-395a-4988-a0ec-9087671d1022",
   "metadata": {},
   "source": [
    "# Normalize data\n",
    "$$\n",
    "Z = \\frac{X - \\bar{X}}{\\sigma}\n",
    "$$\n",
    "where:\n",
    "* $Z$: normalized data\n",
    "* $X$: input features\n",
    "* $\\bar{X}$: average of each input feature\n",
    "* $\\sigma$: standard deviation of each input feature\n",
    "\n",
    "Note: Use $\\bar{X}_{training}$ & $\\sigma_{training}$ so that models have no access to the values in the **validation** & **test** sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec0ee09-37fd-4cfe-a0cc-0085a0d92886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features to normalize\n",
    "# timestamp_dayofweek, wearing_off were not normalized\n",
    "normalize_features = ['heart_rate', 'steps', 'stress_score', 'awake', 'deep', 'light', 'rem',\n",
    " 'nonrem_total', 'total', 'nonrem_percentage', 'sleep_efficiency',\n",
    " 'timestamp_hour_sin', 'timestamp_hour_cos'] \n",
    "train_mean = train_df.loc[:, normalize_features].mean()\n",
    "train_std = train_df.loc[:, normalize_features].std()\n",
    "\n",
    "train_df.loc[:, normalize_features] = (train_df.loc[:, normalize_features] - train_mean) / train_std\n",
    "validation_df.loc[:, normalize_features] = (validation_df.loc[:, normalize_features] - train_mean) / train_std\n",
    "test_df.loc[:, normalize_features] = (test_df.loc[:, normalize_features] - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80439eab-1c6c-4d17-9e9d-b7706084fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standardized = (df.loc[:, normalize_features] - train_mean) / train_std\n",
    "df_standardized = pd.merge(df_standardized, df.iloc[:, -2:], left_index=True,right_index=True)\n",
    "df_standardized = df_standardized.melt(var_name='Columns', value_name='Normalized')\n",
    "plt.figure()\n",
    "ax = sns.violinplot(x='Columns', y='Normalized', data=df_standardized)\n",
    "_ = ax.set_xticklabels(df.keys(), rotation=45)\n",
    "plt.title(\"Distribution of normalized features\")\n",
    "# plt.savefig(f'./results/{user}_distribution_normalized_data.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcefe86-4753-4754-a747-5b9b11ceab28",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626358c7-f8f1-4c2a-9708-fddec24b7998",
   "metadata": {},
   "source": [
    "## `WindowGenerator` class\n",
    "`WindowGenerator` class generates data window with the following specifications:\n",
    "* width / number of timesteps of the input data and label\n",
    "* offset time between input data & label\n",
    "* features used for inputs, label or both\n",
    "\n",
    "| [Source: tensorflow.org](https://www.tensorflow.org/tutorials/structured_data/images/raw_window_1h.png) |\n",
    "|-----|\n",
    "| ![raw window.png](https://www.tensorflow.org/tutorials/structured_data/images/raw_window_1h.png) |\n",
    "\n",
    "* `Input width = 6`: uses 6-hour history\n",
    "* `Label width = 1`, `offset = 1`: predicts next 1-hour into the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e37fa-c44b-45c4-b45a-5d3842b174b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df=train_df, validation_df=validation_df, test_df=test_df,\n",
    "               label_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.validation_df = validation_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    # Work out the target label column indices.\n",
    "    # Example: { 'wearing_off': 0 }\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "    # input column indices\n",
    "    # Example: { 'heart_rate': 0 , 'stress_score': 1 }\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c47dec-10a3-47e7-9a6a-7c9cf299d6f3",
   "metadata": {},
   "source": [
    "## `split_window` function\n",
    "Converts data into window of inputs and window of labels\n",
    "\n",
    "| [Source: tensorflow.org](https://www.tensorflow.org/tutorials/structured_data/images/split_window.png) |\n",
    "|-----|\n",
    "| ![split_window.png](https://www.tensorflow.org/tutorials/structured_data/images/split_window.png) |\n",
    "\n",
    "**Note**: Added `remove_target_column_from_input` parameter to control whether target column shall be included in the input\n",
    "* `True`: if target column/s should not be included\n",
    "* `False`: if target column/s should be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b090eb-98bd-47ea-a524-a52851d40152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_window(self, features, remove_target_column_from_input=True):\n",
    "    if remove_target_column_from_input:\n",
    "        inputs = features[:, self.input_slice, :14]\n",
    "    else:\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "    labels = features[:, self.labels_slice, :]\n",
    "    if self.label_columns is not None:\n",
    "        labels = tf.stack(\n",
    "            [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "            axis=-1)\n",
    "\n",
    "    # Slicing doesn't preserve static shape information, so set the shapes\n",
    "    # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "    inputs.set_shape([None, self.input_width, None])\n",
    "    labels.set_shape([None, self.label_width, None])\n",
    "    \n",
    "    return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "attachments": {
    "497d9a68-ddd3-473b-96ff-969302109744.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5526ba67-5e61-4296-a822-752e84dce856",
   "metadata": {},
   "source": [
    "## `make_dataset` function\n",
    "Converts Dataframe into `tf.data.Dataset` of `(input_window, label_window)` using `tf.keras.utils.timeseries_dataset_from_array`.\n",
    "\n",
    "Each window has dimension of `(number_of_batches, total_window_size, number_of_features)`.\n",
    "\n",
    "**Note**: Accepts `remove_target_column_from_input` parameter to control whether target column shall be included in the input\n",
    "* `True`: if target column/s should not be included\n",
    "* `False`: if target column/s should be included\n",
    "\n",
    "| Sample batch |\n",
    "|-----|\n",
    "| ![image.png](attachment:497d9a68-ddd3-473b-96ff-969302109744.png) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8bea21-eebb-44f0-8c39-f1d3f8f74a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(self, data, remove_target_column_from_input=True):\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        data=data,\n",
    "        targets=None,\n",
    "        sequence_length=self.total_window_size,\n",
    "        sequence_stride=1,\n",
    "        shuffle=True,\n",
    "        batch_size=BATCH_SIZE,)\n",
    "    \n",
    "    ds = ds.map(lambda d: self.split_window(d, remove_target_column_from_input))\n",
    "    \n",
    "    return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f58ba-4e3d-4cbd-9357-06ee05aeb487",
   "metadata": {},
   "source": [
    "## `train`, `validation`, `test` & `sample` functions\n",
    "\n",
    "* `train`, `validation`, `test`: holds the train, validation & test sets inside the `WindowGenerator` instance.<br>\n",
    "By default, each set remove target column from input window.\n",
    "\n",
    "* `sample`: holds a sample from train set for visualization.<br>\n",
    "By default, target column is not remove as it is required in the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aace39-423c-429a-b6d9-e22b64703402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, remove_target_column_from_input=True):\n",
    "    return self.make_dataset(self.train_df, remove_target_column_from_input)\n",
    "\n",
    "def validation(self, remove_target_column_from_input=True):\n",
    "    return self.make_dataset(\n",
    "        self.validation_df, \n",
    "        remove_target_column_from_input=remove_target_column_from_input)\n",
    "\n",
    "def test(self, remove_target_column_from_input=True):\n",
    "    return self.make_dataset(\n",
    "        self.test_df, \n",
    "        remove_target_column_from_input=remove_target_column_from_input)\n",
    "\n",
    "def sample(self):\n",
    "    result = self.make_dataset(self.train_df, remove_target_column_from_input=False)\n",
    "    result = next(iter(result))\n",
    "    return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.validation = validation\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.sample = sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1f39a-9f6d-4bc6-9229-2a7f4fe2d788",
   "metadata": {},
   "source": [
    "## `plot` function\n",
    "Generate a maximum of 3 subplots from the sample set.<br>\n",
    "The plot shows the input data, ground truth data, and predicted data (if model is provided).\n",
    "\n",
    "**Note**: Accepts `override` parameter when model expects data window to have target column.<br>\n",
    "Otherwise, it expects data window without target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e08b1-6b96-4523-867c-00b363869482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(self, model=None, plot_col='wearing_off', max_subplots=3, override=False):\n",
    "    inputs, labels = self.sample()\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_col_index = self.column_indices[plot_col]\n",
    "    max_n = min(max_subplots, len(inputs))\n",
    "    for n in range(max_n):\n",
    "        plt.subplot(max_n, 1, n+1)\n",
    "        plt.ylabel(f'{plot_col} [normed]')\n",
    "        plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "        if self.label_columns:\n",
    "          label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "        else:\n",
    "          label_col_index = plot_col_index\n",
    "        if label_col_index is None:\n",
    "          continue\n",
    "        plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                    edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "        \n",
    "        if model is not None:\n",
    "            if override or inputs.shape[2] == 14:\n",
    "                predictions = model(inputs)\n",
    "            else:\n",
    "                predictions = model(inputs[:, :, :14])\n",
    "            plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                      marker='X', edgecolors='k', label='Predictions',\n",
    "                      c='#ff7f0e', s=64)\n",
    "        if n == 0:\n",
    "          plt.legend()\n",
    "    plt.xlabel('Time [h]')\n",
    "\n",
    "WindowGenerator.plot = plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d0a7de-8bce-4944-bb88-5b0ca846a9cc",
   "metadata": {},
   "source": [
    "## `WindowGenerator` usage\n",
    "**Example**: Predict **1** hour into the future, given **24** hours of history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e4be5-041a-49c0-8289-bd107168a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "w1 = WindowGenerator(input_width=24, label_width=1, shift=1,\n",
    "                     train_df=train_df, validation_df=validation_df, test_df=test_df,\n",
    "                     label_columns=['wearing_off'])\n",
    "w1.plot(plot_col=\"wearing_off\")\n",
    "\n",
    "for example_inputs, example_labels in w1.train().take(1):\n",
    "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798806b3-887e-4f4f-8e8b-508788558442",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b170acfe-5295-4f5e-a58d-4686179a7426",
   "metadata": {},
   "source": [
    "|Single-step window |Expanded single-step window|Conv window |\n",
    "|-------------------|---------------------------|------------|\n",
    "|![single-step-window.png](https://www.tensorflow.org/tutorials/structured_data/images/narrow_window.png)|![expanded-single-step-window.png](https://www.tensorflow.org/tutorials/structured_data/images/last_window.png)       |![conv.png](https://www.tensorflow.org/tutorials/structured_data/images/conv_window.png) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9081b73-bae7-4e8c-81a6-9f01e9350c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIFT = 4\n",
    "BATCH_SIZE = 8\n",
    "single_step_window = WindowGenerator(input_width=1, label_width=1, shift=SHIFT,\n",
    "                                     train_df=train_df, validation_df=validation_df, test_df=test_df,\n",
    "                                     label_columns=['wearing_off'])\n",
    "single_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144fed6-8f79-48dc-81fd-d8b3fde6c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_single_step_window = WindowGenerator(input_width=24, label_width=24, shift=SHIFT,\n",
    "                              train_df=train_df, validation_df=validation_df, test_df=test_df,\n",
    "                              label_columns=['wearing_off'])\n",
    "wide_single_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3bbe74-9145-4640-9073-db29a9086e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_STEP_WIDTH = 24 # t0, t1, t2, ..., t24\n",
    "multi_step_window = WindowGenerator(input_width=MULTI_STEP_WIDTH, label_width=1, shift=SHIFT,\n",
    "                                    train_df=train_df, validation_df=validation_df, test_df=test_df,\n",
    "                                    label_columns=['wearing_off'])\n",
    "multi_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a110e-31c0-4543-bde6-7a31e92149a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_WIDTH = 24\n",
    "INPUT_WIDTH = LABEL_WIDTH + (MULTI_STEP_WIDTH - 1)\n",
    "wide_multi_step_window = WindowGenerator(input_width=INPUT_WIDTH, label_width=LABEL_WIDTH, shift=SHIFT,\n",
    "                                         train_df=train_df, validation_df=validation_df, test_df=test_df,\n",
    "                                         label_columns=['wearing_off'])\n",
    "\n",
    "wide_multi_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd55213-8ccc-4563-b625-0e9a25d8f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 100\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min',\n",
    "                                                    restore_best_weights=True)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                metrics=METRICS)\n",
    "\n",
    "  history = model.fit(window.train(True), epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.validation(True),\n",
    "                      callbacks=[early_stopping])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d1820-0342-45ce-a0c3-f13450cb0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance = {}\n",
    "test_performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8181af42-b74e-49e8-98f2-d46df9895403",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e00b8f-cead-4ced-89aa-5222035b3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Baseline'\n",
    "\n",
    "K.clear_session()\n",
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fb8851-295c-44a9-ae63-f6f4c22ae616",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db5f2b-c261-4486-9eee-ca4f0f5bbdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(label_index=column_indices['wearing_off'])\n",
    "baseline.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                 metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded10de-ccf3-4a6f-874e-1ec39ba34385",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance[model_name] = baseline.evaluate(single_step_window.validation(False))\n",
    "test_performance[model_name] = baseline.evaluate(single_step_window.test(False), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194fb5c-4213-4bdf-8f31-80f9ceaf6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929cabb8-7955-4e89-81c9-073e7ebe548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a76e14-810a-445f-9c50-a3dbf56a46c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e8cba-fb83-420a-8d5b-cf1c6a20a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_single_step_window.plot(baseline, override=True)\n",
    "plt.suptitle(f'Sample forecasting for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "# plt.savefig(f'./results/{user}_sample_prediction_{model_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df327baf-0f79-4643-998e-a427dfa56edc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774211ec-0d62-4c84-94a5-b2966820301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "for input, label in single_step_window.test(False):\n",
    "    output = baseline(input).numpy()\n",
    "    predictions += list(output.reshape(len(output)))\n",
    "    \n",
    "    l = label.numpy()\n",
    "    labels += list(l.reshape(len(l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a4da60-01f3-4444-8645-0ac4f9461c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(f'./results/confusion_matrix.xlsx'):\n",
    "#     with pd.ExcelWriter(f'./results/confusion_matrix.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "#         pd.DataFrame(\n",
    "#             classification_report(predictions, labels,\n",
    "#                                   target_names=['normal', 'wearing-off'],\n",
    "#                                   output_dict=True)\n",
    "#         ).to_excel(writer, sheet_name=f'{user} - {model_name}')\n",
    "# else:\n",
    "#     with pd.ExcelWriter(f'./results/confusion_matrix.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "#         pd.DataFrame(\n",
    "#             classification_report(predictions, labels,\n",
    "#                                   target_names=['normal', 'wearing-off'],\n",
    "#                                   output_dict=True)\n",
    "#         ).to_excel(writer, sheet_name=f'{user} - {model_name}')\n",
    "    \n",
    "print(\n",
    "    classification_report(predictions, labels,\n",
    "                      target_names=['normal', 'wearing-off'],\n",
    "                      output_dict=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f6213d-f472-4bc5-b9e0-d8d2833b8a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(predictions, labels, normalize='pred')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['normal', 'wearing-off'])\n",
    "disp.plot()\n",
    "plt.title(f'Confusion matrix for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "# plt.savefig(f'./results/{user}_confusion_matrix_{model_name}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb1156e-1ee0-4818-8d32-e6cad936f129",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a69598-062d-4ce3-a48c-d18284951361",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Linear\"\n",
    "\n",
    "K.clear_session()\n",
    "linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bc5a59-5c3d-4886-b0bb-6457c0e35434",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f99806d-babc-4105-9e77-6f7453e16983",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(linear, single_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259c7bb-9105-442c-8b32-00ffdb1a3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance[model_name] = linear.evaluate(single_step_window.validation())\n",
    "test_performance[model_name] = linear.evaluate(single_step_window.test(), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9595d58a-7c87-410c-9139-7d1944ba88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9758d-c313-41ea-9479-b763b0a0e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4054e8d4-a178-4323-8f68-ee8124af6624",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46957211-2bad-4100-9d32-9f26fe5056dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_single_step_window.plot(linear)\n",
    "plt.suptitle(f'Sample forecasting for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "# plt.savefig(f'./results/{user}_sample_prediction_{model_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c4f587-33e3-4d8b-ae33-91bf0a916a47",
   "metadata": {},
   "source": [
    "### Visualize learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29719f98-c50a-44fa-aa6c-b0200ecd2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.title(f'Learning Curve Loss for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "plt.legend()\n",
    "# plt.savefig(f'./results/{user}_learning_curve_{model_name}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f59a45-86b9-48fb-912a-6bbc1026355f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb64c58-53a8-426b-a025-f933f148e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "for input, label in single_step_window.test():\n",
    "    output = linear(input).numpy()\n",
    "    predictions += list(output.reshape(len(output)))\n",
    "    \n",
    "    l = label.numpy()\n",
    "    labels += list(l.reshape(len(l)))\n",
    "    \n",
    "predictions = list(map(lambda x: 0 if x < 0.5 else 1, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf59324-755f-4c19-bef0-2a0bb7e6aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(f'./results/confusion_matrix.xlsx'):\n",
    "#     with pd.ExcelWriter(f'./results/confusion_matrix.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "#         pd.DataFrame(\n",
    "#             classification_report(predictions, labels,\n",
    "#                                   target_names=['normal', 'wearing-off'],\n",
    "#                                   output_dict=True)\n",
    "#         ).to_excel(writer, sheet_name=f'{user} - {model_name}')\n",
    "# else:\n",
    "#     with pd.ExcelWriter(f'./results/confusion_matrix.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "#         pd.DataFrame(\n",
    "#             classification_report(predictions, labels,\n",
    "#                                   target_names=['normal', 'wearing-off'],\n",
    "#                                   output_dict=True)\n",
    "#         ).to_excel(writer, sheet_name=f'{user} - {model_name}')\n",
    "\n",
    "print(\n",
    "    classification_report(predictions, labels,\n",
    "                          target_names=['normal', 'wearing-off'],\n",
    "                          output_dict=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec4357-bda9-42f8-8ed8-5d015c3014fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(predictions, labels, normalize='pred')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['normal', 'wearing-off'])\n",
    "disp.plot()\n",
    "plt.title(f'Confusion matrix for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "# plt.savefig(f'./results/{user}_confusion_matrix_{model_name}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f490a22f-6fe6-4ab4-af0f-2ec4984839be",
   "metadata": {},
   "source": [
    "### Feature importance from layer's weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e02f4-e0d9-4197-a813-37cb38476dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = range(len(train_df.columns) - 1),\n",
    "        height=linear.layers[0].kernel[:,0].numpy())\n",
    "axis = plt.gca()\n",
    "axis.set_xticks(range(len(train_df.columns) - 1))\n",
    "_ = axis.set_xticklabels(train_df.columns[:-1], \n",
    "                         rotation=45, fontsize=18, ha='right')\n",
    "plt.title(f'Feature importance for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "# plt.savefig(f'./results/{user}_feature_importance_{model_name}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a1aaa0-1886-46d6-8236-f555fba4beea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Single-time-step Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f3f79f-593c-486a-ac4b-1986a11278ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Single-time-step Dense\"\n",
    "\n",
    "K.clear_session()\n",
    "single_time_step_dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2961b25a-8df4-4d71-a4b3-57ead8df1fde",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be24102-4791-4f6e-941a-254b1fcea88d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(single_time_step_dense, single_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a23ebf3-cb01-4716-90e3-2e336cb52dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance[model_name] = single_time_step_dense.evaluate(single_step_window.validation())\n",
    "test_performance[model_name] = single_time_step_dense.evaluate(single_step_window.test(), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba6895-8f78-41b0-ba36-41fc16745bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab6fcc-8408-4206-ade0-8792344764f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c93762-674a-4c30-b54f-f5145d3c3137",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c1098-cc77-4b40-b945-2ecd8f7dac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_single_step_window.plot(single_time_step_dense)\n",
    "plt.suptitle(f'Sample forecasting for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "# plt.savefig(f'./results/{user}_sample_prediction_{model_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56504700-4906-4399-ab67-ad4c15d00322",
   "metadata": {},
   "source": [
    "### Visualize learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95616b-f7ff-4a85-8fa0-a4c74e125490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.title(f'Learning Curve Loss for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "plt.legend()\n",
    "# plt.savefig(f'./results/{user}_learning_curve_{model_name}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df87acb-4031-4d56-9eec-2847ef31a159",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8147faa-0f99-47a4-8434-0c3abff26ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "for input, label in single_step_window.test():\n",
    "    output = single_time_step_dense(input).numpy()\n",
    "    predictions += list(output.reshape(len(output)))\n",
    "    \n",
    "    l = label.numpy()\n",
    "    labels += list(l.reshape(len(l)))\n",
    "    \n",
    "predictions = list(map(lambda x: 0 if x < 0.5 else 1, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307545b8-fc85-4d08-91da-88b38e103652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(f'./results/confusion_matrix.xlsx'):\n",
    "#     with pd.ExcelWriter(f'./results/confusion_matrix.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "#         pd.DataFrame(\n",
    "#             classification_report(predictions, labels,\n",
    "#                                   target_names=['normal', 'wearing-off'],\n",
    "#                                   output_dict=True)\n",
    "#         ).to_excel(writer, sheet_name=f'{user} - {model_name}')\n",
    "# else:\n",
    "#     with pd.ExcelWriter(f'./results/confusion_matrix.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "#         pd.DataFrame(\n",
    "#             classification_report(predictions, labels,\n",
    "#                                   target_names=['normal', 'wearing-off'],\n",
    "#                                   output_dict=True)\n",
    "#         ).to_excel(writer, sheet_name=f'{user} - {model_name}')\n",
    "\n",
    "print(\n",
    "    classification_report(predictions, labels,\n",
    "                          target_names=['normal', 'wearing-off'],\n",
    "                          output_dict=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975944a-d25d-4124-a59a-0eb3dc0c49bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(predictions, labels, normalize='pred')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['normal', 'wearing-off'])\n",
    "disp.plot()\n",
    "plt.suptitle(f'Confusion matrix for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "# plt.savefig(f'./results/{user}_confusion_matrix_{model_name}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa2a800-75c3-413a-a3da-9e1c927c65e1",
   "metadata": {},
   "source": [
    "### Feature importance from layer's weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17beebf3-c708-4838-88b5-826a871dc4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = range(len(train_df.columns) - 1),\n",
    "        height=single_time_step_dense.layers[0].kernel[:,0].numpy())\n",
    "axis = plt.gca()\n",
    "axis.set_xticks(range(len(train_df.columns) - 1))\n",
    "_ = axis.set_xticklabels(train_df.columns[:-1], \n",
    "                         rotation=45, fontsize=18, ha='right')\n",
    "plt.title(f'Feature importance for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "# plt.savefig(f'./results/{user}_feature_importance_{model_name}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44919d4e-73ff-41b9-9756-74f372aa0090",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi-time-step Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066389b-e231-4367-b7f2-a2dfd19fd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Multi-time-step Dense\"\n",
    "\n",
    "K.clear_session()\n",
    "multi_time_step_dense = tf.keras.Sequential([\n",
    "    # Shape: (time, features) => (time*features)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid'),\n",
    "    # Add back the time dimension.\n",
    "    # Shape: (outputs) => (1, outputs)\n",
    "    tf.keras.layers.Reshape([1, -1]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532ef2e-a154-4d58-8904-956f3fccec47",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34775a92-e7b3-4575-8700-8e8e798aecc0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(multi_time_step_dense, multi_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4871a48-d9cb-4e7a-9fad-eb8b4079acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance[model_name] = multi_time_step_dense.evaluate(multi_step_window.validation())\n",
    "test_performance[model_name] = multi_time_step_dense.evaluate(multi_step_window.test(), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc5dc5e-6361-47e4-88c3-0b83f028f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ca122-8a50-4976-8b3a-342921b79139",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea36f54-b58a-4b73-babf-0ec052831f02",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad0302-9af9-4a27-a6e2-08d239baa428",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_step_window.plot(multi_time_step_dense)\n",
    "plt.suptitle(f'Sample forecasting for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "# plt.savefig(f'./results/{user}_sample_prediction_{model_name}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb497b1-a323-4915-9afa-e0b7fe3341ed",
   "metadata": {},
   "source": [
    "### Visualize learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb7273-5b1f-4db2-b109-c84bf1293a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.title(f'Learning Curve Loss for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "plt.legend()\n",
    "# plt.savefig(f'./results/{user}_learning_curve_{model_name}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49708ea-6df7-4ddb-97bc-af766b1a797b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ccbfb0-522b-4087-abee-53bf4ae68c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "for input, label in multi_step_window.test():\n",
    "    output = multi_time_step_dense(input).numpy()\n",
    "    predictions += list(output.reshape(len(output)))\n",
    "    \n",
    "    l = label.numpy()\n",
    "    labels += list(l.reshape(len(l)))\n",
    "    \n",
    "predictions = list(map(lambda x: 0 if x < 0.5 else 1, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b42d6-f448-43ac-8c90-f288191be5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1.0 in labels:\n",
    "    # if os.path.exists(f'./results/confusion_matrix.xlsx'):\n",
    "    #     with pd.ExcelWriter(f'./results/confusion_matrix.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "    #         pd.DataFrame(\n",
    "    #             classification_report(predictions, labels,\n",
    "    #                                   target_names=['normal', 'wearing-off'],\n",
    "    #                                   output_dict=True)\n",
    "    #         ).to_excel(writer, sheet_name=f'{user} - {model_name}')\n",
    "    # else:\n",
    "    #     with pd.ExcelWriter(f'./results/confusion_matrix.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "    #         pd.DataFrame(\n",
    "    #             classification_report(predictions, labels,\n",
    "    #                                   target_names=['normal', 'wearing-off'],\n",
    "    #                                   output_dict=True)\n",
    "    #         ).to_excel(writer, sheet_name=f'{user} - {model_name}')\n",
    "\n",
    "    print(\n",
    "        classification_report(predictions, labels,\n",
    "                              target_names=['normal', 'wearing-off'],\n",
    "                              output_dict=False)\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        classification_report(predictions, labels,\n",
    "                              target_names=['normal', 'wearing-off'],\n",
    "                              output_dict=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f87d944-31cb-4c87-b64d-19c8e645f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1.0 in labels:\n",
    "    cm = confusion_matrix(predictions, labels, normalize='pred')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['normal', 'wearing-off'])\n",
    "    disp.plot()\n",
    "    plt.title(f'Confusion matrix for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "    # plt.savefig(f'./results/{user}_confusion_matrix_{model_name}.pdf')\n",
    "    plt.show()\n",
    "else:\n",
    "    cm = confusion_matrix(predictions, labels, normalize='pred')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['normal', 'wearing-off'])\n",
    "    disp.plot()\n",
    "    plt.title(f'Confusion matrix for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "    # plt.savefig(f'./results/{user}_confusion_matrix_{model_name}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b245db-a95a-4d98-85e2-8134a4fbffe6",
   "metadata": {},
   "source": [
    "### Feature importance from layer's weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828d217-0a79-4883-bb22-9b8e206392f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_time_step_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c230bc12-9ad4-4ad1-a645-ceaae231a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(x = range(len(train_df.columns) - 1),\n",
    "#         height=multi_time_step_dense.layers[3].kernel[:,0].numpy())\n",
    "# axis = plt.gca()\n",
    "# axis.set_xticks(range(len(train_df.columns) - 1))\n",
    "# _ = axis.set_xticklabels(train_df.columns[:-1], \n",
    "#                          rotation=45, fontsize=18, ha='right')\n",
    "# plt.title(f'Feature importance for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "# plt.savefig(f'./results/{user}_feature_importance_{model_name}.pdf')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da334e-f92c-4dba-ab17-50f941ec2443",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff927f8-b3b1-4629-815f-f44d1a63e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CNN\"\n",
    "\n",
    "K.clear_session()\n",
    "cnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=16,\n",
    "                           kernel_size=(MULTI_STEP_WIDTH,),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Dense(units=16, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76523258-7400-4501-b8fd-40ab68b8dfdf",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed95945-9538-44e9-b8a8-a393cc6fa81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(cnn_model, multi_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a5b75-89ab-4784-8ad2-e9075d46a0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance['CNN'] = cnn_model.evaluate(multi_step_window.validation())\n",
    "test_performance['CNN'] = cnn_model.evaluate(multi_step_window.test(), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6525ddf8-0507-4059-bd28-4bd054feb72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18fc626-1c95-4561-8441-18d3883dbb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24277da-059a-46fc-9bb6-b794a508c22d",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0ea86-92cc-460e-a2d5-18467223c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_multi_step_window.plot(cnn_model)\n",
    "plt.suptitle(f'Sample forecasting for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "# plt.savefig(f'./results/{user}_sample_prediction_{model_name}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf183638-4824-4de4-b480-b28949f64bf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualize learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4fc3cb-c501-4378-be85-36cc812accdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.title(f'Learning Curve Loss for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "plt.legend()\n",
    "# plt.savefig(f'./results/{user}_learning_curve_{model_name}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed4c0ba-0733-46a1-95fe-5f20df301479",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e150780-540d-4933-9b41-5e50faa79614",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "for input, label in multi_step_window.test():\n",
    "    output = cnn_model(input).numpy()\n",
    "    predictions += list(output.reshape(len(output)))\n",
    "    \n",
    "    l = label.numpy()\n",
    "    labels += list(l.reshape(len(l)))\n",
    "    \n",
    "predictions = list(map(lambda x: 0 if x < 0.5 else 1, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383afd7e-57ef-40b2-b14b-bf3ae77e0a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1.0 in labels:\n",
    "    # if os.path.exists(f'./results/confusion_matrix.xlsx'):\n",
    "    #     with pd.ExcelWriter(f'./results/confusion_matrix.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "    #         pd.DataFrame(\n",
    "    #             classification_report(predictions, labels,\n",
    "    #                                   target_names=['normal', 'wearing-off'],\n",
    "    #                                   output_dict=True)\n",
    "    #         ).to_excel(writer, sheet_name=f'{user} - {model_name}')\n",
    "    # else:\n",
    "    #     with pd.ExcelWriter(f'./results/confusion_matrix.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "    #         pd.DataFrame(\n",
    "    #             classification_report(predictions, labels,\n",
    "    #                                   target_names=['normal', 'wearing-off'],\n",
    "    #                                   output_dict=True)\n",
    "    #         ).to_excel(writer, sheet_name=f'{user} - {model_name}')\n",
    "\n",
    "    print(\n",
    "        classification_report(predictions, labels,\n",
    "                              target_names=['normal', 'wearing-off'],\n",
    "                              output_dict=False)\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        classification_report(predictions, labels,\n",
    "                              target_names=['normal', 'wearing-off'],\n",
    "                              output_dict=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422b61c-3268-4172-90e6-8a54e557ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1.0 in labels:\n",
    "    cm = confusion_matrix(predictions, labels, normalize='pred')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['normal', 'wearing-off'])\n",
    "    disp.plot()\n",
    "    plt.title(f'Confusion matrix for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "    # plt.savefig(f'./results/{user}_confusion_matrix_{model_name}.pdf')\n",
    "    plt.show()\n",
    "else:\n",
    "    cm = confusion_matrix(predictions, labels, normalize='pred')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['normal', 'wearing-off'])\n",
    "    disp.plot()\n",
    "    plt.title(f'Confusion matrix for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "    # plt.savefig(f'./results/{user}_confusion_matrix_{model_name}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a0bc79-c47a-4a00-a9a3-407c1212658e",
   "metadata": {},
   "source": [
    "## RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ce3ef-ec88-4dc7-8137-63586733598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM'\n",
    "K.clear_session()\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(16, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd1fd1-9eec-43fc-8eea-530d60821bf3",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af891a44-1509-4e82-a038-62e3fd8d7f48",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(lstm_model, wide_single_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3223f4-2bdb-41f5-8770-21a8230fd148",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance[model_name] = lstm_model.evaluate(wide_single_step_window.validation())\n",
    "test_performance[model_name] = lstm_model.evaluate(wide_single_step_window.test(), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51513a29-ea0a-40fe-bb9b-1fdcb66fcf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93610b19-1005-4d0c-bd58-034b56147622",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8717e0ed-93de-4733-92ea-3128dbb1a5e8",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aac10f-86db-4666-962e-44d16fbbf102",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_single_step_window.plot(lstm_model)\n",
    "plt.suptitle(f'Sample forecasting for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "# plt.savefig(f'./results/{user}_sample_prediction_{model_name}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52714eb9-a0c3-412e-b5ab-5ed6f4dde86c",
   "metadata": {},
   "source": [
    "### Visualize learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e055489-a51b-4ad4-b136-e04be90412ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.title(f'Learning Curve Loss for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "plt.legend()\n",
    "# plt.savefig(f'./results/{user}_learning_curve_{model_name}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0831d-2ffe-47ca-908b-fa2f99577426",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5894078d-bf83-4cb9-812b-54d6c9c1e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "for input, label in single_step_window.test():\n",
    "    output = lstm_model(input).numpy()\n",
    "    predictions += list(output.reshape(len(output)))\n",
    "    \n",
    "    l = label.numpy()\n",
    "    labels += list(l.reshape(len(l)))\n",
    "    \n",
    "predictions = list(map(lambda x: 0 if x < 0.5 else 1, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8484b8a-a26f-49fe-9ae8-c254943e67dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1.0 in labels:\n",
    "    # if os.path.exists(f'./results/confusion_matrix.xlsx'):\n",
    "    #     with pd.ExcelWriter(f'./results/confusion_matrix.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "    #         pd.DataFrame(\n",
    "    #             classification_report(predictions, labels,\n",
    "    #                                   target_names=['normal', 'wearing-off'],\n",
    "    #                                   output_dict=True)\n",
    "    #         ).to_excel(writer, sheet_name=f'{user} - {model_name}')\n",
    "    # else:\n",
    "    #     with pd.ExcelWriter(f'./results/confusion_matrix.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "    #         pd.DataFrame(\n",
    "    #             classification_report(predictions, labels,\n",
    "    #                                   target_names=['normal', 'wearing-off'],\n",
    "    #                                   output_dict=True)\n",
    "    #         ).to_excel(writer, sheet_name=f'{user} - {model_name}')\n",
    "\n",
    "    print(\n",
    "        classification_report(predictions, labels,\n",
    "                              target_names=['normal', 'wearing-off'],\n",
    "                              output_dict=False)\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        classification_report(predictions, labels,\n",
    "                              target_names=['normal', 'wearing-off'],\n",
    "                              output_dict=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303cba13-ce2b-416d-87b6-2e06aa86642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1.0 in labels:\n",
    "    cm = confusion_matrix(predictions, labels, normalize='pred')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['normal', 'wearing-off'])\n",
    "    disp.plot()\n",
    "    plt.title(f'Confusion matrix for Participant {user.replace(\"participant\", \"\")} using {model_name}')\n",
    "    # plt.savefig(f'./results/{user}_confusion_matrix_{model_name}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41598527-2529-4835-a097-7b5a9f7ea354",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4953b-d862-4ad5-87b4-ea2638fd60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(test_performance))\n",
    "width = 0.3\n",
    "metric_name = 'auc' # accuracy\n",
    "metric_index = lstm_model.metrics_names.index(metric_name)\n",
    "validation_accuracy = [v[metric_index] for v in validation_performance.values()]\n",
    "test_accuracy = [v[metric_index] for v in test_performance.values()]\n",
    "\n",
    "plt.ylabel('accuracy [wearing_off, normalized]')\n",
    "plt.bar(x - 0.17, validation_accuracy, width, label='Validation')\n",
    "plt.bar(x + 0.17, test_accuracy, width, label='Test')\n",
    "plt.xticks(ticks=x, labels=test_performance.keys(),\n",
    "           rotation=45)\n",
    "_ = plt.legend()\n",
    "plt.title(f'Test Performance for Participant {user.replace(\"participant\", \"\")} on varying models')\n",
    "# plt.savefig(f'./results/{user}_test_performance_{model_name}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158cad49-11fa-4132-b98b-544aa2755188",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "  pd.DataFrame(validation_performance,\n",
    "              index = ['loss'] + list(map(lambda m: m.name, METRICS))\n",
    "              )\n",
    ")\n",
    "\n",
    "display(\n",
    "  pd.DataFrame(test_performance,\n",
    "              index = ['loss'] + list(map(lambda m: m.name, METRICS))\n",
    "              )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306ea9fe-8f92-456d-b552-8946d9e64596",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_perf = pd.DataFrame(validation_performance).transpose().rename(columns={0: 'val_loss', 1: 'val_accuracy'})\n",
    "val_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a89bcf2-bb46-4e62-a547-dc759973272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perf = pd.DataFrame(test_performance).transpose().rename(columns={0: 'loss', 1: 'accuracy'})\n",
    "test_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2472ccc2-4ca2-402f-a9e9-afead9ec29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_performance = pd.concat([val_perf, test_perf], axis=1, join='inner')\n",
    "if os.path.exists(f'./results/final_performance.xlsx'):\n",
    "    with pd.ExcelWriter(f'./results/final_performance.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "        final_performance.to_excel(writer, sheet_name=f'{user}')\n",
    "else:\n",
    "    with pd.ExcelWriter(f'./results/final_performance.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "        final_performance.to_excel(writer, sheet_name=f'{user}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b89c4d",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd375057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edec1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_input, test_label in multi_step_window.test().take(100):\n",
    "    print(test_input.shape)\n",
    "    print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac86c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c850ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input.reshape([8*24, 14]).numpy().append( pd.DataFrame(test_input.reshape([8*24, 14]).numpy()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d31285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the first 100 training examples as our background dataset to integrate over\n",
    "explainer = shap.DeepExplainer(cnn_model, train_X[:100])\n",
    "\n",
    "# explain the first 10 predictions\n",
    "# explaining each prediction requires 2 * background dataset size runs\n",
    "shap_values = explainer.shap_values(test_X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the JS visualization code\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0].reshape(10,1440), reframed.loc[:, reframed.columns != target_column].columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
