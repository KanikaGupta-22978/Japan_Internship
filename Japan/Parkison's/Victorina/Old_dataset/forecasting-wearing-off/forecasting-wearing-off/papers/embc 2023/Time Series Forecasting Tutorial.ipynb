{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f741db-7d49-4d61-9f90-6a866a7772cb",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e81c93-92b5-42ae-ab07-f6d2be1993cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a2ecc8d",
   "metadata": {},
   "source": [
    "# Load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "604c32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garmin features\n",
    "features = ['heart_rate', 'steps', 'stress_score',\n",
    "           'awake', 'deep', 'light', 'rem', \n",
    "           'nonrem_total', 'total', 'nonrem_percentage', 'sleep_efficiency']\n",
    "\n",
    "# Additional features\n",
    "#   'timestamp_hour'\n",
    "features += ['timestamp_dayofweek', 'timestamp_hour_sin', 'timestamp_hour_cos']\n",
    "\n",
    "TARGET_COLUMN = 'wearing_off'\n",
    "features.append(TARGET_COLUMN)\n",
    "\n",
    "columns = ['timestamp'] + features + ['participant']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68766c22-e029-4504-97bb-d040a280cf7c",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8943b351-b7a4-4319-830b-f5123d3f3b34",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/4-combined_data.xlsx',\n",
    "                  index_col=\"timestamp\",\n",
    "                  usecols=columns,\n",
    "                  sheet_name=\"combined\",\n",
    "                  engine='openpyxl')\n",
    "\n",
    "# Fill missing data with 0\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78772675-72a8-4cb9-9ef7-4cd010800ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16608\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>steps</th>\n",
       "      <th>stress_score</th>\n",
       "      <th>awake</th>\n",
       "      <th>deep</th>\n",
       "      <th>light</th>\n",
       "      <th>rem</th>\n",
       "      <th>nonrem_total</th>\n",
       "      <th>total</th>\n",
       "      <th>nonrem_percentage</th>\n",
       "      <th>sleep_efficiency</th>\n",
       "      <th>timestamp_hour_sin</th>\n",
       "      <th>timestamp_hour_cos</th>\n",
       "      <th>timestamp_dayofweek</th>\n",
       "      <th>wearing_off</th>\n",
       "      <th>participant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-11-25 00:00:00</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-7.627160e-12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-25 00:15:00</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.540313e-02</td>\n",
       "      <td>0.997859</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-25 00:30:00</th>\n",
       "      <td>21.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.305262e-01</td>\n",
       "      <td>0.991445</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-25 00:45:00</th>\n",
       "      <td>60.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.950903e-01</td>\n",
       "      <td>0.980785</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-25 01:00:00</th>\n",
       "      <td>10.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     heart_rate  steps  stress_score  awake  deep  light  rem  \\\n",
       "timestamp                                                                       \n",
       "2021-11-25 00:00:00       -1.00    0.0          -1.0   -1.0  -1.0   -1.0 -1.0   \n",
       "2021-11-25 00:15:00       -1.00    0.0          -1.0   -1.0  -1.0   -1.0 -1.0   \n",
       "2021-11-25 00:30:00       21.95    0.0          -0.4   -1.0  -1.0   -1.0 -1.0   \n",
       "2021-11-25 00:45:00       60.25    0.0          12.4   -1.0  -1.0   -1.0 -1.0   \n",
       "2021-11-25 01:00:00       10.60    0.0          -1.0   -1.0  -1.0   -1.0 -1.0   \n",
       "\n",
       "                     nonrem_total  total  nonrem_percentage  sleep_efficiency  \\\n",
       "timestamp                                                                       \n",
       "2021-11-25 00:00:00          -1.0   -1.0               -1.0              -1.0   \n",
       "2021-11-25 00:15:00          -1.0   -1.0               -1.0              -1.0   \n",
       "2021-11-25 00:30:00          -1.0   -1.0               -1.0              -1.0   \n",
       "2021-11-25 00:45:00          -1.0   -1.0               -1.0              -1.0   \n",
       "2021-11-25 01:00:00          -1.0   -1.0               -1.0              -1.0   \n",
       "\n",
       "                     timestamp_hour_sin  timestamp_hour_cos  \\\n",
       "timestamp                                                     \n",
       "2021-11-25 00:00:00       -7.627160e-12            1.000000   \n",
       "2021-11-25 00:15:00        6.540313e-02            0.997859   \n",
       "2021-11-25 00:30:00        1.305262e-01            0.991445   \n",
       "2021-11-25 00:45:00        1.950903e-01            0.980785   \n",
       "2021-11-25 01:00:00        2.588190e-01            0.965926   \n",
       "\n",
       "                     timestamp_dayofweek  wearing_off  participant  \n",
       "timestamp                                                           \n",
       "2021-11-25 00:00:00                    3            0            1  \n",
       "2021-11-25 00:15:00                    3            0            1  \n",
       "2021-11-25 00:30:00                    3            0            1  \n",
       "2021-11-25 00:45:00                    3            0            1  \n",
       "2021-11-25 01:00:00                    3            0            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(df))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove days without wearing-off record (UNDERSAMPLING)\n",
    "# #   * not sure whether there is no actual wearing-off periods that day\n",
    "# #   * or if there were actual wearing-off periods but not recorded\n",
    "# df.pivot_table(values='wearing_off', index=[\"participant\"], aggfunc='count')\n",
    "\n",
    "# df_day = df.resample('D').sum()\n",
    "# days_without_wearing_off = list(df_day.query('wearing_off != 0').index)\n",
    "# days_without_wearing_off = [day.date().strftime('%Y-%m-%d') for day in days_without_wearing_off]\n",
    "\n",
    "# df['date'] = pd.to_datetime(df.index.date)\n",
    "# df = df[df['date'].dt.date.astype(str).isin(days_without_wearing_off)][features + ['participant']]\n",
    "# # df[df['date'].dt.date.astype(str).isin(days_without_wearing_off)].pivot_table(values='wearing_off', index=[\"participant\"], aggfunc='count')\n",
    "\n",
    "# print(len(df))\n",
    "# display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84433d10-3b70-40d0-a429-118314dcc978",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a0844a4-67da-4ae0-a3f3-a6ffafc92f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTICIPANT_AS_TEST = 9\n",
    "\n",
    "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "# Select all except specified participant (used for training)\n",
    "general_df = df.query(f'participant != {PARTICIPANT_AS_TEST}')[features].copy()\n",
    "train_df = general_df[0:int( len(general_df) * 0.6 )]\n",
    "val_df = general_df[int( len(general_df) * 0.6 ):]\n",
    "\n",
    "test_participant_df = df.query(f'participant == {PARTICIPANT_AS_TEST}')[features].copy()\n",
    "fine_tuning_df = test_participant_df[0:int( len(test_participant_df) * 0.5 )]\n",
    "test_df = test_participant_df[int( len(test_participant_df) * 0.5 ):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5137caf-014a-489e-a27b-873ae9441345",
   "metadata": {},
   "source": [
    "# Normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebb20785-e995-49f6-92ee-99d42218151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_features = ['heart_rate', 'steps', 'stress_score', 'awake', 'deep', \n",
    "                      'light', 'rem', 'nonrem_total', 'total', 'nonrem_percentage',\n",
    "                      'sleep_efficiency', 'timestamp_hour_sin', 'timestamp_hour_cos']\n",
    "def normalize_data(df, mean, std, normalize_features=normalize_features):\n",
    "    df_to_normalize = df.copy()\n",
    "    df_to_normalize.loc[:, normalize_features] = ((\n",
    "        df_to_normalize.loc[:, normalize_features] - mean\n",
    "    ) / std)\n",
    "    \n",
    "    return df_to_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d88e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_mean = general_df.loc[:, normalize_features].mean()\n",
    "general_std = general_df.loc[:, normalize_features].std()\n",
    "\n",
    "train_df = normalize_data(train_df, general_mean, general_std)\n",
    "val_df = normalize_data(val_df, general_mean, general_std)\n",
    "fine_tuning_df = normalize_data(fine_tuning_df, general_mean, general_std)\n",
    "test_df = normalize_data(test_df, general_mean, general_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef7275e-e352-4e8a-a773-89f85bfcfdd8",
   "metadata": {},
   "source": [
    "# WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a698325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHIFT = 4\n",
    "RECORD_SIZE_PER_DAY = 96\n",
    "\n",
    "\n",
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df, val_df, fine_tuning_df, test_df, \n",
    "               label_columns=None, batch_size=1):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.fine_tuning_df = fine_tuning_df\n",
    "    self.test_df = test_df\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(self.train_df.columns)}\n",
    "    \n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])\n",
    "\n",
    "  def split_window(self, features):\n",
    "    inputs = features[:, self.input_slice, :]\n",
    "    labels = features[:, self.labels_slice, :]\n",
    "    if self.label_columns is not None:\n",
    "      labels = tf.stack(\n",
    "          [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "          axis=-1)\n",
    "\n",
    "    # Slicing doesn't preserve static shape information, so set the shapes\n",
    "    # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "    inputs.set_shape([None, self.input_width, None])\n",
    "    labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "    return inputs, labels\n",
    "  \n",
    "  def plot(self, model=None, plot_col='wearing_off', max_subplots=3):\n",
    "    inputs, labels = self.example\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    plot_col_index = self.column_indices[plot_col]\n",
    "    max_n = min(max_subplots, len(inputs))\n",
    "    for n in range(max_n):\n",
    "      ax = plt.subplot(max_n, 1, n+1)\n",
    "      plt.ylabel(f'{plot_col} [normed]')\n",
    "      \n",
    "      # NEW\n",
    "      plt.ylim(-0.1,1.1) \n",
    "      ax.set_yticks(\n",
    "          [0.0, 0.5, 1.0]\n",
    "      )\n",
    "      ax.set_xticks([])\n",
    "      if n == 2:\n",
    "          ax.set_xticks(\n",
    "              np.append(self.input_indices[::SHIFT], self.input_indices[-1] + 1),\n",
    "              list(range(0, len( self.input_indices[::SHIFT] ) + 1 )),\n",
    "              minor=True\n",
    "          )\n",
    "      # NEW\n",
    "\n",
    "      plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "              label='Inputs', marker='.', zorder=-10)\n",
    "      if self.label_columns:\n",
    "        label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "      else:\n",
    "        label_col_index = plot_col_index\n",
    "      if label_col_index is None:\n",
    "        continue\n",
    "\n",
    "      # plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "      #             edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "      plt.scatter(self.label_indices[::SHIFT], labels[n, :, label_col_index][::SHIFT],\n",
    "                  edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "      if model is not None:\n",
    "        predictions = model(inputs)\n",
    "        plt.scatter(self.label_indices[::SHIFT], predictions[n, :, label_col_index][::SHIFT],\n",
    "                    marker='X', edgecolors='k', label='Predictions',\n",
    "                    c='#ff7f0e', s=64)\n",
    "        # plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "        #             marker='X', edgecolors='k', label='Predictions',\n",
    "        #             c='#ff7f0e', s=64)\n",
    "\n",
    "      if n == 2:\n",
    "          # Put a legend below current axis\n",
    "          plt.legend(loc='upper center', bbox_to_anchor=(0.5, 0.025),\n",
    "                      bbox_transform=fig.transFigure,\n",
    "                    fancybox=True, shadow=True, ncol=3)\n",
    "          # plt.legend()\n",
    "      # if n == 0:\n",
    "      #   plt.legend()\n",
    "\n",
    "\n",
    "    plt.xlabel('Time [h]')\n",
    "\n",
    "  def make_dataset(self, data):\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=False,\n",
    "      seed=4,\n",
    "      batch_size=BATCH_SIZE,).shuffle(buffer_size=10000)\n",
    "\n",
    "    ds = ds.map(self.split_window)\n",
    "\n",
    "    return ds\n",
    "  \n",
    "  @property\n",
    "  def train(self):\n",
    "    return self.make_dataset(self.train_df)\n",
    "\n",
    "  @property\n",
    "  def val(self):\n",
    "    return self.make_dataset(self.val_df)\n",
    "\n",
    "  @property\n",
    "  def fine_tuning(self):\n",
    "    return self.make_dataset(self.fine_tuning_df)\n",
    "\n",
    "  @property\n",
    "  def test(self):\n",
    "    return self.make_dataset(self.test_df)\n",
    "\n",
    "  @property\n",
    "  def example(self):\n",
    "    \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "    result = getattr(self, '_example', None)\n",
    "    if result is None:\n",
    "      # No example batch was found, so get one from the `.train` dataset\n",
    "      result = next(iter(self.train))\n",
    "      # And cache it for next time\n",
    "      self._example = result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af2303-6392-49d8-bf3b-168c03a8508f",
   "metadata": {},
   "source": [
    "## Single Step Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d73a7514-1092-4d29-8b77-e5bfa48fc566",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "single_step_window = WindowGenerator(\n",
    "    train_df=train_df, val_df=val_df,\n",
    "    fine_tuning_df=fine_tuning_df, test_df=test_df,\n",
    "    input_width=1, label_width=1, shift=SHIFT,\n",
    "    label_columns=[TARGET_COLUMN], batch_size=BATCH_SIZE)\n",
    "# print(single_step_window)\n",
    "# for example_inputs, example_labels in single_step_window.train.take(1):\n",
    "#   print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "#   print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
    "# single_step_window.plot(plot_col=TARGET_COLUMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d1c5c2-6ca1-49ca-84ab-d4cc2c539ffc",
   "metadata": {},
   "source": [
    "## Wide Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e7d2048-2ad6-4afb-a7db-3afb799e86a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wide_window = WindowGenerator(\n",
    "    train_df=train_df, val_df=val_df,\n",
    "    fine_tuning_df=fine_tuning_df, test_df=test_df,\n",
    "    input_width=24, label_width=24, shift=SHIFT,\n",
    "    label_columns=[TARGET_COLUMN], batch_size=BATCH_SIZE)\n",
    "# print(wide_window)\n",
    "# for example_inputs, example_labels in wide_window.train.take(1):\n",
    "#   print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "#   print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
    "# wide_window.plot(plot_col=TARGET_COLUMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05650c8-6900-4d1c-8d1b-888f3fe79704",
   "metadata": {},
   "source": [
    "## Convolutional Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c3689aa-cb55-4dae-ba8e-89d4785f4571",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONV_WIDTH = RECORD_SIZE_PER_DAY # 24 hours or 96 records\n",
    "conv_window = WindowGenerator(\n",
    "    train_df=train_df, val_df=val_df,\n",
    "    fine_tuning_df=fine_tuning_df, test_df=test_df,\n",
    "    input_width=CONV_WIDTH, label_width=1, shift=SHIFT,\n",
    "    label_columns=[TARGET_COLUMN], batch_size=BATCH_SIZE)\n",
    "# print(conv_window)\n",
    "# for example_inputs, example_labels in conv_window.train.take(1):\n",
    "#   print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "#   print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
    "# conv_window.plot(plot_col=TARGET_COLUMN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6de4978f",
   "metadata": {},
   "source": [
    "## Wide Convolutional Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc3879b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_WIDTH = CONV_WIDTH # 4 * 6 # 4 records * 6 hours\n",
    "INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - 1)\n",
    "wide_conv_window = WindowGenerator(\n",
    "    train_df=train_df, val_df=val_df,\n",
    "    fine_tuning_df=fine_tuning_df, test_df=test_df,\n",
    "    input_width=INPUT_WIDTH, label_width=LABEL_WIDTH, shift=SHIFT,\n",
    "    label_columns=[TARGET_COLUMN], batch_size=BATCH_SIZE)\n",
    "# print(wide_conv_window)\n",
    "# for example_inputs, example_labels in wide_conv_window.train.take(1):\n",
    "#   print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "#   print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
    "# wide_conv_window.plot(plot_col=TARGET_COLUMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a8c169-e711-46e7-9ac2-715c559ccf9d",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48764c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "THRESHOLDS = [\n",
    "    (i + 1) * 1.0 / (200 - 1)\n",
    "    for i in range(200 - 2)\n",
    "]\n",
    "METRICS = [\n",
    "  tf.keras.metrics.TruePositives(name='tp', thresholds=THRESHOLDS),\n",
    "  tf.keras.metrics.FalsePositives(name='fp', thresholds=THRESHOLDS),\n",
    "  tf.keras.metrics.TrueNegatives(name='tn', thresholds=THRESHOLDS),\n",
    "  tf.keras.metrics.FalseNegatives(name='fn', thresholds=THRESHOLDS), \n",
    "  tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "  tf.keras.metrics.Precision(name='precision', thresholds=THRESHOLDS),\n",
    "  tf.keras.metrics.Recall(name='recall', thresholds=THRESHOLDS),\n",
    "  tf.keras.metrics.AUC(name='auc', thresholds=THRESHOLDS),\n",
    "  tf.keras.metrics.AUC(name='prc', curve='PR', thresholds=THRESHOLDS, summation_method='majoring')] # precision-recall curve]\n",
    "\n",
    "\n",
    "def brier_score_loss(y_true, y_pred):\n",
    "  return K.mean(K.square(y_true - y_pred))\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "  # model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "  #               optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "  #               metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                metrics=METRICS)\n",
    "  # model.compile(loss=brier_score_loss,\n",
    "  #               optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "  #               metrics=METRICS)\n",
    "\n",
    "  # history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "  #                     validation_data=window.val,\n",
    "  #                     callbacks=[early_stopping])\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "  \n",
    "  return history\n",
    "\n",
    "def fine_tune(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                metrics=METRICS)\n",
    "  \n",
    "  # model.compile(loss=brier_score_loss,\n",
    "  #               optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "  #               metrics=METRICS)\n",
    "\n",
    "  history = model.fit(window.fine_tuning, epochs=MAX_EPOCHS,\n",
    "                    validation_data=window.val,\n",
    "                    callbacks=[early_stopping])\n",
    "  \n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0aa38e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance = {}\n",
    "before_fine_tuning_performance = {}\n",
    "performance = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21d8ccab",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe813844",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "  def __init__(self, label_index=None):\n",
    "    super().__init__()\n",
    "    self.label_index = label_index\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if self.label_index is None:\n",
    "      return inputs\n",
    "    result = inputs[:, :, self.label_index]\n",
    "    return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4399de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 04:06:05.533113: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "292/292 [==============================] - 4s 6ms/step - loss: 2.1344 - tp: 199.0000 - fp: 649.0000 - tn: 7830.0000 - fn: 649.0000 - accuracy: 0.8608 - precision: 0.2347 - recall: 0.2347 - auc: 0.5791 - prc: 0.1427 - val_loss: 1.8946 - val_tp: 24.0000 - val_fp: 384.0000 - val_tn: 5425.0000 - val_fn: 384.0000 - val_accuracy: 0.8765 - val_precision: 0.0588 - val_recall: 0.0588 - val_auc: 0.4964 - val_prc: 0.0644\n",
      "Epoch 2/20\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 2.1344 - tp: 199.0000 - fp: 649.0000 - tn: 7830.0000 - fn: 649.0000 - accuracy: 0.8608 - precision: 0.2347 - recall: 0.2347 - auc: 0.5791 - prc: 0.1427 - val_loss: 1.8946 - val_tp: 24.0000 - val_fp: 384.0000 - val_tn: 5425.0000 - val_fn: 384.0000 - val_accuracy: 0.8765 - val_precision: 0.0588 - val_recall: 0.0588 - val_auc: 0.4964 - val_prc: 0.0644\n",
      "Epoch 3/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 2.1344 - tp: 199.0000 - fp: 649.0000 - tn: 7830.0000 - fn: 649.0000 - accuracy: 0.8608 - precision: 0.2347 - recall: 0.2347 - auc: 0.5791 - prc: 0.1427 - val_loss: 1.8946 - val_tp: 24.0000 - val_fp: 384.0000 - val_tn: 5425.0000 - val_fn: 384.0000 - val_accuracy: 0.8765 - val_precision: 0.0588 - val_recall: 0.0588 - val_auc: 0.4964 - val_prc: 0.0644\n",
      "Epoch 4/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 2.1344 - tp: 199.0000 - fp: 649.0000 - tn: 7830.0000 - fn: 649.0000 - accuracy: 0.8608 - precision: 0.2347 - recall: 0.2347 - auc: 0.5791 - prc: 0.1427 - val_loss: 1.8946 - val_tp: 24.0000 - val_fp: 384.0000 - val_tn: 5425.0000 - val_fn: 384.0000 - val_accuracy: 0.8765 - val_precision: 0.0588 - val_recall: 0.0588 - val_auc: 0.4964 - val_prc: 0.0644\n",
      "Epoch 5/20\n",
      "292/292 [==============================] - 1s 4ms/step - loss: 2.1344 - tp: 199.0000 - fp: 649.0000 - tn: 7830.0000 - fn: 649.0000 - accuracy: 0.8608 - precision: 0.2347 - recall: 0.2347 - auc: 0.5791 - prc: 0.1427 - val_loss: 1.8946 - val_tp: 24.0000 - val_fp: 384.0000 - val_tn: 5425.0000 - val_fn: 384.0000 - val_accuracy: 0.8765 - val_precision: 0.0588 - val_recall: 0.0588 - val_auc: 0.4964 - val_prc: 0.0644\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "baseline = Baseline(label_index=column_indices[TARGET_COLUMN])\n",
    "history = compile_and_fit(baseline, single_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba565ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 1s 2ms/step - loss: 1.8946 - tp: 24.0000 - fp: 384.0000 - tn: 5425.0000 - fn: 384.0000 - accuracy: 0.8765 - precision: 0.0588 - recall: 0.0588 - auc: 0.4964 - prc: 0.0644\n",
      "loss :  1.0827949047088623\n",
      "tp :  [5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5.]\n",
      "fp :  [19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.]\n",
      "tn :  [482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482.]\n",
      "fn :  [18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.]\n",
      "accuracy :  0.9293892979621887\n",
      "precision :  [0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333]\n",
      "recall :  [0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913]\n",
      "auc :  0.5897335410118103\n",
      "prc :  0.09342513978481293\n"
     ]
    }
   ],
   "source": [
    "val_performance['Baseline'] = baseline.evaluate(single_step_window.val)\n",
    "before_fine_tuning_performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)\n",
    "for name, value in zip(baseline.metrics_names, before_fine_tuning_performance['Baseline']):\n",
    "  print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49422549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 3s 81ms/step - loss: 1.4049 - tp: 31.0000 - fp: 43.0000 - tn: 932.0000 - fn: 42.0000 - accuracy: 0.9189 - precision: 0.4189 - recall: 0.4247 - auc: 0.6903 - prc: 0.2462 - val_loss: 1.8946 - val_tp: 24.0000 - val_fp: 384.0000 - val_tn: 5425.0000 - val_fn: 384.0000 - val_accuracy: 0.8765 - val_precision: 0.0588 - val_recall: 0.0588 - val_auc: 0.4964 - val_prc: 0.0644\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 1.4049 - tp: 26.0000 - fp: 24.0000 - tn: 450.0000 - fn: 24.0000 - accuracy: 0.9084 - precision: 0.5200 - recall: 0.5200 - auc: 0.7347 - prc: 0.3505 - val_loss: 1.8946 - val_tp: 24.0000 - val_fp: 384.0000 - val_tn: 5425.0000 - val_fn: 384.0000 - val_accuracy: 0.8765 - val_precision: 0.0588 - val_recall: 0.0588 - val_auc: 0.4964 - val_prc: 0.0644\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 1s 38ms/step - loss: 1.4049 - tp: 26.0000 - fp: 24.0000 - tn: 450.0000 - fn: 24.0000 - accuracy: 0.9084 - precision: 0.5200 - recall: 0.5200 - auc: 0.7347 - prc: 0.3505 - val_loss: 1.8946 - val_tp: 24.0000 - val_fp: 384.0000 - val_tn: 5425.0000 - val_fn: 384.0000 - val_accuracy: 0.8765 - val_precision: 0.0588 - val_recall: 0.0588 - val_auc: 0.4964 - val_prc: 0.0644\n"
     ]
    }
   ],
   "source": [
    "history = fine_tune(baseline, single_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "297bd932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  1.0827951431274414\n",
      "tp :  [5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5.]\n",
      "fp :  [19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19. 19.]\n",
      "tn :  [482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482. 482.\n",
      " 482. 482.]\n",
      "fn :  [18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.\n",
      " 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18. 18.]\n",
      "accuracy :  0.9293892979621887\n",
      "precision :  [0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333\n",
      " 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333]\n",
      "recall :  [0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913 0.2173913\n",
      " 0.2173913 0.2173913]\n",
      "auc :  0.5897335410118103\n",
      "prc :  0.09342513978481293\n"
     ]
    }
   ],
   "source": [
    "performance['Baseline'] = baseline.evaluate(single_step_window.test, verbose=0)\n",
    "for name, value in zip(baseline.metrics_names, performance['Baseline']):\n",
    "  print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b834b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wide_window.plot(model=baseline, plot_col=\"wearing_off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96428e9c",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a456937d-f35e-4457-a5f0-9dcb3b34609f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "292/292 [==============================] - 4s 6ms/step - loss: 1.4518 - tp: 573.5455 - fp: 5899.9194 - tn: 2579.0808 - fn: 274.4546 - accuracy: 0.2485 - precision: 0.0852 - recall: 0.6764 - auc: 0.4664 - prc: 0.0824 - val_loss: 0.8668 - val_tp: 199.1818 - val_fp: 3144.3940 - val_tn: 2664.6060 - val_fn: 208.8182 - val_accuracy: 0.4147 - val_precision: 0.0513 - val_recall: 0.4882 - val_auc: 0.4165 - val_prc: 0.0555\n",
      "Epoch 2/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.8773 - tp: 433.2020 - fp: 4538.5049 - tn: 3940.4949 - fn: 414.7980 - accuracy: 0.4468 - precision: 0.0831 - recall: 0.5109 - auc: 0.4599 - prc: 0.0815 - val_loss: 0.5745 - val_tp: 149.7172 - val_fp: 2318.6616 - val_tn: 3490.3384 - val_fn: 258.2828 - val_accuracy: 0.7423 - val_precision: 0.0513 - val_recall: 0.3670 - val_auc: 0.4211 - val_prc: 0.0561\n",
      "Epoch 3/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.5691 - tp: 309.9748 - fp: 3212.8586 - tn: 5266.1416 - fn: 538.0253 - accuracy: 0.7499 - precision: 0.0915 - recall: 0.3655 - auc: 0.4683 - prc: 0.0840 - val_loss: 0.4346 - val_tp: 115.8131 - val_fp: 1739.9495 - val_tn: 4069.0505 - val_fn: 292.1869 - val_accuracy: 0.9133 - val_precision: 0.0514 - val_recall: 0.2839 - val_auc: 0.4499 - val_prc: 0.0596\n",
      "Epoch 4/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.4392 - tp: 226.8131 - fp: 2320.9495 - tn: 6158.0503 - fn: 621.1869 - accuracy: 0.8849 - precision: 0.0950 - recall: 0.2675 - auc: 0.4758 - prc: 0.0873 - val_loss: 0.3657 - val_tp: 95.0152 - val_fp: 1382.9242 - val_tn: 4426.0757 - val_fn: 312.9849 - val_accuracy: 0.9241 - val_precision: 0.0511 - val_recall: 0.2329 - val_auc: 0.4856 - val_prc: 0.0632\n",
      "Epoch 5/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.3824 - tp: 182.5253 - fp: 1817.5959 - tn: 6661.4038 - fn: 665.4747 - accuracy: 0.8984 - precision: 0.0924 - recall: 0.2152 - auc: 0.4980 - prc: 0.0924 - val_loss: 0.3285 - val_tp: 81.8283 - val_fp: 1159.0858 - val_tn: 4649.9141 - val_fn: 326.1717 - val_accuracy: 0.9278 - val_precision: 0.0510 - val_recall: 0.2006 - val_auc: 0.5121 - val_prc: 0.0664\n",
      "Epoch 6/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.3545 - tp: 154.3535 - fp: 1509.4899 - tn: 6969.5103 - fn: 693.6465 - accuracy: 0.9028 - precision: 0.0823 - recall: 0.1820 - auc: 0.5100 - prc: 0.0957 - val_loss: 0.3076 - val_tp: 73.5606 - val_fp: 1020.4849 - val_tn: 4788.5151 - val_fn: 334.4394 - val_accuracy: 0.9305 - val_precision: 0.0501 - val_recall: 0.1803 - val_auc: 0.5283 - val_prc: 0.0687\n",
      "Epoch 7/20\n",
      "292/292 [==============================] - 2s 5ms/step - loss: 0.3391 - tp: 139.9394 - fp: 1322.6666 - tn: 7156.3335 - fn: 708.0606 - accuracy: 0.9047 - precision: 0.0770 - recall: 0.1650 - auc: 0.5278 - prc: 0.1012 - val_loss: 0.2945 - val_tp: 67.9394 - val_fp: 926.6263 - val_tn: 4882.3735 - val_fn: 340.0606 - val_accuracy: 0.9323 - val_precision: 0.0477 - val_recall: 0.1665 - val_auc: 0.5394 - val_prc: 0.0708\n",
      "Epoch 8/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.3297 - tp: 130.0556 - fp: 1198.2980 - tn: 7280.7021 - fn: 717.9445 - accuracy: 0.9062 - precision: 0.0643 - recall: 0.1534 - auc: 0.5418 - prc: 0.1048 - val_loss: 0.2859 - val_tp: 64.2071 - val_fp: 863.1465 - val_tn: 4945.8535 - val_fn: 343.7929 - val_accuracy: 0.9329 - val_precision: 0.0436 - val_recall: 0.1574 - val_auc: 0.5476 - val_prc: 0.0723\n",
      "Epoch 9/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.3229 - tp: 125.9697 - fp: 1127.3131 - tn: 7351.6870 - fn: 722.0303 - accuracy: 0.9072 - precision: 0.0621 - recall: 0.1485 - auc: 0.5571 - prc: 0.1095 - val_loss: 0.2798 - val_tp: 61.4192 - val_fp: 816.5808 - val_tn: 4992.4194 - val_fn: 346.5808 - val_accuracy: 0.9331 - val_precision: 0.0394 - val_recall: 0.1505 - val_auc: 0.5536 - val_prc: 0.0733\n",
      "Epoch 10/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.3182 - tp: 121.0808 - fp: 1059.9799 - tn: 7419.0200 - fn: 726.9192 - accuracy: 0.9078 - precision: 0.0518 - recall: 0.1428 - auc: 0.5675 - prc: 0.1125 - val_loss: 0.2756 - val_tp: 59.7273 - val_fp: 785.0707 - val_tn: 5023.9292 - val_fn: 348.2727 - val_accuracy: 0.9334 - val_precision: 0.0361 - val_recall: 0.1464 - val_auc: 0.5593 - val_prc: 0.0744\n",
      "Epoch 11/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.3141 - tp: 120.4141 - fp: 1029.4950 - tn: 7449.5049 - fn: 727.5859 - accuracy: 0.9085 - precision: 0.0540 - recall: 0.1420 - auc: 0.5795 - prc: 0.1174 - val_loss: 0.2719 - val_tp: 58.0808 - val_fp: 757.4141 - val_tn: 5051.5859 - val_fn: 349.9192 - val_accuracy: 0.9341 - val_precision: 0.0322 - val_recall: 0.1424 - val_auc: 0.5636 - val_prc: 0.0750\n",
      "Epoch 12/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.3107 - tp: 114.9697 - fp: 968.8232 - tn: 7510.1768 - fn: 733.0303 - accuracy: 0.9088 - precision: 0.0456 - recall: 0.1356 - auc: 0.5876 - prc: 0.1189 - val_loss: 0.2696 - val_tp: 57.1919 - val_fp: 741.7677 - val_tn: 5067.2324 - val_fn: 350.8081 - val_accuracy: 0.9342 - val_precision: 0.0298 - val_recall: 0.1402 - val_auc: 0.5666 - val_prc: 0.0756\n",
      "Epoch 13/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.3078 - tp: 119.9596 - fp: 981.1313 - tn: 7497.8687 - fn: 728.0404 - accuracy: 0.9089 - precision: 0.0476 - recall: 0.1415 - auc: 0.6049 - prc: 0.1254 - val_loss: 0.2679 - val_tp: 56.4545 - val_fp: 729.0505 - val_tn: 5079.9497 - val_fn: 351.5454 - val_accuracy: 0.9344 - val_precision: 0.0275 - val_recall: 0.1384 - val_auc: 0.5693 - val_prc: 0.0761\n",
      "Epoch 14/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.3053 - tp: 119.9192 - fp: 969.9747 - tn: 7509.0254 - fn: 728.0808 - accuracy: 0.9090 - precision: 0.0473 - recall: 0.1414 - auc: 0.6148 - prc: 0.1282 - val_loss: 0.2651 - val_tp: 55.1313 - val_fp: 707.0606 - val_tn: 5101.9395 - val_fn: 352.8687 - val_accuracy: 0.9344 - val_precision: 0.0257 - val_recall: 0.1351 - val_auc: 0.5737 - val_prc: 0.0768\n",
      "Epoch 15/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.3030 - tp: 115.7374 - fp: 923.5606 - tn: 7555.4395 - fn: 732.2626 - accuracy: 0.9090 - precision: 0.0473 - recall: 0.1365 - auc: 0.6206 - prc: 0.1301 - val_loss: 0.2637 - val_tp: 54.4242 - val_fp: 696.9445 - val_tn: 5112.0557 - val_fn: 353.5757 - val_accuracy: 0.9344 - val_precision: 0.0242 - val_recall: 0.1334 - val_auc: 0.5757 - val_prc: 0.0766\n",
      "Epoch 16/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.3011 - tp: 117.9646 - fp: 928.3990 - tn: 7550.6011 - fn: 730.0353 - accuracy: 0.9091 - precision: 0.0488 - recall: 0.1391 - auc: 0.6300 - prc: 0.1337 - val_loss: 0.2630 - val_tp: 54.1010 - val_fp: 691.0909 - val_tn: 5117.9092 - val_fn: 353.8990 - val_accuracy: 0.9344 - val_precision: 0.0235 - val_recall: 0.1326 - val_auc: 0.5785 - val_prc: 0.0772\n",
      "Epoch 17/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.2992 - tp: 118.7626 - fp: 919.5101 - tn: 7559.4897 - fn: 729.2374 - accuracy: 0.9091 - precision: 0.0507 - recall: 0.1401 - auc: 0.6403 - prc: 0.1381 - val_loss: 0.2616 - val_tp: 53.1465 - val_fp: 679.7929 - val_tn: 5129.2070 - val_fn: 354.8535 - val_accuracy: 0.9344 - val_precision: 0.0224 - val_recall: 0.1303 - val_auc: 0.5791 - val_prc: 0.0770\n",
      "Epoch 18/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.2975 - tp: 116.2273 - fp: 894.0101 - tn: 7584.9897 - fn: 731.7727 - accuracy: 0.9091 - precision: 0.0500 - recall: 0.1371 - auc: 0.6455 - prc: 0.1395 - val_loss: 0.2607 - val_tp: 52.5556 - val_fp: 671.1010 - val_tn: 5137.8989 - val_fn: 355.4445 - val_accuracy: 0.9344 - val_precision: 0.0218 - val_recall: 0.1288 - val_auc: 0.5812 - val_prc: 0.0772\n",
      "Epoch 19/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.2961 - tp: 116.5657 - fp: 888.2323 - tn: 7590.7676 - fn: 731.4343 - accuracy: 0.9091 - precision: 0.0499 - recall: 0.1375 - auc: 0.6534 - prc: 0.1418 - val_loss: 0.2596 - val_tp: 51.6667 - val_fp: 660.8182 - val_tn: 5148.1816 - val_fn: 356.3333 - val_accuracy: 0.9344 - val_precision: 0.0209 - val_recall: 0.1266 - val_auc: 0.5816 - val_prc: 0.0770\n",
      "Epoch 20/20\n",
      "292/292 [==============================] - 2s 4ms/step - loss: 0.2948 - tp: 116.3687 - fp: 875.5606 - tn: 7603.4395 - fn: 731.6313 - accuracy: 0.9091 - precision: 0.0533 - recall: 0.1372 - auc: 0.6586 - prc: 0.1444 - val_loss: 0.2593 - val_tp: 51.5051 - val_fp: 659.4192 - val_tn: 5149.5806 - val_fn: 356.4950 - val_accuracy: 0.9344 - val_precision: 0.0203 - val_recall: 0.1262 - val_auc: 0.5824 - val_prc: 0.0770\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
    "])\n",
    "history = compile_and_fit(linear, single_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6224d508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 1s 2ms/step - loss: 0.2593 - tp: 51.5051 - fp: 659.4192 - tn: 5149.5806 - fn: 356.4950 - accuracy: 0.9344 - precision: 0.0203 - recall: 0.1262 - auc: 0.5824 - prc: 0.0770      \n",
      "loss :  0.18336737155914307\n",
      "tp :  [23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23.\n",
      " 22. 22. 22. 22. 22. 22. 22. 21. 21. 21. 21. 18. 17. 17. 16. 15. 14. 12.\n",
      " 12. 11. 11. 11. 10.  8.  8.  7.  7.  7.  7.  6.  6.  5.  5.  5.  5.  5.\n",
      "  4.  4.  4.  4.  4.  4.  4.  3.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "fp :  [501. 501. 501. 501. 500. 500. 490. 477. 468. 430. 404. 385. 369. 351.\n",
      " 330. 310. 279. 264. 249. 229. 218. 204. 190. 174. 160. 146. 134. 116.\n",
      " 108. 101.  95.  91.  79.  72.  65.  62.  56.  49.  45.  41.  41.  35.\n",
      "  33.  27.  24.  20.  18.  17.  17.  14.  13.  12.   7.   6.   5.   2.\n",
      "   2.   2.   1.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "tn :  [  0.   0.   0.   0.   1.   1.  11.  24.  33.  71.  97. 116. 132. 150.\n",
      " 171. 191. 222. 237. 252. 272. 283. 297. 311. 327. 341. 355. 367. 385.\n",
      " 393. 400. 406. 410. 422. 429. 436. 439. 445. 452. 456. 460. 460. 466.\n",
      " 468. 474. 477. 481. 483. 484. 484. 487. 488. 489. 494. 495. 496. 499.\n",
      " 499. 499. 500. 500. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501.\n",
      " 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501.\n",
      " 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501.\n",
      " 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501.\n",
      " 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501.\n",
      " 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501.\n",
      " 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501.\n",
      " 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501.\n",
      " 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501.\n",
      " 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501. 501.\n",
      " 501. 501.]\n",
      "fn :  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  5.  6.  6.  7.  8.  9. 11.\n",
      " 11. 12. 12. 12. 13. 15. 15. 16. 16. 16. 16. 17. 17. 18. 18. 18. 18. 18.\n",
      " 19. 19. 19. 19. 19. 19. 19. 20. 21. 23. 23. 23. 23. 23. 23. 23. 23. 23.\n",
      " 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23.\n",
      " 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23.\n",
      " 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23.\n",
      " 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23.\n",
      " 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23.\n",
      " 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23.\n",
      " 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23. 23.]\n",
      "accuracy :  0.9561068415641785\n",
      "precision :  [0.04389313 0.04389313 0.04389313 0.04389313 0.04397706 0.04397706\n",
      " 0.04483431 0.046      0.04684318 0.05077263 0.05386417 0.05637255\n",
      " 0.05867347 0.06149733 0.0651558  0.06906907 0.07615894 0.08013938\n",
      " 0.08118081 0.08764941 0.09166667 0.09734514 0.10377359 0.1122449\n",
      " 0.12087912 0.1257485  0.13548388 0.15328467 0.1627907  0.15126051\n",
      " 0.15178572 0.1574074  0.16842106 0.1724138  0.17721519 0.16216215\n",
      " 0.1764706  0.18333334 0.19642857 0.21153846 0.19607843 0.18604651\n",
      " 0.19512194 0.20588236 0.22580644 0.25925925 0.28       0.26086956\n",
      " 0.26086956 0.2631579  0.2777778  0.29411766 0.41666666 0.45454547\n",
      " 0.44444445 0.6666667  0.6666667  0.6666667  0.8        0.8\n",
      " 1.         1.         1.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "recall :  [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.95652175 0.95652175 0.95652175 0.95652175 0.95652175 0.95652175\n",
      " 0.95652175 0.9130435  0.9130435  0.9130435  0.9130435  0.7826087\n",
      " 0.73913044 0.73913044 0.6956522  0.65217394 0.6086956  0.5217391\n",
      " 0.5217391  0.47826087 0.47826087 0.47826087 0.4347826  0.3478261\n",
      " 0.3478261  0.3043478  0.3043478  0.3043478  0.3043478  0.26086956\n",
      " 0.26086956 0.2173913  0.2173913  0.2173913  0.2173913  0.2173913\n",
      " 0.17391305 0.17391305 0.17391305 0.17391305 0.17391305 0.17391305\n",
      " 0.17391305 0.13043478 0.08695652 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "auc :  0.8772020936012268\n",
      "prc :  0.33522528409957886\n"
     ]
    }
   ],
   "source": [
    "val_performance['Linear'] = linear.evaluate(single_step_window.val)\n",
    "before_fine_tuning_performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0)\n",
    "for name, value in zip(linear.metrics_names, before_fine_tuning_performance['Linear']):\n",
    "  print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6983b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fine_tune(linear, single_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66db05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0)\n",
    "for name, value in zip(linear.metrics_names, performance['Linear']):\n",
    "  print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627320b-e6cf-43ff-aeaf-13d9746253af",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_window.plot(model=linear, plot_col=\"wearing_off\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1df90bbb",
   "metadata": {},
   "source": [
    "## Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e09211",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
    "\n",
    "])\n",
    "history = compile_and_fit(dense, single_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8fc705",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance['Dense'] = dense.evaluate(single_step_window.val)\n",
    "before_fine_tuning_performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)\n",
    "for name, value in zip(dense.metrics_names, before_fine_tuning_performance['Dense']):\n",
    "  print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10d65ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fine_tune(dense, single_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd402c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance['Dense'] = dense.evaluate(single_step_window.test, verbose=0)\n",
    "for name, value in zip(dense.metrics_names, performance['Dense']):\n",
    "  print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00951be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_window.plot(model=dense, plot_col=\"wearing_off\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea12ac49",
   "metadata": {},
   "source": [
    "## Multi-step Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f35aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "multi_step_dense = tf.keras.Sequential([\n",
    "    # Shape: (time, features) => (time*features)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid'),\n",
    "    # Add back the time dimension.\n",
    "    # Shape: (outputs) => (1, outputs)\n",
    "    tf.keras.layers.Reshape([1, -1]),\n",
    "])\n",
    "history = compile_and_fit(multi_step_dense, conv_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3900685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance['Multi step Dense'] = multi_step_dense.evaluate(conv_window.val)\n",
    "before_fine_tuning_performance['Multi step Dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)\n",
    "for name, value in zip(multi_step_dense.metrics_names, before_fine_tuning_performance['Multi step Dense']):\n",
    "  print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d856f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fine_tune(multi_step_dense, conv_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance['Multi step Dense'] = multi_step_dense.evaluate(conv_window.test, verbose=0)\n",
    "for name, value in zip(multi_step_dense.metrics_names, performance['Multi step Dense']):\n",
    "  print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_window.plot(model=multi_step_dense, plot_col=\"wearing_off\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86c6061e",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a098167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "conv_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32,\n",
    "                           kernel_size=(CONV_WIDTH,),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "history = compile_and_fit(conv_model, conv_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dec297",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance['CNN'] = conv_model.evaluate(conv_window.val)\n",
    "before_fine_tuning_performance['CNN'] = conv_model.evaluate(conv_window.test, verbose=0)\n",
    "for name, value in zip(conv_model.metrics_names, before_fine_tuning_performance['CNN']):\n",
    "  print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659642ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fine_tune(conv_model, conv_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance['CNN'] = conv_model.evaluate(conv_window.test, verbose=0)\n",
    "for name, value in zip(conv_model.metrics_names, performance['CNN']):\n",
    "  print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_conv_window.plot(model=conv_model, plot_col='wearing_off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbf02972",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460bacfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "history = compile_and_fit(lstm_model, wide_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a2a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance['LSTM'] = lstm_model.evaluate(wide_window.val)\n",
    "before_fine_tuning_performance['LSTM'] = lstm_model.evaluate(wide_window.test, verbose=0)\n",
    "for name, value in zip(lstm_model.metrics_names, before_fine_tuning_performance['LSTM']):\n",
    "  print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10309ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fine_tune(lstm_model, wide_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance['LSTM'] = lstm_model.evaluate(wide_window.test, verbose=0)\n",
    "for name, value in zip(lstm_model.metrics_names, performance['LSTM']):\n",
    "  print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2426d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_window.plot(model=lstm_model, plot_col='wearing_off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5ebf553",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(performance))\n",
    "width = 0.3\n",
    "metric_name = 'prc'\n",
    "metric_index = lstm_model.metrics_names.index(metric_name)\n",
    "# val_mae = [v[metric_index] for v in val_performance.values()]\n",
    "before_fine_tuning_mae = [v[metric_index] for v in before_fine_tuning_performance.values()]\n",
    "test_mae = [v[metric_index] for v in performance.values()]\n",
    "\n",
    "plt.ylabel(f'{metric_name} [wearing_off, normalized]')\n",
    "# plt.bar(x - 0.17, before_fine_tuning_mae, width, label='Validation')\n",
    "plt.bar(x - 0.17, before_fine_tuning_mae, width, label='Before Fine-Tuning Test')\n",
    "plt.bar(x + 0.17, test_mae, width, label='After Fine-Tuning Test')\n",
    "plt.xticks(ticks=x, labels=performance.keys(),\n",
    "           rotation=45)\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff22e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(f'./results/final_performance.xlsx'):\n",
    "#     with pd.ExcelWriter(f'./results/final_performance.xlsx', engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "#         pd.DataFrame(\n",
    "#             val_performance, index=lstm_model.metrics_names\n",
    "#         ).assign(\n",
    "#             participant=PARTICIPANT_AS_TEST\n",
    "#         ).to_excel(writer, sheet_name=\"validation\", startrow=writer.sheets['validation'].max_row, header=None)\n",
    "\n",
    "#         pd.DataFrame(\n",
    "#             before_fine_tuning_performance, index=lstm_model.metrics_names\n",
    "#         ).assign(\n",
    "#             participant=PARTICIPANT_AS_TEST\n",
    "#         ).to_excel(writer, sheet_name=\"before fine-tuning\", startrow=writer.sheets['before fine-tuning'].max_row, header=None)\n",
    "\n",
    "#         pd.DataFrame(\n",
    "#             performance, index=lstm_model.metrics_names\n",
    "#         ).assign(\n",
    "#             participant=PARTICIPANT_AS_TEST\n",
    "#         ).to_excel(writer, sheet_name=\"after fine-tuning\", startrow=writer.sheets['after fine-tuning'].max_row, header=None)\n",
    "# else:\n",
    "#     with pd.ExcelWriter(f'./results/final_performance.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "#         pd.DataFrame(\n",
    "#             val_performance, index=lstm_model.metrics_names\n",
    "#         ).assign(\n",
    "#             participant=PARTICIPANT_AS_TEST\n",
    "#         ).to_excel(writer, sheet_name=\"validation\")\n",
    "\n",
    "#         pd.DataFrame(\n",
    "#             before_fine_tuning_performance, index=lstm_model.metrics_names\n",
    "#         ).assign(\n",
    "#             participant=PARTICIPANT_AS_TEST\n",
    "#         ).to_excel(writer, sheet_name=\"before fine-tuning\")\n",
    "\n",
    "#         pd.DataFrame(\n",
    "#             performance, index=lstm_model.metrics_names\n",
    "#         ).assign(\n",
    "#             participant=PARTICIPANT_AS_TEST\n",
    "#         ).to_excel(writer, sheet_name=\"after fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c8c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def display_side_by_side(dfs:list, captions:list, tablespacing=5):\n",
    "    \"\"\"Display tables side by side to save vertical space\n",
    "    Input:\n",
    "        dfs: list of pandas.DataFrame\n",
    "        captions: list of table captions\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    for (caption, df) in zip(captions, dfs):\n",
    "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += tablespacing * \"\\xa0\"\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19485849",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_side_by_side([\n",
    "  pd.DataFrame(val_performance, index=lstm_model.metrics_names),\n",
    "  # pd.DataFrame(before_fine_tuning_performance, index=lstm_model.metrics_names),\n",
    "  # pd.DataFrame(performance, index=lstm_model.metrics_names)\n",
    "], [\n",
    "  'validation',\n",
    "  # 'before fine-tuning',\n",
    "  # 'after fine-tuning'\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe093f43",
   "metadata": {},
   "source": [
    "## Residual Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42135ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide_window = WindowGenerator(\n",
    "#     train_df=train_df, val_df=val_df,\n",
    "#     fine_tuning_df=fine_tuning_df, test_df=test_df,\n",
    "#     input_width=24, label_width=24, shift=1,\n",
    "#     batch_size=BATCH_SIZE)\n",
    "# print(wide_window)\n",
    "# for example_inputs, example_labels in wide_window.train.take(1):\n",
    "#   print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "#   print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
    "# wide_window.plot(plot_col=TARGET_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdad9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compile_and_fit(model, window, patience=2):\n",
    "#   early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "#                                                     patience=patience,\n",
    "#                                                     mode='min')\n",
    "\n",
    "#   model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "#                 optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "#                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "#   # model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "#   #               optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "#   #               metrics=METRICS)\n",
    "#   # model.compile(loss=brier_score_loss,\n",
    "#   #               optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "#   #               metrics=METRICS)\n",
    "\n",
    "#   # history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "#   #                     validation_data=window.val,\n",
    "#   #                     callbacks=[early_stopping])\n",
    "#   history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "#                       validation_data=window.val,\n",
    "#                       callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba86b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResidualWrapper(tf.keras.Model):\n",
    "#   def __init__(self, model):\n",
    "#     super().__init__()\n",
    "#     self.model = model\n",
    "\n",
    "#   def call(self, inputs, *args, **kwargs):\n",
    "#     delta = self.model(inputs, *args, **kwargs)\n",
    "\n",
    "#     # The prediction for each time step is the input\n",
    "#     # from the previous time step plus the delta\n",
    "#     # calculated by the model.\n",
    "#     return inputs + delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.clear_session()\n",
    "# residual_lstm = ResidualWrapper(\n",
    "#     tf.keras.Sequential([\n",
    "#         tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "#         tf.keras.layers.Dense(\n",
    "#             units=len(features),\n",
    "#             # # The predicted deltas should start small.\n",
    "#             # # Therefore, initialize the output layer with zeros.\n",
    "#             kernel_initializer=tf.initializers.zeros())\n",
    "#     ])\n",
    "# )\n",
    "\n",
    "# history = compile_and_fit(residual_lstm, wide_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d21b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.val)\n",
    "# performance['Residual LSTM'] = residual_lstm.evaluate(wide_window.test, verbose=0)\n",
    "# for name, value in zip(residual_lstm.metrics_names, performance['Residual LSTM']):\n",
    "#   print(name, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide_window.plot(model=residual_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.arange(len(performance))\n",
    "# width = 0.3\n",
    "# metric_name = 'mean_absolute_error'\n",
    "# metric_index = lstm_model.metrics_names.index('mean_absolute_error')\n",
    "# val_mae = [v[metric_index] for v in val_performance.values()]\n",
    "# test_mae = [v[metric_index] for v in performance.values()]\n",
    "\n",
    "# plt.ylabel('mean_absolute_error [T (degC), normalized]')\n",
    "# plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
    "# plt.bar(x + 0.17, test_mae, width, label='Test')\n",
    "# plt.xticks(ticks=x, labels=performance.keys(),\n",
    "#            rotation=45)\n",
    "# _ = plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e7e6b8d",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b70be-4506-44a8-a0e0-ad7a7d76a7c1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# metrics = ['loss'] #, 'balanced_accuracy', 'auc', 'prc', 'precision', 'recall']\n",
    "# plt.figure(figsize=(25, 10))\n",
    "# for n, metric in enumerate(metrics):\n",
    "#     name = metric.replace(\"_\",\" \").capitalize()\n",
    "#     plt.subplot(3,3,n+1)\n",
    "#     plt.plot(history.epoch, history.history[metric], label='Train')\n",
    "#     plt.plot(history.epoch, history.history['val_'+metric], label='Validation')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel(name)\n",
    "#     if metric == 'loss':\n",
    "#       plt.ylim([0, plt.ylim()[1]])\n",
    "#     # # elif metric == 'auc':\n",
    "#     # #   plt.ylim([0.8,1])\n",
    "#     # else:\n",
    "#     #   plt.ylim([0,1])\n",
    "#     plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa37c5e3",
   "metadata": {},
   "source": [
    "# Predict using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d8cb25-45dc-4abe-b05f-7a52616d40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_loader(new_df):\n",
    "#     return np.array(new_df, dtype=np.float32)[np.newaxis, ...]\n",
    "# linear.predict(data_loader(test_df.head(4))) # [0,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8201a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = None\n",
    "# labels = None\n",
    "\n",
    "# for input, label in single_step_window.val.as_numpy_iterator():\n",
    "#   if inputs is None:\n",
    "#     inputs = input\n",
    "#     labels = label\n",
    "#   else:\n",
    "#     inputs = np.concatenate([inputs, inputs])\n",
    "#     labels = np.concatenate([labels, labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c1be8-cf9f-49fe-9dd3-08b3b02951cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c15882-f6bf-4cf8-b804-90ed32b5a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_model = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1608823-d0e8-4acb-95b0-442174555b64",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saved_model(data_loader(test_df.iloc[0:36, :]), training=False)[:,:,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92496a0b-401c-40a5-955f-6148174ec096",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saved_model(data_loader(test_df.iloc[0:24, :]).tolist(), training=False)[:,:,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b37fff-6d12-4ef6-b03f-c84223812173",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(data_loader(test_df.iloc[0:36, :]).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9663e-18a9-450c-b900-f8554c1329c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader(test_df.iloc[0:36, :]).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
