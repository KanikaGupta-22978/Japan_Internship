{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e8f427-8968-4124-9f2c-33b2a89a21fa",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181a3a70-247e-4583-8daf-5e7bd3e23db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandasql import sqldf\n",
    "import seaborn\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "from IPython.display import Javascript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47f7ed0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configurations & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2902dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'participant12' # participant1-10\n",
    "target_freq_as_int = 15 # 15|1\n",
    "target_freq_unit1 = 'min' # min|s\n",
    "target_freq_unit2 = 'm' # m|s\n",
    "dataset_type = '' # '' | time_series_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1030a19d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# participant information\n",
    "participant_dictionary = json.load(open(f'./data/participant_dictionary.json'))\n",
    "\n",
    "target_freq = f'{target_freq_as_int}{target_freq_unit1}'\n",
    "target_freq2 = f'{target_freq_as_int}{target_freq_unit2}'\n",
    "\n",
    "user_id = participant_dictionary[user]['fonlog_id']\n",
    "start_date = participant_dictionary[user]['start_date']\n",
    "end_date_plus_one = participant_dictionary[user]['end_date_plus_one']\n",
    "end_date_plus_two = participant_dictionary[user]['end_date_plus_two']\n",
    "\n",
    "color = {\n",
    "    \"boxes\": \"Blue\",\n",
    "    \"whiskers\": \"Black\",\n",
    "    \"medians\": \"Red\",\n",
    "    \"caps\": \"Gray\"\n",
    "}\n",
    "\n",
    "wo_columns = {\n",
    "    \"Timestamp\": \"timestamp\",\n",
    "    \"Heart Rate (in Beats per minute)\": \"heart_rate\",\n",
    "    \"Stress Score\": \"stress_score\",\n",
    "    \"Stress Interpretation\": \"stress_level\",\n",
    "    \"Number of Steps\": \"steps\",\n",
    "    \"Wearing Off\": \"wearing_off\",\n",
    "    \"started_at\": \"wo_start\",\n",
    "    \"finished_at\": \"wo_end\",\n",
    "    \"Tremors\": \"wo_tremors\",\n",
    "    \"Slowing down of movement\": \"wo_slowdown\",\n",
    "    \"Change in mood or depression\": \"wo_moodchange\",\n",
    "    \"Rigidity of muscles\": \"wo_rigidity\",\n",
    "    \"Sharp pain or prolonged dull pain\": \"wo_pain\",\n",
    "    \"Impairment of complex movements of the hand and fingers\": \"wo_impairment_hands\",\n",
    "    \"Difficulty integrating thoughts or slowing down of thought\": \"wo_slow_thoughts\",\n",
    "    \"Anxiety or panic attacks\": \"wo_anxiety\",\n",
    "    \"Muscle spasm\": \"wo_muscle_spasm\",\n",
    "    \"activity_target.activity_id\": \"report_id\"\n",
    "}\n",
    "\n",
    "drug_intake_columns = {\n",
    "    \"started_at\": \"drug_intake_start\",\n",
    "    \"finished_at\": \"drug_intake_end\",\n",
    "    \"Sharp pain or prolonged dull pain\": \"drug_intake_tremors\",\n",
    "    \"Tremors\": \"drug_intake_slowdown\",\n",
    "    \"Anxiety or panic attacks\": \"drug_intake_moodchange\",\n",
    "    \"Rigidity of muscles\": \"drug_intake_rigidity\",\n",
    "    \"Slowing down of movement\": \"drug_intake_pain\",\n",
    "    \"Difficulty integrating thoughts or slowing down of thought\": \"drug_intake_impairment_hands\",\n",
    "    \"Impairment of complex movements of the hand and fingers\": \"drug_intake_slow_thoughts\",\n",
    "    \"Change in mood or depression\": \"drug_intake_anxiety\",\n",
    "    \"Muscle spasm\": \"drug_intake_muscle_spasm\"\n",
    "}\n",
    "\n",
    "symptoms_dictionary = {\n",
    "    \"ふるえる\": \"Tremors\",\n",
    "    \"動作が遅くなる\": \"Slowing down of movement\",\n",
    "    \"気分が変化する または おちこむ\": \"Change in mood or depression\",\n",
    "    \"体のどこかがこわばる\": \"Rigidity of muscles\",\n",
    "    \"するどい痛み または 長ぐ続ぐこぶい痛みがある\": \"Sharp pain or prolonged dull pain\",\n",
    "    \"手先の細かい作業が うまくできない\": \"Impairment of complex movements of the hand and fingers\",\n",
    "    \"思考がまとまらない または 頭の回転がおそい\": \"Difficulty integrating thoughts or slowing down of thought\",\n",
    "    \"不安になる または パニック状態になる\": \"Anxiety or panic attacks\",\n",
    "    \"筋肉がひきつる\": \"Muscle spasm\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adec8a7",
   "metadata": {},
   "source": [
    "# FonLog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfe444e",
   "metadata": {},
   "source": [
    "## Process wearing-off dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356f2d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activity_type_id = 2 # wearing-off's\n",
    "activity_type_id = 12 # wearing-off's\n",
    "\n",
    "# Load from file\n",
    "# fonlog_data = pd.read_excel(f'./data/fonlog/records ABC.xlsx',\n",
    "fonlog_data = pd.read_excel(f'./data/fonlog/records.xlsx',\n",
    "                           sheet_name='records', engine='openpyxl')\n",
    "# Make sure to use datetime data type\n",
    "fonlog_data['activity.started_at'] = pd.to_datetime(fonlog_data['activity.started_at'])\n",
    "fonlog_data['activity.finished_at'] = pd.to_datetime(fonlog_data['activity.finished_at'])\n",
    "\n",
    "filtered_fonlog_data = fonlog_data.loc[\n",
    "    (fonlog_data['activity_target.customer_id'] == user_id) &\n",
    "    (fonlog_data['activity_type_group.name'] == 'Wearing-Off for PD') &\n",
    "    (fonlog_data['activity.started_at'] >= start_date) &\n",
    "    (fonlog_data['activity.started_at'] < end_date_plus_two) &\n",
    "    (fonlog_data['record_type.activity_type_id'] == activity_type_id)\n",
    "]\n",
    "grouped_fonlog_data = filtered_fonlog_data.groupby(['activity_target.activity_id'])\n",
    "\n",
    "# Extract wearing-off periods\n",
    "wearing_off_periods = grouped_fonlog_data[\n",
    "    ['activity.started_at', 'activity.finished_at']\n",
    "].agg(np.unique)\n",
    "wearing_off_periods['activity_target.activity_id'] = wearing_off_periods.index\n",
    "wearing_off_periods.rename(\n",
    "    inplace=True,\n",
    "    columns={\n",
    "        \"activity.started_at\": \"started_at\",\n",
    "        \"activity.finished_at\": \"finished_at\",\n",
    "        \"activity_target.activity_id\": \"wearing_off_id\" }\n",
    ")\n",
    "\n",
    "# # Compute wearing-off duration\n",
    "# wearing_off_periods['Duration'] = ( (\n",
    "#     wearing_off_periods['finished_at'] - wearing_off_periods['started_at']\n",
    "# ) / np.timedelta64(1, \"s\") ) / 60. # in minutes\n",
    "\n",
    "# # Show wearing-off summary\n",
    "# display(wearing_off_periods['Duration'].describe())\n",
    "# display(wearing_off_periods)\n",
    "\n",
    "# # Update finished_at when finished_at == started_at\n",
    "def update_finished_at(row):\n",
    "    if row[\"started_at\"] == row[\"finished_at\"]:\n",
    "        return (row[\"finished_at\"] + pd.Timedelta(minutes=15))\n",
    "    else:\n",
    "        return (row[\"finished_at\"])\n",
    "\n",
    "wearing_off_periods['finished_at'] = wearing_off_periods.apply(lambda row: update_finished_at(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d7f4490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at</th>\n",
       "      <th>finished_at</th>\n",
       "      <th>wearing_off_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activity_target.activity_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262.0</th>\n",
       "      <td>2023-01-05 14:16:13</td>\n",
       "      <td>2023-01-05 14:31:13</td>\n",
       "      <td>262.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     started_at         finished_at  \\\n",
       "activity_target.activity_id                                           \n",
       "262.0                       2023-01-05 14:16:13 2023-01-05 14:31:13   \n",
       "\n",
       "                             wearing_off_id  \n",
       "activity_target.activity_id                  \n",
       "262.0                                 262.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wearing_off_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b68ca3",
   "metadata": {},
   "source": [
    "## Process symptoms dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f2e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table to convert to columns of symptoms\n",
    "symptoms_wearing_off = filtered_fonlog_data.pivot(\n",
    "    index='activity_target.activity_id', columns='record_type.name', values='value'\n",
    ").rename(columns=symptoms_dictionary).drop(columns='共有したい他の症状はありますか？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bdb33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge symptoms to wearing-off periods\n",
    "wearing_off_with_symptoms = pd.merge(\n",
    "    wearing_off_periods,\n",
    "    symptoms_wearing_off,\n",
    "    left_index=True, right_index=True\n",
    ")\n",
    "\n",
    "wearing_off_with_symptoms = wearing_off_with_symptoms.fillna(0).replace({'ある':1, 'ない':0})\n",
    "# # Show wearing-off symptoms\n",
    "# display(wearing_off_with_symptoms.describe())\n",
    "# display(wearing_off_with_symptoms.head())\n",
    "# display(wearing_off_with_symptoms.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07153c21",
   "metadata": {},
   "source": [
    "Remove overarching reporting when there are embedded reportings.\n",
    "\n",
    "11:00 AM      **12:00 PM**        **12:30 PM**     1:00 PM  \n",
    "    |-------------|----------------|-----------|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c041df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "cond_join= '''\n",
    "    select distinct\n",
    "        wearing_off_2.[activity_target.activity_id] as for_remove_id\n",
    "    from wearing_off_with_symptoms as wearing_off_1\n",
    "    join wearing_off_with_symptoms as wearing_off_2\n",
    "    on (wearing_off_2.[started_at] < wearing_off_1.[finished_at] AND wearing_off_2.[started_at] < wearing_off_1.[started_at]) AND\n",
    "            (wearing_off_2.[finished_at] > wearing_off_1.[finished_at] AND wearing_off_2.[finished_at] > wearing_off_1.[started_at]) AND\n",
    "            (wearing_off_1.[wearing_off_id] <> wearing_off_2.[wearing_off_id])\n",
    "'''\n",
    "for_remove_ids = pysqldf(cond_join)\n",
    "# # Show id to remove\n",
    "# display(for_remove_ids)\n",
    "\n",
    "wearing_off_with_symptoms = wearing_off_with_symptoms[~wearing_off_with_symptoms['wearing_off_id'].isin(for_remove_ids['for_remove_id'])]\n",
    "\n",
    "# # Show wearing-off symptoms\n",
    "# display(wearing_off_with_symptoms.describe())\n",
    "# display(wearing_off_with_symptoms.head())\n",
    "# display(wearing_off_with_symptoms.tail())\n",
    "\n",
    "wearing_off_with_symptoms['finished_at'] = wearing_off_with_symptoms.apply(lambda row: update_finished_at(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3fe59",
   "metadata": {},
   "source": [
    "## Process drug intake dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca028319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activity_type_id = 3 # drug-intake\n",
    "activity_type_id = 13 # drug-intake\n",
    "\n",
    "filtered_fonlog_data = fonlog_data.loc[\n",
    "    (fonlog_data['activity_target.customer_id'] == user_id) &\n",
    "    (fonlog_data['activity_type_group.name'] == 'Wearing-Off for PD') &\n",
    "    (fonlog_data['activity.started_at'] >= start_date) &\n",
    "    (fonlog_data['activity.started_at'] < end_date_plus_two) &\n",
    "    (fonlog_data['record_type.activity_type_id'] == activity_type_id)\n",
    "]\n",
    "grouped_fonlog_data = filtered_fonlog_data.groupby('activity_target.activity_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_intake = grouped_fonlog_data[\n",
    "    ['activity.started_at', 'activity.finished_at']\n",
    "].agg(np.unique)\n",
    "drug_intake['activity_target.activity_id'] = drug_intake.index\n",
    "drug_intake.rename(\n",
    "    inplace=True,\n",
    "    columns={\n",
    "        \"activity.started_at\": \"started_at\",\n",
    "        \"activity.finished_at\": \"finished_at\",\n",
    "        'activity_target.activity_id': 'drug_intake_id'\n",
    "    }\n",
    ")\n",
    "# # Show drug intake summary\n",
    "# display(drug_intake['drug_intake_id'].describe())\n",
    "# display(drug_intake.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369fff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms_drug_intake = filtered_fonlog_data.pivot(\n",
    "    index='activity_target.activity_id', columns='record_type.name', values='value'\n",
    ").rename(columns=symptoms_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b38cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_intake_with_symptoms = pd.merge(\n",
    "    drug_intake,\n",
    "    symptoms_drug_intake,\n",
    "    left_index=True, right_index=True\n",
    ")\n",
    "\n",
    "drug_intake_with_symptoms = drug_intake_with_symptoms.fillna(0).replace({'飲めば経くなる':0, '飲んでも変わらない':1, \n",
    "                                                                        'ある':1, 'ない':0})\n",
    "# display(drug_intake_with_symptoms.describe())\n",
    "# display(drug_intake_with_symptoms.head())\n",
    "# display(drug_intake_with_symptoms.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb5b5af",
   "metadata": {},
   "source": [
    "Remove overarching reporting when there are embedded reportings.\n",
    "\n",
    "11:00 AM      **12:00 PM**        **12:30 PM**     1:00 PM  \n",
    "    |-------------|----------------|-----------|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c02c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "cond_join= '''\n",
    "    select distinct\n",
    "        drug_intake_2.[activity_target.activity_id] as for_remove_id\n",
    "    from drug_intake_with_symptoms as drug_intake_1\n",
    "    join drug_intake_with_symptoms as drug_intake_2\n",
    "    on (drug_intake_2.[started_at] < drug_intake_1.[finished_at] AND drug_intake_2.[started_at] < drug_intake_1.[started_at]) AND\n",
    "            (drug_intake_2.[finished_at] > drug_intake_1.[finished_at] AND drug_intake_2.[finished_at] > drug_intake_1.[started_at]) AND\n",
    "            (drug_intake_1.[drug_intake_id] <> drug_intake_2.[drug_intake_id])\n",
    "'''\n",
    "for_remove_ids_in_drug_intake = pysqldf(cond_join)\n",
    "# display(for_remove_ids_in_drug_intake)\n",
    "\n",
    "drug_intake_with_symptoms = drug_intake_with_symptoms[~drug_intake_with_symptoms['drug_intake_id'].isin(for_remove_ids_in_drug_intake['for_remove_id'])]\n",
    "# drug_intake_with_symptoms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ca68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_intake_with_symptoms['finished_at'] = drug_intake_with_symptoms.apply(lambda row: update_finished_at(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ac977",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'./data/steps/{user}'):\n",
    "    os.makedirs(f'./data/steps/{user}')\n",
    "\n",
    "wearing_off_with_symptoms.to_excel(f'./data/steps/{user}/1-{user}_woq_with_symptoms.xlsx')\n",
    "drug_intake_with_symptoms.to_excel(f'./data/steps/{user}/2-{user}_drug_intake_with_symptoms.xlsx')\n",
    "\n",
    "# To save description, for later\n",
    "# if not os.path.exists(f'./data/summary/{user}'):\n",
    "#     os.makedirs(f'./data/summary/{user}')\n",
    "\n",
    "# # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "# writer = pd.ExcelWriter(f'./results/summary/{user}/0-{user}-summary.xlsx', engine='openpyxl')\n",
    "\n",
    "# # Write each dataframe to a different worksheet.\n",
    "# drug_intake_with_symptoms.describe().to_excel(writer, sheet_name='Drug Intake Summary')\n",
    "\n",
    "# # Close the Pandas Excel writer and output the Excel file.\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b108436c",
   "metadata": {},
   "source": [
    "# Garmin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e061c87",
   "metadata": {},
   "source": [
    "## Heart rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4f841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate = pd.read_excel(f'./data/garmin/{user}.xlsx',\n",
    "                           sheet_name='Heart Rate', index_col='Timestamp',\n",
    "                           engine='openpyxl')\n",
    "heart_rate.sort_values('Timestamp', inplace=True)\n",
    "heart_rate = heart_rate.loc[start_date:end_date_plus_one].rename(\n",
    "    columns={'Heart Rate (in Beats per minute)': 'heart_rate'}\n",
    ")\n",
    "# display(heart_rate.describe())\n",
    "# display(heart_rate.head())\n",
    "# display(heart_rate.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553a01a2",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = pd.read_excel(f'./data/garmin/{user}.xlsx',\n",
    "                           sheet_name='Steps', index_col='Timestamp',\n",
    "                           engine='openpyxl')\n",
    "steps.sort_values('Timestamp', inplace=True)\n",
    "steps = steps.loc[start_date:end_date_plus_one].rename(\n",
    "    columns={'Number of Steps': 'steps'}\n",
    ")\n",
    "# display(steps.describe())\n",
    "# display(steps.head())\n",
    "# display(steps.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0399934c",
   "metadata": {},
   "source": [
    "## Stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb6625",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress = pd.read_excel(f'./data/garmin/{user}.xlsx',\n",
    "                           sheet_name='Stress', index_col='Timestamp',\n",
    "                           engine='openpyxl')\n",
    "stress.sort_values('Timestamp', inplace=True)\n",
    "stress = stress.loc[start_date:end_date_plus_one].rename(\n",
    "    columns={'Stress Score': 'stress_score', 'Stress Interpretation': 'stress_interpretation'}\n",
    ")\n",
    "# display(stress.describe())\n",
    "# display(stress.head())\n",
    "# display(stress.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7db813d",
   "metadata": {},
   "source": [
    "## Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc26dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep = pd.read_excel(f'./data/garmin/{user}.xlsx',\n",
    "                           sheet_name='Sleep', index_col='Calendar Date',\n",
    "                           engine='openpyxl')\n",
    "sleep.sort_values('Start Time', inplace=True)\n",
    "sleep = sleep.loc[start_date:end_date_plus_one]\n",
    "\n",
    "# Compute duration in minutes\n",
    "sleep['Duration'] = (sleep['End Time'] - sleep['Start Time']) / np.timedelta64(1, \"m\")\n",
    "\n",
    "# # Show original sleep data format\n",
    "# display('Original')\n",
    "# display(sleep.head())\n",
    "# display(sleep.tail())\n",
    "\n",
    "# Transform sleep data by sleep classification type\n",
    "sleep = sleep.pivot_table(\n",
    "    index = 'Calendar Date',\n",
    "    columns = 'Sleep Type',\n",
    "    values = 'Duration',\n",
    "    aggfunc = 'sum'\n",
    ")\n",
    "sleep = pd.DataFrame(sleep.to_records()).set_index('Calendar Date').fillna(0)\n",
    "# Make sure that sleep index is a DateTimeIndex type\n",
    "sleep.index = pd.to_datetime(sleep.index)\n",
    "sleep.index.name = 'Timestamp'\n",
    "\n",
    "# Compute total non-rem sleep\n",
    "sleep['nonrem_total'] = (sleep['deep'] + sleep['light'])\n",
    "sleep['total'] = (sleep['nonrem_total'] + sleep['rem'])\n",
    "sleep['nonrem_percentage'] = sleep['nonrem_total'] / sleep['total']\n",
    "sleep['sleep_efficiency'] = sleep['total'] / (sleep['total'] + sleep['awake'])\n",
    "\n",
    "# Ignore unmeasurable column from sleep dataset\n",
    "if 'unmeasurable' in sleep.columns:\n",
    "    sleep.drop(columns=['unmeasurable'], inplace=True)\n",
    "\n",
    "# # Show transformed sleep data\n",
    "# display('Summary')\n",
    "# display(sleep.describe())\n",
    "# display('Transformed')\n",
    "# display(sleep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a112344",
   "metadata": {},
   "source": [
    "## Complete collection period before resampling\n",
    "\n",
    "First, fill missing values according to Garmin's documentation and within the collection period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d9240",
   "metadata": {},
   "source": [
    "### Heart rate\n",
    "* Fill missing values with -1, as per Garmin's documentation for missing values before resampling\n",
    "* Missing values for the expected period indicate that the Garmin vivosmart4 was not worn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673fce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate_freq = '15s'\n",
    "reference = pd.DataFrame(\n",
    "    index = pd.date_range(\n",
    "        start_date, end_date_plus_two,\n",
    "        freq = heart_rate_freq, name='Timestamp'\n",
    "    ).drop(\n",
    "        pd.Timestamp(end_date_plus_two)\n",
    "    )\n",
    ")\n",
    "\n",
    "heart_rate = reference.merge(\n",
    "    heart_rate.resample(heart_rate_freq).mean(), on='Timestamp', how='left'\n",
    ")#.fillna(-1)\n",
    "\n",
    "# display(heart_rate.describe())\n",
    "# display(heart_rate.head())\n",
    "# display(heart_rate.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa578cd",
   "metadata": {},
   "source": [
    "### Steps\n",
    "* Fill missing values with -1 to standardize with other Garmin datasets\n",
    "* Missing values for the expected period indicate that the Garmin vivosmart4 was not worn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7965809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps\n",
    "#     fill missing values with -1 to standardize with other Garmin dataset\n",
    "#     missing values for the expected period indicates Garmin vivosmart4 was not worn\n",
    "steps_freq = '15min'\n",
    "reference = pd.DataFrame(\n",
    "    index = pd.date_range(\n",
    "        start_date, end_date_plus_two,\n",
    "        freq = steps_freq, name='Timestamp'\n",
    "    ).drop(\n",
    "        pd.Timestamp(end_date_plus_two)\n",
    "    )\n",
    ")\n",
    "\n",
    "steps = reference.merge(\n",
    "    steps.resample(steps_freq).mean(), on='Timestamp', how='left'\n",
    ")#.fillna(-1)\n",
    "\n",
    "# display(steps.describe())\n",
    "# display(steps.head())\n",
    "# display(steps.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc38b2f",
   "metadata": {},
   "source": [
    "### Stress\n",
    "* Fill missing values with -1, as per Garmin's documentation for missing values before resampling\n",
    "* Missing values for the expected period indicate that the Garmin vivosmart4 was not worn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb311b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_freq = '3min'\n",
    "reference = pd.DataFrame(\n",
    "    index = pd.date_range(\n",
    "        start_date, end_date_plus_two,\n",
    "        freq = stress_freq, name='Timestamp'\n",
    "    ).drop(\n",
    "        pd.Timestamp(end_date_plus_two)\n",
    "    )\n",
    ")\n",
    "\n",
    "stress = reference.merge(\n",
    "    stress.resample(stress_freq).mean(), on='Timestamp', how='left'\n",
    ")#.fillna(-1)\n",
    "\n",
    "# display(stress.describe())\n",
    "# display(stress.head())\n",
    "# display(stress.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a2774c",
   "metadata": {},
   "source": [
    "### Sleep\n",
    "* Fill missing values with -1 to standardize with other Garmin datasets\n",
    "* Missing values for the expected period indicate that the Garmin vivosmart4 was not worn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f52e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_freq = 'D'\n",
    "reference = pd.DataFrame(\n",
    "    index = pd.date_range(\n",
    "        start_date, end_date_plus_two,\n",
    "        freq = sleep_freq, name = 'Timestamp'\n",
    "    ).drop(\n",
    "        pd.Timestamp(end_date_plus_two)\n",
    "    )\n",
    ")\n",
    "sleep = reference.merge(\n",
    "    sleep.resample(sleep_freq).mean(), on=\"Timestamp\", how='left'\n",
    ")#.fillna(-1)\n",
    "\n",
    "# # Show transformed sleep data\n",
    "# display('Summary')\n",
    "# display(sleep.describe())\n",
    "# display('Transformed')\n",
    "# display(sleep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e487721b-472e-46f8-b66f-7473b84a2905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# multi_res = pd.concat([heart_rate, steps, stress], axis=1).sort_index(ascending=True)# .to_excel(\"garmin_multiresolution.xlsx\")\n",
    "# multi_res\n",
    "\n",
    "# sleep_multi_res = pd.concat([\n",
    "#     pd.DataFrame(\n",
    "#         index = pd.date_range(\n",
    "#             start_date, end_date_plus_two,\n",
    "#             freq = '15s', name = 'Timestamp'\n",
    "#         ).drop(\n",
    "#             pd.Timestamp(end_date_plus_two)\n",
    "#         )\n",
    "#     ).merge(\n",
    "#         sleep.resample('15s').mean(), on='Timestamp', how='left'\n",
    "#     ).ffill(),\n",
    "\n",
    "#     pd.DataFrame(\n",
    "#         index = pd.date_range(\n",
    "#             start_date, end_date_plus_two,\n",
    "#             freq = '15min', name = 'Timestamp'\n",
    "#         ).drop(\n",
    "#             pd.Timestamp(end_date_plus_two)\n",
    "#         )\n",
    "#     ).merge(\n",
    "#         sleep.resample('15min').mean(), on='Timestamp', how='left'\n",
    "#     ).ffill(),\n",
    "\n",
    "#     pd.DataFrame(\n",
    "#         index = pd.date_range(\n",
    "#             start_date, end_date_plus_two,\n",
    "#             freq = '3min', name = 'Timestamp'\n",
    "#         ).drop(\n",
    "#             pd.Timestamp(end_date_plus_two)\n",
    "#         )\n",
    "#     ).merge(\n",
    "#         sleep.resample('3min').mean(), on='Timestamp', how='left'\n",
    "#     ).ffill() \n",
    "# ]).reset_index().drop_duplicates(subset=['Timestamp']).set_index('Timestamp').sort_index(ascending=True)\n",
    "# sleep_multi_res\n",
    "\n",
    "# multi_res.merge(\n",
    "#     sleep_multi_res, on='Timestamp', how='left'\n",
    "# ).sort_index(ascending=True).to_excel(\"garmin_multiresolution.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb9c84",
   "metadata": {},
   "source": [
    "## Combine Garmin Dataset\n",
    "Resample according to resampling plan.\n",
    "\n",
    "Missing values due to resampling:\n",
    "* Fill using previous known value.\n",
    "* ``ffill()`` does this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cbb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reference timestamp dataframe for the collection period\n",
    "reference = pd.DataFrame(\n",
    "    index = pd.date_range(\n",
    "        start_date, end_date_plus_two,\n",
    "        freq = target_freq, name = 'Timestamp'\n",
    "    ).drop(\n",
    "        pd.Timestamp(end_date_plus_two)\n",
    "    )\n",
    ")\n",
    "# display('Reference timestamp')\n",
    "# display(reference)\n",
    "\n",
    "# Combine each Garmin dataset to reference timestamp dataframe\n",
    "garmin_data = reference.merge(\n",
    "    # downsample heart rate from 15sec to 1min\n",
    "    #   missing values = -1 same treatment with Garmin with regards to missing value, fitness tracker not worn\n",
    "    heart_rate.resample(target_freq).mean(), on='Timestamp', how='left'\n",
    ")#.ffill()\n",
    "garmin_data = garmin_data.merge(\n",
    "    steps.resample(target_freq).mean(), on='Timestamp', how='left'\n",
    ")#.ffill()\n",
    "garmin_data = garmin_data.merge(\n",
    "    stress.resample(target_freq).mean(), on='Timestamp', how='left'\n",
    ")#.ffill()\n",
    "garmin_data = garmin_data.merge(\n",
    "    sleep.resample(target_freq).mean().ffill(), on='Timestamp', how='left'\n",
    ")#.ffill()\n",
    "# display('Combined Data')\n",
    "# display(garmin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33843d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "garmin_data.to_excel(f'./data/steps/{user}/3-{user}_combined_garmin_data_only.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88741a6",
   "metadata": {},
   "source": [
    "# Combine Datasets\n",
    "Match wearing-off to combined Garmin data based on wearing-off start and end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807c8e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "cond_join= '''\n",
    "    select \n",
    "        garmin.*,\n",
    "        wearing_off_with_symptoms.*,\n",
    "        case\n",
    "            when wearing_off_with_symptoms.[started_at] is not null THEN 1\n",
    "        else 0\n",
    "        end as 'Wearing Off'\n",
    "    from garmin_data as garmin\n",
    "    left join wearing_off_with_symptoms\n",
    "    on garmin.[Timestamp] BETWEEN wearing_off_with_symptoms.[started_at] AND wearing_off_with_symptoms.[finished_at]\n",
    "'''\n",
    "\n",
    "# Change wearing-off columns\n",
    "combined_data = pysqldf(cond_join).rename(columns=wo_columns)\n",
    "\n",
    "# Drop duplicates based on timestamp\n",
    "combined_data = combined_data.drop_duplicates(subset=['timestamp'])\n",
    "\n",
    "# Set timestamp as index\n",
    "combined_data['timestamp'] = pd.to_datetime(combined_data['timestamp'])\n",
    "combined_data = combined_data.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecde580e",
   "metadata": {},
   "source": [
    "Compute for wearing-off duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['wo_duration'] = ''\n",
    "combined_data['wo_duration'] = (\n",
    "    pd.to_datetime(combined_data.index) - pd.to_datetime(combined_data['wo_start'])\n",
    ") / np.timedelta64(1, target_freq_unit2)\n",
    "\n",
    "# gid = combined_data['wo_duration'].notnull().cumsum()\n",
    "# dg = combined_data.groupby(gid)\n",
    "# base = dg['wo_duration'].transform('last')\n",
    "# combined_data['wo_duration'] = (  base + ( dg.cumcount() ) * target_freq_as_int)\n",
    "\n",
    "# display(combined_data.iloc[140:150, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e8dacb",
   "metadata": {},
   "source": [
    "Match drug intake to combined Garmin data based on drug intake start and end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb996c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "cond_join= '''\n",
    "    select \n",
    "        combined_data.*,\n",
    "        drug_intake_with_symptoms.*,\n",
    "        case\n",
    "            when drug_intake_with_symptoms.[started_at] is not null THEN 1\n",
    "        else 0\n",
    "        end as 'drug_intake'\n",
    "    from combined_data\n",
    "    left join drug_intake_with_symptoms\n",
    "    on combined_data.[timestamp] BETWEEN drug_intake_with_symptoms.[started_at] AND drug_intake_with_symptoms.[finished_at]\n",
    "'''\n",
    "\n",
    "# Change drug intake columns\n",
    "combined_data = pysqldf(cond_join).rename(columns={\n",
    "    \"started_at\": \"drug_intake_start\",\n",
    "    \"finished_at\": \"drug_intake_end\",\n",
    "    \"Sharp pain or prolonged dull pain\": \"drug_intake_tremors\",\n",
    "    \"Tremors\": \"drug_intake_slowdown\",\n",
    "    \"Anxiety or panic attacks\": \"drug_intake_moodchange\",\n",
    "    \"Rigidity of muscles\": \"drug_intake_rigidity\",\n",
    "    \"Slowing down of movement\": \"drug_intake_pain\",\n",
    "    \"Difficulty integrating thoughts or slowing down of thought\": \"drug_intake_impairment_hands\",\n",
    "    \"Impairment of complex movements of the hand and fingers\": \"drug_intake_slow_thoughts\",\n",
    "    \"Change in mood or depression\": \"drug_intake_anxiety\",\n",
    "    \"Muscle spasm\": \"drug_intake_muscle_spasm\"\n",
    "}).drop_duplicates(subset=['timestamp'])\n",
    "\n",
    "# Drop duplicates based on timestamp\n",
    "combined_data['timestamp'] = pd.to_datetime(combined_data['timestamp'])\n",
    "combined_data = combined_data.set_index('timestamp')\n",
    "combined_data = combined_data.drop(columns=['activity_target.activity_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8cd76",
   "metadata": {},
   "source": [
    "Compute time from last drug taken\n",
    "* find the difference between the reference timestamp and the drug intake start\n",
    "* convert difference to target frequency's unit e.g. minute, seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e4eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['time_from_last_drug_taken'] = ''\n",
    "combined_data['time_from_last_drug_taken'] = (\n",
    "    pd.to_datetime(combined_data.index) - pd.to_datetime(combined_data['drug_intake_start'])\n",
    ") / np.timedelta64(1, target_freq_unit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2289ee",
   "metadata": {},
   "source": [
    "Fill records after a drug intake report by adding target frequency value\n",
    "* add 1 minute, 15 seconds or 15 minutes to succeeding records after the drug intake end\n",
    "* reference: https://stackoverflow.com/a/42748625/2303766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7347d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "gid = combined_data['time_from_last_drug_taken'].notnull().cumsum()\n",
    "dg = combined_data.groupby(gid)\n",
    "base = dg['time_from_last_drug_taken'].transform('last')\n",
    "combined_data['time_from_last_drug_taken'] = (  base + ( dg.cumcount() ) * target_freq_as_int)\n",
    "\n",
    "if combined_data['time_from_last_drug_taken'].isna().any():\n",
    "    combined_data['time_from_last_drug_taken'] = combined_data['time_from_last_drug_taken'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f03f8a4",
   "metadata": {},
   "source": [
    "Generate final symptoms i.e., initial symptom + symptom after drug intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da5691",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wo_symptoms = ['wo_pain', 'wo_tremors', 'wo_anxiety', 'wo_rigidity',\n",
    "               'wo_slowdown', 'wo_slow_thoughts', 'wo_impairment_hands', \n",
    "               'wo_moodchange', 'wo_muscle_spasm']\n",
    "\n",
    "drug_intake_symptoms = ['drug_intake_pain', 'drug_intake_tremors',\n",
    "                        'drug_intake_anxiety', 'drug_intake_rigidity',\n",
    "                        'drug_intake_slowdown', 'drug_intake_slow_thoughts',\n",
    "                        'drug_intake_impairment_hands', \n",
    "                        'drug_intake_moodchange', 'drug_intake_muscle_spasm']\n",
    "\n",
    "def generate_final_symptoms(row):\n",
    "    values = []\n",
    "    for wo_symptom, drug_intake_symptom in zip(wo_symptoms, drug_intake_symptoms):\n",
    "        if math.isnan(row[drug_intake_symptom]):\n",
    "            if row[wo_symptom] is None or math.isnan(row[wo_symptom]):\n",
    "                values.append(0)\n",
    "            else:\n",
    "                values.append(row[wo_symptom])\n",
    "        else:\n",
    "            values.append(row[drug_intake_symptom])\n",
    "    if sum(values) >= 1:\n",
    "        values.append(1)\n",
    "    else:\n",
    "        values.append(0)\n",
    "    return pd.Series(values)\n",
    "\n",
    "symptoms = combined_data.apply(lambda row: generate_final_symptoms(row), axis=1)\n",
    "symptoms.columns = ['pain', 'tremors', 'anxiety', 'rigidity', 'slowdown', 'slow_thoughts',\n",
    "                    'impairment_hands', 'moodchange', 'muscle_spasm', 'wearing_off_post_meds']\n",
    "# combined_data = combined_data.drop(columns=['y'])\n",
    "combined_data = combined_data.join(symptoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea61b8f5-83ea-4c71-9f63-19b5f2e68dff",
   "metadata": {},
   "source": [
    "Compute for final wearing_off based on\n",
    "* wearing_off: reported from WoQ-9 Part 1 (symptoms)\n",
    "* wearing_off_post_meds: reported from WoQ-9 Part 2 (Medicine Intake & its effect on the symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b907d-6f1f-40f3-a10c-eb232060fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_wearing_offs(n):\n",
    "    if n > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "combined_data[\"wearing_off\"] = (combined_data.wearing_off + combined_data.wearing_off_post_meds).apply(\n",
    "    lambda n: combine_wearing_offs(n)\n",
    ").values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af16d93-858b-44c0-8a51-1b862d8fc6e9",
   "metadata": {},
   "source": [
    "# Post-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df20a534-a605-4888-baf1-727e4b293adc",
   "metadata": {},
   "source": [
    "## Include hour & day of the week\n",
    "Include hour and day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4cb149-e330-4215-a373-b53f5438a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['timestamp_hour'] = combined_data.index.hour\n",
    "combined_data['timestamp_dayofweek'] = combined_data.index.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aae12a-80be-49be-bd64-03d9f7ad0d7b",
   "metadata": {},
   "source": [
    "## Encode hour-features as cyclical features\n",
    "Include hour sine & hour cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28e2e7-f357-47c3-897d-26567e0e80ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix timestamp format\n",
    "date_time = pd.to_datetime(combined_data.index, format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "# Convert to timestamp\n",
    "timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "\n",
    "# Get seconds per day\n",
    "day = 24 * 60 * 60 \n",
    "# Get seconds per year\n",
    "year = 365.2425 * day\n",
    "\n",
    "# Get sine(), cosine() for hour-feature\n",
    "combined_data['timestamp_hour_sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "combined_data['timestamp_hour_cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "\n",
    "# Move `wearing_off` feature at the end of the dataframe\n",
    "tmp = combined_data.pop('timestamp_dayofweek')\n",
    "combined_data['timestamp_dayofweek'] = tmp\n",
    "tmp = combined_data.pop('wearing_off')\n",
    "combined_data['wearing_off'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6626d5a9-455a-4b08-b8a3-49b583b829fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "n, bins, patches = plt.hist(x=combined_data['timestamp_dayofweek'], bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution Days of the Week')\n",
    "# plt.text(23, 45, r'$\\mu=15, b=3$')\n",
    "maxfreq = n.max()\n",
    "# Set a clean upper y-axis limit.\n",
    "plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\n",
    "plt.figure(figsize=(24, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b7bd1d-95ed-44f5-a59b-c22e34696748",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(combined_data['time_from_last_drug_taken'] * (2 * np.pi / combined_data['time_from_last_drug_taken'].max())).plot(figsize=(24,10))\n",
    "np.cos(combined_data['time_from_last_drug_taken'] * (2 * np.pi / combined_data['time_from_last_drug_taken'].max())).plot(figsize=(24,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914cdb75-ba5d-48b5-8096-abc31502ca26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.to_excel(f'./data/4-combined_data_{user}_{target_freq}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b9d65f-fdf3-41a0-afd2-f96d593599eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Javascript(\"alert('Done')\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaadb3b",
   "metadata": {},
   "source": [
    "## Generate shifted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "# columns = [ 'timestamp', \n",
    "#            'heart_rate', 'steps', 'stress_score',\n",
    "#            'awake', 'deep', 'light', 'rem', 'nonrem_total', 'total', \n",
    "#            'nonrem_percentage', 'sleep_efficiency']\n",
    "\n",
    "# # Include FonLog data\n",
    "# columns = columns + ['time_from_last_drug_taken', 'wo_duration'] \\\n",
    "#                   + [\"wearing_off_post_meds\", \"wearing_off\"]\n",
    "# target_column = \"wearing_off\"\n",
    "\n",
    "# interval = \"15min\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe3904b",
   "metadata": {},
   "source": [
    "### Add wearing-off from future to current time\n",
    "$$\n",
    "X_t, y_t \\rightarrow y_{(t+1 \\texttt{hour})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf7166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # participant_number = 1\n",
    "# for participant_number in range(1,11):\n",
    "#     data = pd.read_excel(f\"data/original/4-combined_data_participant{participant_number}_{interval}.xlsx\",\n",
    "#                         index_col = \"timestamp\")\n",
    "\n",
    "#     data[\"wearing_off\"] = (data.wearing_off + data.wearing_off_post_meds).apply(\n",
    "#         lambda n: combine_wearing_offs(n)\n",
    "#     ).values\n",
    "    \n",
    "#     # select only columns\n",
    "#     # data = data.loc[:, columns[1:]]\n",
    "\n",
    "#     # shift data\n",
    "#     # 60: target forecast of 1 hour\n",
    "#     # 15: current frequency\n",
    "#     forecast_lead = 60\n",
    "#     forecast_lead_rows = int( 60 / 15 )\n",
    "#     target = f\"{target_column}_lead{forecast_lead}\"\n",
    "\n",
    "#     data[target] = data[target_column].shift(-forecast_lead_rows)\n",
    "#     data = data.iloc[:-forecast_lead_rows]\n",
    "\n",
    "#     # Save to Excel\n",
    "#     data.to_excel(f\"data/4-combined_data_participant{participant_number}_{interval}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129cbb02",
   "metadata": {},
   "source": [
    "### Add previous features\n",
    "$$\n",
    "X_{t-1}, y_{t-1}, X_{t} \\rightarrow y_{t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1308fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for participant_number in range(1,11):\n",
    "#     data = pd.read_excel(f\"data/original/4-combined_data_participant{participant_number}_{interval}.xlsx\",\n",
    "#                         index_col = \"timestamp\")\n",
    "\n",
    "#     data[\"wearing_off\"] = (data.wearing_off + data.wearing_off_post_meds).apply(\n",
    "#         lambda n: combine_wearing_offs(n)\n",
    "#     ).values\n",
    "    \n",
    "#     # select only columns\n",
    "#     # data = data.loc[:, columns[1:]]\n",
    "\n",
    "#     # shift data\n",
    "#     # 60: target forecast of 1 hour\n",
    "#     # 15: current frequency\n",
    "#     forecast_lead = 60\n",
    "#     forecast_lead_rows = int( 60 / 15 )\n",
    "\n",
    "#     data = pd.concat([\n",
    "#         data,                                                         # data at current time step\n",
    "#         data.shift(forecast_lead_rows).add_suffix(\"-1\") # data at previous time step\n",
    "#     ], axis=1)\n",
    "\n",
    "#     # Save to Excel\n",
    "#     data.to_excel(f\"data/4-combined_data_participant{participant_number}_{interval}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f80064",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-discipline",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# from openpyxl import load_workbook\n",
    "# # https://stackoverflow.com/a/47740262/2303766\n",
    "# def append_df_to_excel(filename, df, sheet_name='Sheet1', startrow=None,\n",
    "#                        truncate_sheet=False, \n",
    "#                        **to_excel_kwargs):\n",
    "#     \"\"\"\n",
    "#     Append a DataFrame [df] to existing Excel file [filename]\n",
    "#     into [sheet_name] Sheet.\n",
    "#     If [filename] doesn't exist, then this function will create it.\n",
    "\n",
    "#     @param filename: File path or existing ExcelWriter\n",
    "#                      (Example: '/path/to/file.xlsx')\n",
    "#     @param df: DataFrame to save to workbook\n",
    "#     @param sheet_name: Name of sheet which will contain DataFrame.\n",
    "#                        (default: 'Sheet1')\n",
    "#     @param startrow: upper left cell row to dump data frame.\n",
    "#                      Per default (startrow=None) calculate the last row\n",
    "#                      in the existing DF and write to the next row...\n",
    "#     @param truncate_sheet: truncate (remove and recreate) [sheet_name]\n",
    "#                            before writing DataFrame to Excel file\n",
    "#     @param to_excel_kwargs: arguments which will be passed to `DataFrame.to_excel()`\n",
    "#                             [can be a dictionary]\n",
    "#     @return: None\n",
    "\n",
    "#     Usage examples:\n",
    "\n",
    "#     >>> append_df_to_excel('d:/temp/test.xlsx', df)\n",
    "\n",
    "#     >>> append_df_to_excel('d:/temp/test.xlsx', df, header=None, index=False)\n",
    "\n",
    "#     >>> append_df_to_excel('d:/temp/test.xlsx', df, sheet_name='Sheet2',\n",
    "#                            index=False)\n",
    "\n",
    "#     >>> append_df_to_excel('d:/temp/test.xlsx', df, sheet_name='Sheet2', \n",
    "#                            index=False, startrow=25)\n",
    "\n",
    "#     (c) [MaxU](https://stackoverflow.com/users/5741205/maxu?tab=profile)\n",
    "#     \"\"\"\n",
    "#     # Excel file doesn't exist - saving and exiting\n",
    "#     if not os.path.isfile(filename):\n",
    "#         df.to_excel(\n",
    "#             filename,\n",
    "#             sheet_name=sheet_name, \n",
    "#             startrow=startrow if startrow is not None else 0, \n",
    "#             **to_excel_kwargs)\n",
    "#         return\n",
    "    \n",
    "#     # ignore [engine] parameter if it was passed\n",
    "#     if 'engine' in to_excel_kwargs:\n",
    "#         to_excel_kwargs.pop('engine')\n",
    "\n",
    "#     writer = pd.ExcelWriter(filename, engine='openpyxl', mode='a')\n",
    "\n",
    "#     # try to open an existing workbook\n",
    "#     writer.book = load_workbook(filename)\n",
    "    \n",
    "#     # get the last row in the existing Excel sheet\n",
    "#     # if it was not specified explicitly\n",
    "#     if startrow is None and sheet_name in writer.book.sheetnames:\n",
    "#         startrow = writer.book[sheet_name].max_row\n",
    "\n",
    "#     # truncate sheet\n",
    "#     if truncate_sheet and sheet_name in writer.book.sheetnames:\n",
    "#         # index of [sheet_name] sheet\n",
    "#         idx = writer.book.sheetnames.index(sheet_name)\n",
    "#         # remove [sheet_name]\n",
    "#         writer.book.remove(writer.book.worksheets[idx])\n",
    "#         # create an empty sheet [sheet_name] using old index\n",
    "#         writer.book.create_sheet(sheet_name, idx)\n",
    "    \n",
    "#     # copy existing sheets\n",
    "#     writer.sheets = {ws.title:ws for ws in writer.book.worksheets}\n",
    "\n",
    "#     if startrow is None:\n",
    "#         startrow = 0\n",
    "\n",
    "#     # write out the new sheet\n",
    "#     df.to_excel(writer, sheet_name, startrow=startrow, **to_excel_kwargs)\n",
    "\n",
    "#     # save the workbook\n",
    "#     writer.save()\n",
    "\n",
    "# independent_variables = ['heart_rate', 'steps', 'stress_score',\n",
    "#     'awake', 'deep', 'light', 'rem', 'nonrem_total',\n",
    "#     'total', 'nonrem_percentage', 'sleep_efficiency',\n",
    "#     'time_from_last_drug_taken', 'drug_intake']\n",
    "\n",
    "# dependent_variables = [ \n",
    "#     'wo_pain', 'wo_tremors', 'wo_anxiety', 'wo_rigidity',\n",
    "#     'wo_slowdown', 'wo_slow_thoughts', 'wo_impairment_hands',\n",
    "#     'wo_moodchange', 'wo_muscle_spasm',\n",
    "    \n",
    "#     'pain', 'tremors', 'anxiety', 'rigidity',\n",
    "#     'slowdown', 'slow_thoughts', 'impairment_hands',\n",
    "#     'moodchange', 'muscle_spasm',\n",
    "#     'wo_duration', 'wearing_off',\n",
    "#     'wearing_off_post_meds'\n",
    "# ]\n",
    "\n",
    "# find_correlation = independent_variables + dependent_variables\n",
    "\n",
    "# correlation_results = combined_data.fillna(0)[combined_data.columns & find_correlation].corr(method='pearson').loc[\n",
    "#     independent_variables, dependent_variables\n",
    "# ]\n",
    "\n",
    "# append_df_to_excel(f'./results/correlation.xlsx',\n",
    "#                   correlation_results,\n",
    "#                   sheet_name=f'{user}_{target_freq}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
