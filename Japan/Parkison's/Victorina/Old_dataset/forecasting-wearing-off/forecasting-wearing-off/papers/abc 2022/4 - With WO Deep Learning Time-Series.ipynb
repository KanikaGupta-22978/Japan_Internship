{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0437bbe9-9749-4c9e-b556-b4e2399a4b43",
   "metadata": {},
   "source": [
    "# Load libraries, configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f75f41-df13-4157-a93a-1901c3fa5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# !pip install shap\n",
    "# import shap\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (25,10)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "np.random.seed(0)\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "# shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20049a-9d7f-435a-8b2f-9b7d32781b37",
   "metadata": {},
   "source": [
    "# Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272b3308-8332-4561-b5e3-28bcb8b4e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedAccuracy(tf.keras.metrics.Metric):\n",
    "\n",
    "  def __init__(self, name='sklearn_balanced_accuracy', **kwargs):\n",
    "    super(BalancedAccuracy, self).__init__(name=name, **kwargs)\n",
    "    self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "    self.true_negatives = self.add_weight(name='tn', initializer='zeros')\n",
    "    self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "    self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    y_true = tf.cast(y_true, tf.bool)\n",
    "    y_pred = tf.cast(y_pred, tf.bool)\n",
    "\n",
    "    tp_values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n",
    "    tn_values = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, False))\n",
    "    fp_values = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, True))\n",
    "    fn_values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, False))\n",
    "    \n",
    "    tp_values = tf.cast(tp_values, self.dtype)\n",
    "    tn_values = tf.cast(tn_values, self.dtype)\n",
    "    fp_values = tf.cast(fp_values, self.dtype)\n",
    "    fn_values = tf.cast(fn_values, self.dtype)\n",
    "    \n",
    "    self.true_positives.assign_add(tf.reduce_sum(tp_values))\n",
    "    self.true_negatives.assign_add(tf.reduce_sum(tn_values))\n",
    "    self.false_positives.assign_add(tf.reduce_sum(fp_values))\n",
    "    self.false_negatives.assign_add(tf.reduce_sum(fn_values))\n",
    "\n",
    "  def result(self):\n",
    "    return ( (self.true_positives/(self.true_positives + self.false_negatives)) + (self.true_negatives/(self.true_negatives + self.false_positives)) ) / 2\n",
    "\n",
    "  def reset_state(self):\n",
    "    self.true_positives.assign(0)\n",
    "    self.true_negatives.assign(0)\n",
    "    self.false_positives.assign(0)\n",
    "    self.false_negatives.assign(0)\n",
    "    \n",
    "# m = BalancedAccuracy()\n",
    "# m.update_state([0, 1, 1, 1], [0, 1, 0, 0])\n",
    "# print('Intermediate result:', float(m.result()))\n",
    "\n",
    "# # m.update_state([1, 1, 1, 1], [0, 1, 1, 0])\n",
    "# # print('Final result:', float(m.result()))\n",
    "\n",
    "# # SkLearn / Manual\n",
    "# y_true = [0, 1, 1, 1]\n",
    "# y_pred = [0, 1, 0, 0]\n",
    "# tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "# print(tn, fp, fn, tp)\n",
    "# print(f'Manual {(((tp/(tp + fn)) + (tn/(tn + fp)))/2)}')\n",
    "# print(f'scikit-learn {balanced_accuracy_score(y_true, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a6a12c-5711-4efd-8e9c-fcfbba8032aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train size moving window\n",
    "class WindowTimeSeriesSplit():\n",
    "    def __init__(self, train_size, test_size, is_expanding=False):\n",
    "        self.train_size = train_size\n",
    "        self.test_size = test_size\n",
    "        self.is_expanding = is_expanding\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups):\n",
    "        n_splits = 0\n",
    "        \n",
    "        n_records = int(len(X))\n",
    "        indices = np.arange(n_records)\n",
    "\n",
    "        margin = 0 # Gap between train and test data\n",
    "        start = 0\n",
    "        mid = None\n",
    "        stop = None\n",
    "        while True:\n",
    "            if mid is None:\n",
    "                mid = start + self.train_size\n",
    "            elif mid is not None:\n",
    "                if self.is_expanding:\n",
    "                    start = 0\n",
    "                else:\n",
    "                    start = mid\n",
    "                mid = mid + self.train_size                \n",
    "            stop = mid + self.test_size\n",
    "            if start >= n_records or mid >= n_records or stop > n_records:\n",
    "                break\n",
    "            else:\n",
    "                n_splits += 1\n",
    "        return n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_records = int(len(X))\n",
    "        indices = np.arange(n_records)\n",
    "\n",
    "        margin = 0 # Gap between train and test data\n",
    "        start = 0\n",
    "        mid = None\n",
    "        stop = None\n",
    "        while True:\n",
    "            if mid is None:\n",
    "                mid = start + self.train_size\n",
    "            elif mid is not None:\n",
    "                if self.is_expanding:\n",
    "                    start = 0\n",
    "                else:\n",
    "                    start = mid\n",
    "                mid = mid + self.train_size                \n",
    "            stop = mid + self.test_size\n",
    "            if start >= n_records or mid >= n_records or stop > n_records:\n",
    "                break\n",
    "            else:\n",
    "                # print(start, mid, stop)\n",
    "                yield indices[start: mid], indices[mid + margin: stop]\n",
    "\n",
    "class BalancedSparseCategoricalAccuracy(tf.keras.metrics.BinaryAccuracy):\n",
    "    def __init__(self, name='balanced_accuracy', dtype=None):\n",
    "        super().__init__(name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_flat = y_true\n",
    "        if y_true.shape.ndims == y_pred.shape.ndims:\n",
    "            y_flat = tf.squeeze(y_flat, axis=[-1])\n",
    "        y_true_int = tf.cast(y_flat, tf.int32)\n",
    "\n",
    "        cls_counts = tf.math.bincount(y_true_int)\n",
    "        cls_counts = tf.math.reciprocal_no_nan(tf.cast(cls_counts, self.dtype))\n",
    "        weight = tf.gather(cls_counts, y_true_int)\n",
    "        # print(weight)\n",
    "        return super().update_state(y_true, y_pred, sample_weight=weight)\n",
    "\n",
    "def plot_cv_indices(cv, X, y, ax, n_splits=0, lw=20):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                    c=indices, marker='_', lw=lw, cmap=plt.cm.coolwarm,\n",
    "                    vmin=-.2, vmax=1.2)\n",
    "\n",
    "    n_splits = ii + 1\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X), c=y, marker='_', lw=lw, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['wearing-off']\n",
    "    ax.set(yticks=np.arange(n_splits+1) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Records\\'s Index', ylabel=\"Folds\",\n",
    "           ylim=[n_splits+1.2, -.2], xlim=[0, len(X)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax\n",
    "\n",
    "def visualize_cv_split(cv, df, save_to_path=None):\n",
    "    cmap_data = plt.cm.Paired\n",
    "    cmap_cv = plt.cm.coolwarm\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    # outer cv\n",
    "    plot_cv_indices(cv, df.iloc[:, 0:-1].values, df.iloc[:, -1:].values, ax)\n",
    "    plt.rc('text') # , usetex=False)\n",
    "    plt.rc('font', family='serif')\n",
    "    plt.title('Walk Forward Validation')\n",
    "    if save_to_path:\n",
    "        plt.savefig('./cv_split.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_wearing_offs(df):\n",
    "    # Fix timestamp format\n",
    "    date_time = pd.to_datetime(df.index, format='%d.%m.%Y %H:%M:%S')\n",
    "    \n",
    "    plot_cols = df.columns\n",
    "    plot_features = df[plot_cols]\n",
    "    plot_features.index = date_time\n",
    "    i = 1\n",
    "    # plot each column\n",
    "    plt.figure(figsize=(25,10))\n",
    "    for group in plot_cols:\n",
    "        if group == 'wearing_off':\n",
    "            continue\n",
    "        ax = plt.subplot(len(plot_cols), 1, i)\n",
    "        plt.fill_between(\n",
    "            plot_features.index, 0, plot_features.loc[:, [group]].max(), where=plot_features.wearing_off, alpha=0.4, color=\"red\", transform=ax.get_xaxis_transform()\n",
    "        )\n",
    "        plt.plot(plot_features.loc[:, [group]])\n",
    "        plt.title(group, y=0.5, loc='right')\n",
    "        i += 1\n",
    "    plt.suptitle(f'Input features with wearing-off periods for Participant {user.replace(\"participant\", \"\")}')\n",
    "    # plt.savefig(f'./results/{user}_wearing_off.pdf')\n",
    "    plt.show()\n",
    "\n",
    "def split_train_validation_test_set(df, test_set_size=1, validation_percentage=0.2):\n",
    "    test_size = record_size_per_day * test_set_size\n",
    "    test_set = df.tail(test_size).copy()\n",
    "    total_rows = len(df) - test_size\n",
    "    training_end_index = int(total_rows - total_rows * validation_percentage)\n",
    "    validation_end_index = int(total_rows)    \n",
    "    \n",
    "    train_df = df.iloc[0:training_end_index].copy()\n",
    "    validation_df = df.iloc[training_end_index:validation_end_index].copy()\n",
    "    return train_df, validation_df, test_set\n",
    "\n",
    "# features to normalize\n",
    "# timestamp_dayofweek, wearing_off were not normalized\n",
    "normalize_features = ['heart_rate', 'steps', 'stress_score', 'awake', 'deep', \n",
    "                      'light', 'rem', 'nonrem_total', 'total', 'nonrem_percentage',\n",
    "                      'sleep_efficiency', 'timestamp_hour_sin', 'timestamp_hour_cos']\n",
    "def normalize_data(df, mean, std, normalize_features=normalize_features):\n",
    "    df_to_normalize = df.copy()\n",
    "    df_to_normalize.loc[:, normalize_features] = ((\n",
    "        df_to_normalize.loc[:, normalize_features] - mean\n",
    "    ) / std)\n",
    "    \n",
    "    return df_to_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46480bf1-2b36-4dd3-8428-41b87a18633c",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a2ed0d7-65a5-432d-9a21-19c362b41d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 08:44:36.696459: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-08 08:44:36.696539: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-08 08:44:36.696586: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0.0.0.0): /proc/driver/nvidia/version does not exist\n",
      "2023-02-08 08:44:36.697058: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "user = 'participant12'\n",
    "interval = '15min'\n",
    "\n",
    "columns = [ 'timestamp', 'heart_rate', 'steps', 'stress_score',\n",
    "            'awake', 'deep', 'light', 'rem', \n",
    "           'nonrem_total', 'total', 'nonrem_percentage', 'sleep_efficiency']\n",
    "\n",
    "# Include FonLog data\n",
    "# columns += ['time_from_last_drug_taken'] #, 'wo_duration']\n",
    "\n",
    "# Additional data\n",
    "columns += ['timestamp_dayofweek', 'timestamp_hour_sin', 'timestamp_hour_cos']\n",
    "\n",
    "# 'wearing_off' | 'wearing_off_post_meds' | 'wearing_off_lead60'\n",
    "target_column = 'wearing_off' \n",
    "columns.append(target_column)\n",
    "\n",
    "participant_dictionary = json.load(open(f'./data/participant_dictionary.json'))\n",
    "\n",
    "# CV splits\n",
    "if interval == '15min':\n",
    "    record_size_per_day = 96\n",
    "elif interval == '15s':\n",
    "    record_size_per_day = 5760\n",
    "elif interval == '1min':\n",
    "    record_size_per_day = 1440\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "      # tfa.metrics.F1Score(num_classes=2, name='f1_score', threshold=0.5),\n",
    "      BalancedSparseCategoricalAccuracy(),\n",
    "      BalancedAccuracy()]\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "MAX_EPOCHS = 200\n",
    "LEARNING_RATE = 1e-3\n",
    "SHIFT = 4\n",
    "USE_HOURLY = False\n",
    "SAVEFIG = True\n",
    "EXPERIMENT_NAME = 'with wearing-off'\n",
    "REMOVE_WEARING_OFF_IN_PREVIOUS_STEP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf70dd5-ea4c-48b6-abb9-04757b4790f4",
   "metadata": {},
   "source": [
    "## WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54639ff7-165c-411d-9cf8-1c0a737e07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                 train_df, test_df, validation_df=None,\n",
    "                 label_columns=None):\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.validation_df = validation_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the target label column indices.\n",
    "        # Example: { 'wearing_off': 0 }\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "          self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        # input column indices\n",
    "        # Example: { 'heart_rate': 0 , 'stress_score': 1 }\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                               enumerate(train_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "\n",
    "    def split_window(self, features, remove_target_column_from_input=True):\n",
    "        if remove_target_column_from_input:\n",
    "            number_of_columns = self.column_indices.copy().pop('wearing_off')\n",
    "            inputs = features[:, self.input_slice, :number_of_columns] # without wearing-off\n",
    "        else:\n",
    "            inputs = features[:, self.input_slice, :]   # with wearing-off\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def make_dataset(self, data, remove_target_column_from_input=True):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=False,\n",
    "            seed=4,\n",
    "            batch_size=BATCH_SIZE,).shuffle(seed=4, buffer_size=10000)\n",
    "            # .shuffle(buffer_size=10000)\n",
    "\n",
    "        ds = ds.map(lambda d: self.split_window(d, remove_target_column_from_input))\n",
    "\n",
    "        return ds\n",
    "    \n",
    "    def train(self, remove_target_column_from_input=True):\n",
    "        return self.make_dataset(\n",
    "            self.train_df, \n",
    "            remove_target_column_from_input=remove_target_column_from_input)\n",
    "\n",
    "    def validation(self, remove_target_column_from_input=True):\n",
    "        return self.make_dataset(\n",
    "            self.validation_df, \n",
    "            remove_target_column_from_input=remove_target_column_from_input)\n",
    "\n",
    "    def test(self, remove_target_column_from_input=True):\n",
    "        return self.make_dataset(\n",
    "            self.test_df, \n",
    "            remove_target_column_from_input=remove_target_column_from_input)\n",
    "\n",
    "    def sample(self, remove_target_column_from_input=True):\n",
    "        sample_dataset = self.make_dataset(\n",
    "            self.train_df,\n",
    "            remove_target_column_from_input=remove_target_column_from_input)\n",
    "        result = next(iter(sample_dataset))\n",
    "        return result\n",
    "    \n",
    "    def plot(self, model=None, plot_col='wearing_off', max_subplots=3, \n",
    "             remove_target_column_from_input=True, override=False):\n",
    "        inputs, labels = self.sample(remove_target_column_from_input=False)\n",
    "        if override:\n",
    "            inputs_for_prediction = inputs\n",
    "        else:\n",
    "            if remove_target_column_from_input:\n",
    "                number_of_columns = self.column_indices.copy().pop('wearing_off')\n",
    "                inputs_for_prediction = inputs[:,:, :number_of_columns]\n",
    "            else:\n",
    "                inputs_for_prediction = inputs\n",
    "        \n",
    "        fig = plt.figure(figsize=(25,10))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        for n in range(max_n):\n",
    "            ax = plt.subplot(max_n, 1, n+1)\n",
    "            if n == 1:\n",
    "                plt.ylabel(f'{plot_col} [normed]')\n",
    "            plt.ylim(-0.1,1.1)\n",
    "            ax.set_yticks(\n",
    "                [0.0, 0.5, 1.0]\n",
    "            )\n",
    "            ax.set_xticks([])\n",
    "            if n == 2:\n",
    "                ax.set_xticks(\n",
    "                    np.append(self.input_indices[::SHIFT], self.input_indices[-1] + 1),\n",
    "                    list(range(0, len( self.input_indices[::SHIFT] ) + 1 )),\n",
    "                    minor=True\n",
    "                )\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "                label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "\n",
    "            plt.scatter(self.label_indices[::SHIFT], labels[n, :, label_col_index][::SHIFT],\n",
    "                        edgecolors='k', label='Labels', c='#2ca02c', s=64*4)\n",
    "            if model is not None:\n",
    "                predictions = model(inputs_for_prediction)\n",
    "                plt.scatter(self.label_indices[::SHIFT], predictions[n, :, label_col_index][::SHIFT],\n",
    "                            marker='X', edgecolors='k', label='Predictions',\n",
    "                            c='#ff7f0e', s=64*4)\n",
    "            if n == 2:\n",
    "                # Put a legend below current axis\n",
    "                plt.legend(loc='upper center', bbox_to_anchor=(0.5, 0.025),\n",
    "                           bbox_transform=fig.transFigure,\n",
    "                          fancybox=True, shadow=True, ncol=3)\n",
    "                # plt.legend()\n",
    "                \n",
    "        plt.xlabel('Time [h]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc6fbb0-1fe0-46b8-8b4e-2c28d26d6685",
   "metadata": {},
   "source": [
    "## Compile and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "302c7982-13f7-43a5-9e96-8045ede73cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossAndErrorPrintingCallback(keras.callbacks.Callback):\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print(\n",
    "            \"Up to batch {}, the average balanced accuracy is {:7.2f}.\".format(batch, logs[\"balanced_accuracy\"])\n",
    "        )\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        print(\n",
    "            \"Up to batch {}, the average balanced accuracy is {:7.2f}.\".format(batch, logs[\"balanced_accuracy\"])\n",
    "        )\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\n",
    "            \"The average balanced_accuracy for epoch {} is {:7.2f} \"\n",
    "            \"and mean accuracy is {:7.2f}.\".format(\n",
    "                epoch, logs[\"balanced_accuracy\"], logs[\"accuracy\"]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80f0ee9-adfc-4da3-8983-6b7d425407a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compile_and_fit(model, window, patience=10, experiment_name=EXPERIMENT_NAME, remove_target_column_from_input=True):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_prc',\n",
    "    #                                                   verbose=1,\n",
    "    #                                                   patience=patience,\n",
    "    #                                                   mode='max',\n",
    "    #                                                   restore_best_weights=True)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=patience,\n",
    "                                                      mode='min',\n",
    "                                                      restore_best_weights=True)\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'logs/{experiment_name}/{timestamp}/{model.name}',\n",
    "                                                 histogram_freq=0,\n",
    "                                                 write_graph=True,\n",
    "                                                 write_images=False,\n",
    "                                                 write_steps_per_second=False,\n",
    "                                                 update_freq=\"epoch\",\n",
    "                                                 profile_batch=0)\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                metrics=METRICS)\n",
    "\n",
    "    history = model.fit(window.train(remove_target_column_from_input), epochs=MAX_EPOCHS,\n",
    "                        validation_data=window.validation(remove_target_column_from_input),\n",
    "                        callbacks=[tensorboard, early_stopping], verbose=1)\n",
    "                      # callbacks=[tensorboard, early_stopping, LossAndErrorPrintingCallback()], verbose=0)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff8ff17-9b02-4b1e-9a79-ba4eb19b15f1",
   "metadata": {},
   "source": [
    "## Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56be5422-8c49-47c7-876c-3ba93da4517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history, model, savefig=False):\n",
    "    FORMAT = 'pdf'\n",
    "    metrics = ['loss', 'balanced_accuracy', 'auc', 'prc', 'precision', 'recall']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(3,3,n+1)\n",
    "        plt.plot(history.epoch, history.history[metric], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric], label='Validation')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "          plt.ylim([0, plt.ylim()[1]])\n",
    "        # elif metric == 'auc':\n",
    "        #   plt.ylim([0.8,1])\n",
    "        else:\n",
    "          plt.ylim([0,1])\n",
    "        plt.legend();\n",
    "    if savefig:\n",
    "        plt.savefig(f'./results/metrics/{user}_learning_curve_{model.name}.{FORMAT}', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fpr, tpr, thresholds = roc_curve(labels, predictions)\n",
    "\n",
    "    plt.plot([0,1], [0,1], linestyle='--')\n",
    "    plt.plot(fpr, tpr, marker='.', label=name)\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate [%]')\n",
    "    plt.ylabel('True Positive Rate [%]')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_prc(name, labels, predictions, **kwargs):\n",
    "    precision, recall, thresholds = precision_recall_curve(labels, predictions)\n",
    "\n",
    "    no_skill = len(labels[labels==1]) / len(labels)\n",
    "    plt.plot([0,1], [no_skill,no_skill], linestyle='--')\n",
    "    plt.plot(recall, precision, marker='.', label=name)\n",
    "    # axis labels\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "\n",
    "def plot_cm(model, single_window, wide_window, history=None, override=False, savefig=False, remove_target_column_from_input=True):\n",
    "    FORMAT = 'pdf'\n",
    "    \n",
    "    # confusion matrix\n",
    "    font = {'size': 20}\n",
    "            # 'family' : 'normal',\n",
    "            # 'weight' : 'bold',\n",
    "    mpl.rc('font', **font)\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for input, label in single_window.test(remove_target_column_from_input=remove_target_column_from_input):\n",
    "        output = model(input).numpy()\n",
    "        predictions += list(output.reshape( output.shape[0] ))\n",
    "        \n",
    "        l = label.numpy()\n",
    "        labels += list(l.reshape( l.shape[0] ))\n",
    "    predictions = np.array(predictions)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    THRESHOLD = 0.5\n",
    "    cm = confusion_matrix(labels.reshape(labels.shape[0]),\n",
    "                          predictions.reshape(predictions.shape[0]) > THRESHOLD)\n",
    "    cm_normalized = confusion_matrix(labels.reshape(labels.shape[0]),\n",
    "                     predictions.reshape(predictions.shape[0]) > THRESHOLD,\n",
    "                     normalize='all') * 100\n",
    "\n",
    "    if 1.0 in labels:\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                      display_labels=['normal', 'wearing-off'])\n",
    "    else:\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    \n",
    "    disp.plot()\n",
    "    plt.title(f'Confusion matrix for Participant {user.replace(\"participant\", \"\")} using {model.name}')\n",
    "    if savefig:\n",
    "        plt.savefig(f'./results/confusion_matrix/{user}_confusion_matrix_{model.name}.{FORMAT}', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_results(model, single_window, wide_window, history=None, override=False, savefig=False, remove_target_column_from_input=True):\n",
    "    FORMAT = 'PNG'\n",
    "    \n",
    "    # sample predictions\n",
    "    # sample predictions\n",
    "    font = {'size': 30}\n",
    "            # 'family' : 'normal',\n",
    "            # 'weight' : 'bold',\n",
    "    mpl.rc('font', **font)\n",
    "    \n",
    "    wide_window.plot(model, remove_target_column_from_input=remove_target_column_from_input)\n",
    "    plt.suptitle(f'Sample forecasting for Participant {user.replace(\"participant\", \"\")} using {model.name}')\n",
    "    if savefig:\n",
    "        plt.savefig(f'./results/sample_predictions/{user}_sample_prediction_{model.name}.{FORMAT}', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # learning curve\n",
    "    if history is not None:\n",
    "        plt.plot(history.history['loss'], label='Train')\n",
    "        plt.plot(history.history['val_loss'], label='Validation')\n",
    "        plt.title(f'Learning Curve Loss for Participant {user.replace(\"participant\", \"\")} using {model.name}')\n",
    "        plt.legend()\n",
    "        if savefig:\n",
    "            plt.savefig(f'./results/learning_curve/{user}_learning_curve_{model.name}.{FORMAT}', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        # metrics\n",
    "        plot_metrics(history, model=model, savefig=savefig)\n",
    "\n",
    "    # confusion matrix\n",
    "    font = {'size': 20}\n",
    "            # 'family' : 'normal',\n",
    "            # 'weight' : 'bold',\n",
    "    mpl.rc('font', **font)\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for input, label in single_window.test(remove_target_column_from_input=remove_target_column_from_input):\n",
    "        output = model(input).numpy()\n",
    "        predictions += list(output.reshape( output.shape[0] ))\n",
    "        \n",
    "        l = label.numpy()\n",
    "        labels += list(l.reshape( l.shape[0] ))\n",
    "    predictions = np.array(predictions)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    THRESHOLD = 0.5\n",
    "    cm = confusion_matrix(labels.reshape(labels.shape[0]),\n",
    "                          predictions.reshape(predictions.shape[0]) > THRESHOLD)\n",
    "    cm_normalized = confusion_matrix(labels.reshape(labels.shape[0]),\n",
    "                     predictions.reshape(predictions.shape[0]) > THRESHOLD,\n",
    "                     normalize='all') * 100\n",
    "\n",
    "    if 1.0 in labels:\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                      display_labels=['normal', 'wearing-off'])\n",
    "    else:\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    \n",
    "    disp.plot()\n",
    "    plt.title(f'Confusion matrix for Participant {user.replace(\"participant\", \"\")} using {model.name}')\n",
    "    if savefig:\n",
    "        plt.savefig(f'./results/confusion_matrix/{user}_confusion_matrix_{model.name}.{FORMAT}', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC\n",
    "    plot_roc(model.name, labels, predictions)\n",
    "    \n",
    "    plot_prc(model.name, labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aedf5aae-2165-454c-8b4a-ad509b60bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    var_names = data.columns\n",
    "    n_vars = len(var_names)\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()    # new column values, new columne names\n",
    "    \n",
    "    # input sequence (t-i, ... t-1)\n",
    "    # timesteps before (e.g., n_in = 3, t-3, t-2, t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += list(\n",
    "            map(lambda var_name: f'{var_name}(t-{i})', var_names)\n",
    "        )\n",
    "        \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    # timesteps after (e.g., n_out = 3, t, t+1, t+2)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += list( map(lambda var_name: f'{var_name}(t)', var_names) )\n",
    "        else:\n",
    "            names += list( map(lambda var_name: f'{var_name}(t+{i})', var_names) )\n",
    "\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a4665-139d-48f3-acb1-923905aa89d5",
   "metadata": {},
   "source": [
    "# Load & process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11879e6b-b6a4-4a7b-8679-68fda09ac128",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(f'./data/4-combined_data_{user}_{interval}.xlsx',\n",
    "                              index_col=\"timestamp\",\n",
    "                              usecols=columns,\n",
    "                              engine='openpyxl')\n",
    "# Fill missing data with 0\n",
    "dataset.fillna(0, inplace=True)\n",
    "\n",
    "# Filter data based on participants' dictionary\n",
    "dataset = dataset.loc[\n",
    "    (dataset.index >= participant_dictionary[user]['start_date']) &\n",
    "    (dataset.index < participant_dictionary[user]['end_date_plus_two'])\n",
    "]\n",
    "\n",
    "column_indices = { name: i for i, name in enumerate(dataset.columns) }\n",
    "df = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7505c3ed-33dd-4e9a-b131-37a8aab0b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(df[target_column])\n",
    "total = neg + pos\n",
    "initial_bias = np.log([pos/neg])\n",
    "output_bias = tf.keras.initializers.Constant(initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13cb7aa9-fe0d-4ca3-9e4e-5a68240c2656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.50\n",
      "Weight for class 1: 600.00\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04148fb3-f4f3-4985-b840-b12e17bc2563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4796\n",
      "1       4\n",
      "Name: wearing_off, dtype: int64\n",
      "0    0.999167\n",
      "1    0.000833\n",
      "Name: wearing_off, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'wearing_off'}>]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df[target_column].value_counts(normalize=False))\n",
    "print(df[target_column].value_counts(normalize=True))\n",
    "df.hist(column=target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec55fcda-6b33-493b-9783-2787bf2e83e4",
   "metadata": {},
   "source": [
    "## Slice to get hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f02d783-965f-4a21-add0-028e5067c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_HOURLY:\n",
    "    # Slice [start:stop:step], starting from index 0, take every 4 record\n",
    "    # Take every hour record only\n",
    "    df = dataset[::SHIFT].copy() \n",
    "\n",
    "    # Fix columns arrangement\n",
    "    dataset = dataset.reindex(columns=columns[1:])\n",
    "\n",
    "    record_size_per_day = 24\n",
    "    SHIFT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc0676-cbaf-41d3-b58c-143eb9a52fe5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03aa566-5e99-4bef-a45c-e244eaae3de8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3690a4f-9276-49b4-8217-21fd421a77b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 50.0 days\n",
      "0    99.917\n",
      "1     0.083\n",
      "Name: wearing_off, dtype: float64\n",
      "\n",
      "Training data: 30.0 days\n",
      "0    99.861\n",
      "1     0.139\n",
      "Name: wearing_off, dtype: float64\n",
      "\n",
      "Validation data: 10.0 days\n",
      "0    100.0\n",
      "Name: wearing_off, dtype: float64\n",
      "\n",
      "Test data: 10.0 days\n",
      "0    100.0\n",
      "Name: wearing_off, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# training data 60% \n",
    "TRAINING_PERCENTAGE = 0.6\n",
    "# validation data 20%\n",
    "VALIDATION_PERCENTAGE = 0.2\n",
    "\n",
    "column_indices = { name: i for i, name in enumerate(df.columns) }\n",
    "total_rows = len(df)\n",
    "num_features = len(df.columns)\n",
    "\n",
    "training_end_index = int(total_rows * TRAINING_PERCENTAGE)\n",
    "validation_end_index = int(total_rows * (TRAINING_PERCENTAGE + VALIDATION_PERCENTAGE))\n",
    "\n",
    "train_df = df[0:training_end_index].copy()\n",
    "validation_df = df[training_end_index:validation_end_index].copy()\n",
    "test_df = df[validation_end_index:].copy()\n",
    "\n",
    "print(f\"Total data: {round(len(df)/record_size_per_day, 3)} days\")\n",
    "print( ( df.wearing_off.value_counts(normalize=True) * 100 ).round(3) )\n",
    "print()\n",
    "print(f\"Training data: {round(len(train_df)/record_size_per_day, 3)} days\")\n",
    "print( ( train_df.wearing_off.value_counts(normalize=True) * 100 ).round(3) )\n",
    "print()\n",
    "print(f\"Validation data: {round(len(validation_df)/record_size_per_day, 3)} days\")\n",
    "print( ( validation_df.wearing_off.value_counts(normalize=True) * 100 ).round(3) )\n",
    "print()\n",
    "print(f\"Test data: {round(len(test_df)/record_size_per_day, 3)} days\")\n",
    "print( ( test_df.wearing_off.value_counts(normalize=True) * 100 ).round(3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d3406-8ffb-47a9-9cb1-408d4dab37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, validation_df, test_df = split_train_validation_test_set(df, \n",
    "#                                                                    test_set_size=1, \n",
    "#                                                                    validation_percentage=0.2)\n",
    "\n",
    "# print(f\"Training data: {round(len(train_df)/record_size_per_day * 1, 3)} days\")\n",
    "# print(f\"Validation data: {round(len(validation_df)/record_size_per_day * 1, 3)} days\")\n",
    "# print(f\"Test data: {round(len(test_df)/record_size_per_day * 1, 3)} days\")\n",
    "# print(f\"Total data: {round(len(df)/record_size_per_day * 1, 3)} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92386aa-6163-47f8-a57b-b424f99b7d20",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f712264-8add-42d4-9cbf-c0d5a2b59b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = train_df.loc[:, normalize_features].mean()\n",
    "train_std = train_df.loc[:, normalize_features].std()\n",
    "\n",
    "train_df = normalize_data(train_df, train_mean, train_std)\n",
    "validation_df = normalize_data(validation_df, train_mean, train_std)\n",
    "test_df = normalize_data(test_df, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d9a40a-4808-4f14-9f76-98dd8fc26de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_standardized = (df.loc[:, normalize_features] - train_mean) / train_std\n",
    "df_standardized = pd.merge(df_standardized, df.iloc[:, -2:], left_index=True,right_index=True)\n",
    "df_standardized = df_standardized.melt(var_name='Columns', value_name='Normalized')\n",
    "plt.figure()\n",
    "ax = sns.violinplot(x='Columns', y='Normalized', data=df_standardized)\n",
    "_ = ax.set_xticklabels(df.keys(), rotation=45)\n",
    "plt.title(\"Distribution of normalized features\")\n",
    "if SAVEFIG:\n",
    "    plt.savefig(f'./results/{user}_distribution_normalized_data.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f8efb-ec1f-440d-ae75-b903116e7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size': 30}\n",
    "        # 'family' : 'normal',\n",
    "        # 'weight' : 'bold',\n",
    "\n",
    "mpl.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194828ce-1b64-4b9a-b88f-a60c5f27af50",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c842b6c-a62a-43d2-ae21-22deec455d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance = {}\n",
    "test_performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566870f-183d-4ca1-86c9-6d86f120886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_window = WindowGenerator(input_width=1, label_width=1, shift=SHIFT,\n",
    "                                     train_df=train_df, test_df=test_df, validation_df=validation_df,\n",
    "                                     label_columns=['wearing_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e60ffa-603c-4198-bde4-cb2cca2d8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_single_step_window = WindowGenerator(input_width=record_size_per_day, label_width=record_size_per_day, shift=SHIFT,\n",
    "                              train_df=train_df, validation_df=validation_df, test_df=test_df,\n",
    "                              label_columns=['wearing_off'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4605131b-eee6-4adc-b681-af8341cc0af4",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e31d52-8c9f-4972-b1f5-1d4f241bd267",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb161d0-55e9-4615-88d0-803b0ffb1e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(label_index=column_indices['wearing_off'], name='Baseline')\n",
    "baseline.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47214425-a868-42b6-a50d-3e5926ac3ce3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_performance[baseline.name] = baseline.evaluate(single_step_window.validation(remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP))\n",
    "test_performance[baseline.name] = baseline.evaluate(single_step_window.test(remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860872f-65cd-41e0-b87e-035a1a79cdd0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_results(baseline, single_step_window, wide_single_step_window, \n",
    "                  history=None, savefig=SAVEFIG,\n",
    "                  override=True,\n",
    "                  remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608be484-bc06-498a-87b5-88ae803d96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(baseline.metrics_names, test_performance[baseline.name]):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b328446-4e9b-41a7-bcdc-e649ca810e04",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aaf04c-0c3b-405c-89d4-a227308bb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\", name=\"output\")\n",
    "], name = \"Linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b21a0-5a19-49ee-942d-8ba5d5424ecd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(linear, single_step_window,\n",
    "                          remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9566aa74-02fa-4ba5-97bc-8366e99a55e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_performance[linear.name] = linear.evaluate(\n",
    "    single_step_window.validation(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP))\n",
    "test_performance[linear.name] = linear.evaluate(\n",
    "    single_step_window.test(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=1,\n",
    "    callbacks=[LossAndErrorPrintingCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d785e1-c1a7-429e-be4b-00cb232001ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance[linear.name] = linear.evaluate(\n",
    "    single_step_window.test(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=0,\n",
    "    callbacks=[LossAndErrorPrintingCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a365dbe-1a23-45e5-938c-e0d6c9fbc8b0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_results(linear, single_step_window, wide_single_step_window, \n",
    "                  history=history, savefig=SAVEFIG,\n",
    "                  override=False,\n",
    "                  remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b965576-e54f-430d-8f6a-ac16da03ba46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, value in zip(linear.metrics_names, test_performance[linear.name]):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f700e2-a80a-45e2-9e09-235d23d880cb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_bin = tf.keras.metrics.BinaryAccuracy()\n",
    "m_bal = BalancedSparseCategoricalAccuracy()\n",
    "m_auc = tf.keras.metrics.AUC()\n",
    "\n",
    "y_trues = []\n",
    "y_preds = []\n",
    "for input, label in single_step_window.test(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP):\n",
    "    y_true = label\n",
    "    y_trues.append(y_true.numpy())\n",
    "    print(f'Label: { [y_t for y_t in y_true.numpy().reshape(y_true.numpy().shape[0]) ]}')\n",
    "    \n",
    "    y_pred = linear(input)\n",
    "    y_preds.append(y_pred.numpy())\n",
    "    print(f'Predictions: {  [y_p for y_p in y_pred.numpy().reshape(y_pred.numpy().shape[0]) ]}')\n",
    "    \n",
    "    THRESHOLD = 0.5\n",
    "    cm = confusion_matrix(y_true.numpy().reshape(y_true.shape[0]),\n",
    "                          y_pred.numpy().reshape(y_pred.shape[0]) > THRESHOLD)\n",
    "    print(cm)\n",
    "    \n",
    "    m_bin.update_state(y_true, y_pred)\n",
    "    m_bal.update_state(y_true, y_pred)\n",
    "    m_auc.update_state(y_true, y_pred)\n",
    "    print(f'bin result: {m_bin.result().numpy()}')\n",
    "    print(f'bal result: {m_bal.result().numpy()}')\n",
    "    print(f'auc result: {m_auc.result().numpy()}')\n",
    "    print()\n",
    "    \n",
    "# y_trues = np.concatenate(y_trues)\n",
    "# y_preds = np.concatenate(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a921d-cfa3-4036-9445-8092b028d484",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846fd503-238e-4f2e-980b-408f16daa1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model):\n",
    "    # if REMOVE_WEARING_OFF_IN_PREVIOUS_STEP:\n",
    "    #     NUM_FEATURES = 14\n",
    "    # else:\n",
    "    NUM_FEATURES = 15\n",
    "    \n",
    "#     # use Kernel SHAP to explain test set predictions\n",
    "#     explainer = shap.KernelExplainer(model, train_df.values)\n",
    "#     shap_values = explainer.shap_values(test_df.values, nsamples=15)\n",
    "\n",
    "#     # plot the SHAP values for the the first instance\n",
    "#     shap.force_plot(explainer.expected_value[0], shap_values[0][0,:], test_df.iloc[0,:NUM_FEATURES], show=False, matplotlib=True)\n",
    "#     plt.savefig(f'./results/feature_importance/{user}_shap_one_sample_{model.name}.pdf', bbox_inches='tight')\n",
    "#     plt.show()\n",
    "\n",
    "#     # TODO: OUTPUT OVERLAPPING\n",
    "#     # shap.plots._waterfall.waterfall_legacy(explainer.expected_value[0], shap_values[0][0], test_df.iloc[0,:NUM_FEATURES], show=False)\n",
    "#     # plt.savefig(f'./results/{user}_shap_one_sample_{model.name}.pdf', bbox_inches='tight')\n",
    "#     # plt.show()\n",
    "\n",
    "#     # TODO: Convert HTML to PDF\n",
    "#     f = shap.force_plot(explainer.expected_value[0], shap_values[0], test_df.iloc[:,:NUM_FEATURES], link=\"logit\", show=False)\n",
    "#     shap.save_html(f'./results/feature_importance/{user}_shap_stacked_samples_{model.name}.html', f)\n",
    "\n",
    "#     # Summary Plot\n",
    "#     f = plt.figure()\n",
    "#     feature_names = [\n",
    "#         a + \": \" + str(b) for a,b in zip(test_df.columns, shap_values[0].mean(0).round(2))\n",
    "#     ]\n",
    "#     shap.summary_plot(shap_values[0], test_df, feature_names=feature_names)\n",
    "#     f.savefig(f'./results/feature_importance/{user}_shap_summary_plot_{model.name}.pdf', bbox_inches='tight')\n",
    "\n",
    "    # Native feature importance\n",
    "    plt.bar(x = range(len(train_df.columns)),\n",
    "            height=model.layers[0].kernel[:,0].numpy())\n",
    "    axis = plt.gca()\n",
    "    axis.set_xticks(range(len(train_df.columns)))\n",
    "    _ = axis.set_xticklabels(train_df.columns, \n",
    "                             rotation=45, fontsize=18, ha='right')\n",
    "    plt.title(f'Feature weights for Participant {user.replace(\"participant\", \"\")} using {model.name} model')\n",
    "    plt.savefig(f'./results/feature_importance/{user}_native_feature_importance_{model.name}.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5292bbf5-2201-4eca-aa80-1da2d78f1ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_feature_importance(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc892223-20a4-425d-a079-0a7d4bed43af",
   "metadata": {},
   "source": [
    "## Single-time-step Dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad18574-d0e5-4dd7-815a-525a25f69745",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "single_time_step_dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid', name=\"output\")\n",
    "], name = \"Single_time_step_Dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e328f2-8b14-4d7f-b1ad-898cb68a2a37",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(single_time_step_dense, single_step_window,\n",
    "                          remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced8dc8-58a0-492d-9384-ee94fb62bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance[single_time_step_dense.name] = single_time_step_dense.evaluate(\n",
    "    single_step_window.validation(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP))\n",
    "test_performance[single_time_step_dense.name] = single_time_step_dense.evaluate(\n",
    "    single_step_window.test(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f2a3d-d333-4775-bbdd-f8737adfc2b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_results(single_time_step_dense, single_step_window, wide_single_step_window,\n",
    "                  history=history, savefig=SAVEFIG,\n",
    "                  override=False,\n",
    "                  remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0956e-aaf5-4cf3-ab11-43721a4a5d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(single_time_step_dense.metrics_names, test_performance[single_time_step_dense.name]):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a06bf4-b029-4525-9537-b2bbde73bf85",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f8f5a6-cabb-4e77-9960-44dcf4fb2347",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_feature_importance(single_time_step_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38335a83-e93c-41ff-b773-b00920deadbc",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bda48c-e17c-461e-8806-1d650e87877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, -1:, self.label_index]\n",
    "        return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbdff94-c0d2-45ad-9a37-a082870727a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline = Baseline(label_index=column_indices['wearing_off'], name='Baseline')\n",
    "history = compile_and_fit(baseline, multi_step_window,\n",
    "                         remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf7106-3d0d-47a8-9a31-e89a2cf0fafd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_performance[baseline.name] = baseline.evaluate(multi_step_window.validation(remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP))\n",
    "test_performance[baseline.name] = baseline.evaluate(multi_step_window.test(remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e98a8-5019-4900-a14f-686a9efc18db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_cm(baseline, multi_step_window, wide_multi_step_window,\n",
    "                  history=history, savefig=SAVEFIG,\n",
    "                  override=False,\n",
    "                  remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f62ac-8487-4f03-a5c6-6e0a4ae779c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(baseline.metrics_names, test_performance[baseline.name]):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070b81c-3cf3-4484-9dd8-80da424ae36c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi-time-step Dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ccb28-3d3e-4632-b839-db8fe8139b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_STEP_WIDTH = record_size_per_day # t0, t1, t2, ..., t24\n",
    "multi_step_window = WindowGenerator(input_width=MULTI_STEP_WIDTH, label_width=1, shift=SHIFT,\n",
    "                                    train_df=train_df, validation_df=validation_df, test_df=test_df,\n",
    "                                    label_columns=['wearing_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dafe16-7bc7-4806-b74f-49c9109cd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "multi_time_step_dense = tf.keras.Sequential([\n",
    "    # Shape: (time, features) => (time*features)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid', name=\"output\"),\n",
    "    # Add back the time dimension.\n",
    "    # Shape: (outputs) => (1, outputs)\n",
    "    tf.keras.layers.Reshape([1, -1]),\n",
    "], name = \"Multi_time_step_Dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c8b3d-7588-4825-a348-d566808aee0d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(multi_time_step_dense, multi_step_window,\n",
    "                          remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca263d70-df90-4812-bcbb-5d32658470f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_performance[multi_time_step_dense.name] = multi_time_step_dense.evaluate(\n",
    "    multi_step_window.validation(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP))\n",
    "test_performance[multi_time_step_dense.name] = multi_time_step_dense.evaluate(\n",
    "    multi_step_window.test(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e52e1-7b4f-440b-bd25-a0fc0e276972",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_results(multi_time_step_dense, multi_step_window, multi_step_window,\n",
    "                  history=history, savefig=SAVEFIG,\n",
    "                  override=False,\n",
    "                  remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59300abe-199c-437d-bdc3-afa16f34349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(multi_time_step_dense.metrics_names, test_performance[multi_time_step_dense.name]):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affabe7d-6fce-4e80-8320-224d656ac74c",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa286ea-1b2a-43c1-bb38-5b50bc1d3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    var_names = data.columns\n",
    "    n_vars = len(var_names)\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()    # new column values, new columne names\n",
    "    \n",
    "    # input sequence (t-i, ... t-1)\n",
    "    # timesteps before (e.g., n_in = 3, t-3, t-2, t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += list(\n",
    "            map(lambda var_name: f'{var_name}(t-{i})', var_names)\n",
    "        )\n",
    "        \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    # timesteps after (e.g., n_out = 3, t, t+1, t+2)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += list( map(lambda var_name: f'{var_name}(t)', var_names) )\n",
    "        else:\n",
    "            names += list( map(lambda var_name: f'{var_name}(t+{i})', var_names) )\n",
    "\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d295c6-6c98-48e3-a111-c755e5eb7a69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature_weights = pd.DataFrame(multi_time_step_dense.layers[1].kernel[:,0].numpy()).T\n",
    "\n",
    "# layer = single_time_step_dense.layers[0].kernel[:,0].numpy()\n",
    "# width = 1\n",
    "model = multi_time_step_dense\n",
    "\n",
    "layer = multi_time_step_dense.layers[1].kernel[:,0].numpy()\n",
    "width = MULTI_STEP_WIDTH\n",
    "\n",
    "feature_weights = pd.DataFrame(layer).T\n",
    "feature_weights.columns = list(series_to_supervised(train_df,\n",
    "                                                    n_in=width, n_out=1\n",
    "                                                   ).columns.drop([\n",
    "                                                    'heart_rate(t)', 'steps(t)', 'stress_score(t)',\n",
    "                                                    'awake(t)', 'deep(t)', 'light(t)', 'rem(t)',\n",
    "                                                    'nonrem_total(t)', 'total(t)', 'nonrem_percentage(t)',\n",
    "                                                    'sleep_efficiency(t)',\n",
    "                                                    'timestamp_hour_sin(t)', 'timestamp_hour_cos(t)', 'timestamp_dayofweek(t)',\n",
    "                                                    'wearing_off(t)']))\n",
    "\n",
    "\n",
    "sorted_idx = feature_weights.values[0].argsort()\n",
    "sorted_idx = np.concatenate([sorted_idx[0:10], sorted_idx[-10:]])\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "plt.barh(range(len(sorted_idx)), feature_weights.values[0][sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(feature_weights.columns)[sorted_idx])\n",
    "plt.ylabel('Features')\n",
    "plt.xlabel('Weights')\n",
    "plt.title('Feature Importance for participant %i' % 6)\n",
    "plt.savefig(f'./results/feature_importance/{user}_native_feature_importance_{model.name}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d778846-30e2-4fa8-9612-bb155f11525d",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb81470-a946-4224-a2ff-e0bc90e50f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_STEP_WIDTH = record_size_per_day # t0, t1, t2, ..., t24\n",
    "multi_step_window = WindowGenerator(input_width=MULTI_STEP_WIDTH, label_width=1, shift=SHIFT,\n",
    "                                    train_df=train_df, validation_df=validation_df, test_df=test_df,\n",
    "                                    label_columns=['wearing_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abe209-930e-40a0-b3e4-93dc71feabae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABEL_WIDTH = 4 * 6 # record_size_per_day\n",
    "INPUT_WIDTH = LABEL_WIDTH + (MULTI_STEP_WIDTH - 1)\n",
    "wide_multi_step_window = WindowGenerator(input_width=INPUT_WIDTH, label_width=LABEL_WIDTH, shift=SHIFT,\n",
    "                                         train_df=train_df, validation_df=validation_df, test_df=test_df,\n",
    "                                         label_columns=['wearing_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe30c5-c1df-40fb-ba23-b6f0d35f4ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "cnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=64,\n",
    "                           kernel_size=(MULTI_STEP_WIDTH,),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid', name=\"output\"),\n",
    "], name = \"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1405b102-1257-4f50-b4a4-adc9a69fbff0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(cnn_model, multi_step_window,\n",
    "                         remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853f2b97-b50a-47d0-a9e3-583b46bb29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance[cnn_model.name] = cnn_model.evaluate(\n",
    "    multi_step_window.validation(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP))\n",
    "test_performance[cnn_model.name] = cnn_model.evaluate(\n",
    "    multi_step_window.test(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6617c2-8b08-4cdd-bcf1-0c68d3ad0aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ORIGINAL: visualize_results(cnn_model, multi_step_window, wide_multi_step_window,\n",
    "#  but not working\n",
    "visualize_results(cnn_model, multi_step_window, wide_multi_step_window,\n",
    "                  history=history, savefig=SAVEFIG,\n",
    "                  override=False,\n",
    "                  remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262fdb7-0e84-4a89-b7f8-136d35e4dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(cnn_model.metrics_names, test_performance[cnn_model.name]):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e0979-dce8-42df-908d-72dbf27eae7f",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ba522-84ab-4cd2-99af-def5f9dea5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights.values[0][sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8fc014-a3aa-4437-b585-f518a4d2ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = cnn_model.layers[0].kernel.numpy().reshape(96*15, 64)\n",
    "width = MULTI_STEP_WIDTH\n",
    "\n",
    "feature_weights = pd.DataFrame(layer).T\n",
    "feature_weights.columns = list(series_to_supervised(train_df,\n",
    "                                                    n_in=width, n_out=1\n",
    "                                                   ).columns.drop([\n",
    "                                                    'heart_rate(t)', 'steps(t)', 'stress_score(t)',\n",
    "                                                    'awake(t)', 'deep(t)', 'light(t)', 'rem(t)',\n",
    "                                                    'nonrem_total(t)', 'total(t)', 'nonrem_percentage(t)',\n",
    "                                                    'sleep_efficiency(t)',\n",
    "                                                    'timestamp_hour_sin(t)', 'timestamp_hour_cos(t)', 'timestamp_dayofweek(t)',\n",
    "                                                    'wearing_off(t)']))\n",
    "\n",
    "\n",
    "sorted_idx = feature_weights.values[0].argsort()\n",
    "sorted_idx = np.concatenate([sorted_idx[0:10], sorted_idx[-10:]])\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "plt.barh(range(len(sorted_idx)), feature_weights.values[0][sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(feature_weights.columns)[sorted_idx])\n",
    "plt.ylabel('Features')\n",
    "plt.xlabel('Weights')\n",
    "plt.title('Feature Importance for participant %i' % 6)\n",
    "# plt.savefig(f'./results/feature_importance/{user}_native_feature_importance_{model.name}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaea1cd-cf44-4f21-811f-e30a055e2146",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea45e6a4-7113-403d-a1b8-3c18b98969b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(16, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid', name=\"output\")\n",
    "], name = \"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc62ff2e-90ce-4bf9-b7e0-619081af130d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(lstm_model, wide_single_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb96f78-47ed-4dfb-ab15-eaea93a4e89d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_performance[lstm_model.name] = lstm_model.evaluate(\n",
    "    wide_single_step_window.validation(not REMOVE_WEARING_OFF_IN_PREVIOUS_STEP))\n",
    "test_performance[lstm_model.name] = lstm_model.evaluate(\n",
    "    wide_single_step_window.test(not REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c67a2f-c56e-4302-ac8f-a47088c37da3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_results(lstm_model, single_step_window, wide_single_step_window, \n",
    "                  history=history, override=not REMOVE_WEARING_OFF_IN_PREVIOUS_STEP,\n",
    "                  savefig=SAVEFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69a1c4-938e-408f-bc94-562347f75db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(lstm_model.metrics_names, test_performance[lstm_model.name]):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75383335-8f27-4256-88ee-a355a036cf82",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c0d656-3634-4596-84a8-b882d2380a87",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "FORMAT = 'png'\n",
    "\n",
    "x = np.arange(len(test_performance))\n",
    "width = 0.3\n",
    "\n",
    "for metric_name in ['loss'] + list(map(lambda m: m.name, METRICS)):\n",
    "    # metric_name = 'auc'\n",
    "    metric_index = lstm_model.metrics_names.index(metric_name)\n",
    "    validation_accuracy = [v[metric_index] for v in validation_performance.values()]\n",
    "    test_accuracy = [v[metric_index] for v in test_performance.values()]\n",
    "\n",
    "    plt.ylabel(f'{metric_name} [wearing_off, normalized]')\n",
    "    plt.bar(x - 0.17, validation_accuracy, width, label='Validation')\n",
    "    plt.bar(x + 0.17, test_accuracy, width, label='Test')\n",
    "    plt.xticks(ticks=x, labels=test_performance.keys(),\n",
    "               rotation=45)\n",
    "    _ = plt.legend()\n",
    "    plt.title(f'Test Performance ({metric_name.upper()}) for Participant {user.replace(\"participant\", \"\")} on varying models')\n",
    "    plt.savefig(f'./results/performance/test_performance_{user}_{metric_name}.{FORMAT}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75351e8-118b-4d32-a531-7d9448807d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_perf = pd.DataFrame(validation_performance,\n",
    "             index = ['loss'] + list(map(lambda m: m.name, METRICS))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c05343-160b-494f-884a-b1aedfe7f10e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_perf = pd.DataFrame(test_performance,\n",
    "             index = ['loss'] + list(map(lambda m: m.name, METRICS))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96fe7b2-8a5f-48b4-93e8-6599dde89c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_perf['participant'] = user\n",
    "val_perf['set'] = 'validation'\n",
    "\n",
    "test_perf['participant'] = user\n",
    "test_perf['set'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4437c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_performance = pd.concat([val_perf, test_perf])\n",
    "final_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2e115-3f91-439f-9d81-51855cf488e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_performance = pd.concat([val_perf, test_perf])\n",
    "if os.path.exists(f'./results/final_performance.xlsx'):\n",
    "    with pd.ExcelWriter(f'./results/final_performance.xlsx', engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "        final_performance.to_excel(writer, startrow=writer.sheets['Sheet1'].max_row, header=None)\n",
    "else:\n",
    "    with pd.ExcelWriter(f'./results/final_performance.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "        final_performance.to_excel(writer)\n",
    "final_performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
