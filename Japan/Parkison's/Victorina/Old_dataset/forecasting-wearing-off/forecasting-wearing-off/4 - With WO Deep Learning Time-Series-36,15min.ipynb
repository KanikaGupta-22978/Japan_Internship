{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0437bbe9-9749-4c9e-b556-b4e2399a4b43",
   "metadata": {},
   "source": [
    "# Load libraries, configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f75f41-df13-4157-a93a-1901c3fa5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (25,10)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "np.random.seed(0)\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "# shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20049a-9d7f-435a-8b2f-9b7d32781b37",
   "metadata": {},
   "source": [
    "# Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1eb82-ffea-4fb6-965b-37a7c04d6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedAccuracy(tf.keras.metrics.Metric):\n",
    "\n",
    "  def __init__(self, name='sklearn_balanced_accuracy', **kwargs):\n",
    "    super(BalancedAccuracy, self).__init__(name=name, **kwargs)\n",
    "    self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "    self.true_negatives = self.add_weight(name='tn', initializer='zeros')\n",
    "    self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "    self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    y_true = tf.cast(y_true, tf.bool)\n",
    "    y_pred = tf.cast(y_pred, tf.bool)\n",
    "\n",
    "    tp_values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n",
    "    tn_values = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, False))\n",
    "    fp_values = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, True))\n",
    "    fn_values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, False))\n",
    "    \n",
    "    tp_values = tf.cast(tp_values, self.dtype)\n",
    "    tn_values = tf.cast(tn_values, self.dtype)\n",
    "    fp_values = tf.cast(fp_values, self.dtype)\n",
    "    fn_values = tf.cast(fn_values, self.dtype)\n",
    "    \n",
    "    self.true_positives.assign_add(tf.reduce_sum(tp_values))\n",
    "    self.true_negatives.assign_add(tf.reduce_sum(tn_values))\n",
    "    self.false_positives.assign_add(tf.reduce_sum(fp_values))\n",
    "    self.false_negatives.assign_add(tf.reduce_sum(fn_values))\n",
    "\n",
    "  def result(self):\n",
    "    return ( (self.true_positives/(self.true_positives + self.false_negatives)) + (self.true_negatives/(self.true_negatives + self.false_positives)) ) / 2\n",
    "\n",
    "  def reset_state(self):\n",
    "    self.true_positives.assign(0)\n",
    "    self.true_negatives.assign(0)\n",
    "    self.false_positives.assign(0)\n",
    "    self.false_negatives.assign(0)\n",
    "    \n",
    "# m = BalancedAccuracy()\n",
    "# m.update_state([0, 1, 1, 1], [0, 1, 0, 0])\n",
    "# print('Intermediate result:', float(m.result()))\n",
    "\n",
    "# # m.update_state([1, 1, 1, 1], [0, 1, 1, 0])\n",
    "# # print('Final result:', float(m.result()))\n",
    "\n",
    "# # SkLearn / Manual\n",
    "# y_true = [0, 1, 1, 1]\n",
    "# y_pred = [0, 1, 0, 0]\n",
    "# tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "# print(tn, fp, fn, tp)\n",
    "# print(f'Manual {(((tp/(tp + fn)) + (tn/(tn + fp)))/2)}')\n",
    "# print(f'scikit-learn {balanced_accuracy_score(y_true, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6a12c-5711-4efd-8e9c-fcfbba8032aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train size moving window\n",
    "class WindowTimeSeriesSplit():\n",
    "    def __init__(self, train_size, test_size, is_expanding=False):\n",
    "        self.train_size = train_size\n",
    "        self.test_size = test_size\n",
    "        self.is_expanding = is_expanding\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups):\n",
    "        n_splits = 0\n",
    "        \n",
    "        n_records = int(len(X))\n",
    "        indices = np.arange(n_records)\n",
    "\n",
    "        margin = 0 # Gap between train and test data\n",
    "        start = 0\n",
    "        mid = None\n",
    "        stop = None\n",
    "        while True:\n",
    "            if mid is None:\n",
    "                mid = start + self.train_size\n",
    "            elif mid is not None:\n",
    "                if self.is_expanding:\n",
    "                    start = 0\n",
    "                else:\n",
    "                    start = mid\n",
    "                mid = mid + self.train_size                \n",
    "            stop = mid + self.test_size\n",
    "            if start >= n_records or mid >= n_records or stop > n_records:\n",
    "                break\n",
    "            else:\n",
    "                n_splits += 1\n",
    "        return n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_records = int(len(X))\n",
    "        indices = np.arange(n_records)\n",
    "\n",
    "        margin = 0 # Gap between train and test data\n",
    "        start = 0\n",
    "        mid = None\n",
    "        stop = None\n",
    "        while True:\n",
    "            if mid is None:\n",
    "                mid = start + self.train_size\n",
    "            elif mid is not None:\n",
    "                if self.is_expanding:\n",
    "                    start = 0\n",
    "                else:\n",
    "                    start = mid\n",
    "                mid = mid + self.train_size                \n",
    "            stop = mid + self.test_size\n",
    "            if start >= n_records or mid >= n_records or stop > n_records:\n",
    "                break\n",
    "            else:\n",
    "                # print(start, mid, stop)\n",
    "                yield indices[start: mid], indices[mid + margin: stop]\n",
    "\n",
    "class BalancedSparseCategoricalAccuracy(tf.keras.metrics.SparseCategoricalAccuracy):\n",
    "    def __init__(self, name='balanced_accuracy', dtype=None):\n",
    "        super().__init__(name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_flat = y_true\n",
    "        if y_true.shape.ndims == y_pred.shape.ndims:\n",
    "            y_flat = tf.squeeze(y_flat, axis=[-1])\n",
    "        y_true_int = tf.cast(y_flat, tf.int32)\n",
    "\n",
    "        cls_counts = tf.math.bincount(y_true_int)\n",
    "        cls_counts = tf.math.reciprocal_no_nan(tf.cast(cls_counts, self.dtype))\n",
    "        weight = tf.gather(cls_counts, y_true_int)\n",
    "        \n",
    "        return super().update_state(y_true, y_pred, sample_weight=weight)\n",
    "\n",
    "def plot_cv_indices(cv, X, y, ax, n_splits=0, lw=20):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                    c=indices, marker='_', lw=lw, cmap=plt.cm.coolwarm,\n",
    "                    vmin=-.2, vmax=1.2)\n",
    "\n",
    "    n_splits = ii + 1\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X), c=y, marker='_', lw=lw, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['wearing-off']\n",
    "    ax.set(yticks=np.arange(n_splits+1) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Records\\'s Index', ylabel=\"Folds\",\n",
    "           ylim=[n_splits+1.2, -.2], xlim=[0, len(X)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax\n",
    "\n",
    "def visualize_cv_split(cv, df, save_to_path=None):\n",
    "    cmap_data = plt.cm.Paired\n",
    "    cmap_cv = plt.cm.coolwarm\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    # outer cv\n",
    "    plot_cv_indices(cv, df.iloc[:, 0:-1].values, df.iloc[:, -1:].values, ax)\n",
    "    plt.rc('text') # , usetex=False)\n",
    "    plt.rc('font', family='serif')\n",
    "    plt.title('Walk Forward Validation')\n",
    "    if save_to_path:\n",
    "        plt.savefig('./cv_split.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_wearing_offs(df):\n",
    "    # Fix timestamp format\n",
    "    date_time = pd.to_datetime(df.index, format='%d.%m.%Y %H:%M:%S')\n",
    "    \n",
    "    plot_cols = df.columns\n",
    "    plot_features = df[plot_cols]\n",
    "    plot_features.index = date_time\n",
    "    i = 1\n",
    "    # plot each column\n",
    "    plt.figure(figsize=(25,10))\n",
    "    for group in plot_cols:\n",
    "        if group == 'wearing_off':\n",
    "            continue\n",
    "        ax = plt.subplot(len(plot_cols), 1, i)\n",
    "        plt.fill_between(\n",
    "            plot_features.index, 0, plot_features.loc[:, [group]].max(), where=plot_features.wearing_off, alpha=0.4, color=\"red\", transform=ax.get_xaxis_transform()\n",
    "        )\n",
    "        plt.plot(plot_features.loc[:, [group]])\n",
    "        plt.title(group, y=0.5, loc='right')\n",
    "        i += 1\n",
    "    plt.suptitle(f'Input features with wearing-off periods for Participant {user.replace(\"participant\", \"\")}')\n",
    "    # plt.savefig(f'./results/{user}_wearing_off.pdf')\n",
    "    plt.show()\n",
    "\n",
    "def split_train_validation_test_set(df, test_set_size=1, validation_percentage=0.2):\n",
    "    test_size = record_size_per_day * test_set_size\n",
    "    test_set = df.tail(test_size).copy()\n",
    "    total_rows = len(df) - test_size\n",
    "    training_end_index = int(total_rows - total_rows * validation_percentage)\n",
    "    validation_end_index = int(total_rows)    \n",
    "    \n",
    "    train_df = df.iloc[0:training_end_index].copy()\n",
    "    validation_df = df.iloc[training_end_index:validation_end_index].copy()\n",
    "    return train_df, validation_df, test_set\n",
    "\n",
    "# features to normalize\n",
    "# timestamp_dayofweek, wearing_off were not normalized\n",
    "normalize_features = ['heart_rate', 'steps', 'stress_score', 'awake', 'deep', \n",
    "                      'light', 'rem', 'nonrem_total', 'total', 'nonrem_percentage',\n",
    "                      'sleep_efficiency', 'timestamp_hour_sin', 'timestamp_hour_cos']\n",
    "def normalize_data(df, mean, std, normalize_features=normalize_features):\n",
    "    df_to_normalize = df.copy()\n",
    "    df_to_normalize.loc[:, normalize_features] = ((\n",
    "        df_to_normalize.loc[:, normalize_features] - mean\n",
    "    ) / std)\n",
    "    \n",
    "    return df_to_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f96e6-19a8-42fc-bc7b-5bd7c4175e30",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ed0d7-65a5-432d-9a21-19c362b41d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user = 'participant6'\n",
    "interval = '15min'\n",
    "\n",
    "columns = [ 'timestamp', 'heart_rate', 'steps', 'stress_score',\n",
    "            'awake', 'deep', 'light', 'rem', \n",
    "           'nonrem_total', 'total', 'nonrem_percentage', 'sleep_efficiency']\n",
    "\n",
    "# Include FonLog data\n",
    "# columns += ['time_from_last_drug_taken'] #, 'wo_duration']\n",
    "\n",
    "# Additional data\n",
    "columns += ['timestamp_dayofweek', 'timestamp_hour_sin', 'timestamp_hour_cos']\n",
    "\n",
    "# 'wearing_off' | 'wearing_off_post_meds' | 'wearing_off_lead60'\n",
    "target_column = 'wearing_off' \n",
    "columns.append(target_column)\n",
    "\n",
    "participant_dictionary = json.load(open(f'./data/participant_dictionary.json'))\n",
    "\n",
    "# CV splits\n",
    "if interval == '15min':\n",
    "    record_size_per_day = 96\n",
    "elif interval == '15s':\n",
    "    record_size_per_day = 5760\n",
    "elif interval == '1min':\n",
    "    record_size_per_day = 1440\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "      BalancedSparseCategoricalAccuracy(),\n",
    "      BalancedAccuracy()]\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "MAX_EPOCHS = 200\n",
    "LEARNING_RATE = 1e-3\n",
    "SHIFT = 4 # 1 = 15 min, 2 = 30 min, 4 = 1 hour\n",
    "MULTI_STEP_WIDTH = record_size_per_day # 36 # input 36 = 9 hours\n",
    "USE_HOURLY = False\n",
    "SAVEFIG = True\n",
    "EXPERIMENT_NAME = 'with wearing-off'\n",
    "REMOVE_WEARING_OFF_IN_PREVIOUS_STEP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf70dd5-ea4c-48b6-abb9-04757b4790f4",
   "metadata": {},
   "source": [
    "## WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54639ff7-165c-411d-9cf8-1c0a737e07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                 train_df, test_df, validation_df=None,\n",
    "                 label_columns=None):\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.validation_df = validation_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the target label column indices.\n",
    "        # Example: { 'wearing_off': 0 }\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "          self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        # input column indices\n",
    "        # Example: { 'heart_rate': 0 , 'stress_score': 1 }\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                               enumerate(train_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "\n",
    "    def split_window(self, features, remove_target_column_from_input=True):\n",
    "        if remove_target_column_from_input:\n",
    "            number_of_columns = self.column_indices.copy().pop('wearing_off')\n",
    "            inputs = features[:, self.input_slice, :number_of_columns] # without wearing-off\n",
    "        else:\n",
    "            inputs = features[:, self.input_slice, :]   # with wearing-off\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def make_dataset(self, data, remove_target_column_from_input=True):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=False,\n",
    "            seed=4,\n",
    "            batch_size=BATCH_SIZE,).shuffle(buffer_size=10000)\n",
    "            # .shuffle(seed=4, buffer_size=10000)\n",
    "\n",
    "        ds = ds.map(lambda d: self.split_window(d, remove_target_column_from_input))\n",
    "\n",
    "        return ds\n",
    "    \n",
    "    def train(self, remove_target_column_from_input=True):\n",
    "        return self.make_dataset(\n",
    "            self.train_df, \n",
    "            remove_target_column_from_input=remove_target_column_from_input)\n",
    "\n",
    "    def validation(self, remove_target_column_from_input=True):\n",
    "        return self.make_dataset(\n",
    "            self.validation_df, \n",
    "            remove_target_column_from_input=remove_target_column_from_input)\n",
    "\n",
    "    def test(self, remove_target_column_from_input=True):\n",
    "        return self.make_dataset(\n",
    "            self.test_df, \n",
    "            remove_target_column_from_input=remove_target_column_from_input)\n",
    "\n",
    "    def sample(self, remove_target_column_from_input=True):\n",
    "        sample_dataset = self.make_dataset(\n",
    "            self.train_df,\n",
    "            remove_target_column_from_input=remove_target_column_from_input)\n",
    "        result = next(iter(sample_dataset))\n",
    "        return result\n",
    "    \n",
    "    def plot(self, model=None, plot_col='wearing_off', max_subplots=3, \n",
    "             remove_target_column_from_input=True, override=False):\n",
    "        inputs, labels = self.sample(remove_target_column_from_input=False)\n",
    "        if override:\n",
    "            inputs_for_prediction = inputs\n",
    "        else:\n",
    "            if remove_target_column_from_input:\n",
    "                number_of_columns = self.column_indices.copy().pop('wearing_off')\n",
    "                inputs_for_prediction = inputs[:,:, :number_of_columns]\n",
    "            else:\n",
    "                inputs_for_prediction = inputs\n",
    "        \n",
    "        fig = plt.figure(figsize=(25,10))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        for n in range(max_n):\n",
    "            ax = plt.subplot(max_n, 1, n+1)\n",
    "            if n == 1:\n",
    "                plt.ylabel(f'{plot_col} [normed]')\n",
    "            plt.ylim(-0.1,1.1)\n",
    "            ax.set_yticks(\n",
    "                [0.0, 0.5, 1.0]\n",
    "            )\n",
    "            ax.set_xticks([])\n",
    "            if n == 2:\n",
    "                ax.set_xticks(\n",
    "                    np.append(self.input_indices[::SHIFT], self.input_indices[-1] + 1),\n",
    "                    list(range(0, len( self.input_indices[::SHIFT] ) + 1 )),\n",
    "                    minor=True\n",
    "                )\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "                label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "\n",
    "            plt.scatter(self.label_indices[::SHIFT], labels[n, :, label_col_index][::SHIFT],\n",
    "                        edgecolors='k', label='Labels', c='#2ca02c', s=64*4)\n",
    "            if model is not None:\n",
    "                predictions = model(inputs_for_prediction)\n",
    "                plt.scatter(self.label_indices[::SHIFT], predictions[n, :, label_col_index][::SHIFT],\n",
    "                            marker='X', edgecolors='k', label='Predictions',\n",
    "                            c='#ff7f0e', s=64*4)\n",
    "            if n == 2:\n",
    "                # Put a legend below current axis\n",
    "                plt.legend(loc='upper center', bbox_to_anchor=(0.5, 0.025),\n",
    "                           bbox_transform=fig.transFigure,\n",
    "                          fancybox=True, shadow=True, ncol=3)\n",
    "                # plt.legend()\n",
    "                \n",
    "        plt.xlabel('Time [h]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc6fbb0-1fe0-46b8-8b4e-2c28d26d6685",
   "metadata": {},
   "source": [
    "## Compile and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80f0ee9-adfc-4da3-8983-6b7d425407a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compile_and_fit(model, window, patience=10, experiment_name=EXPERIMENT_NAME, remove_target_column_from_input=True):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_prc',\n",
    "    #                                                   verbose=1,\n",
    "    #                                                   patience=patience,\n",
    "    #                                                   mode='max',\n",
    "    #                                                   restore_best_weights=True)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=patience,\n",
    "                                                      mode='min',\n",
    "                                                      restore_best_weights=True)\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'logs/{experiment_name}/{timestamp}/{model.name}',\n",
    "                                                 histogram_freq=0,\n",
    "                                                 write_graph=True,\n",
    "                                                 write_images=False,\n",
    "                                                 write_steps_per_second=False,\n",
    "                                                 update_freq=\"epoch\",\n",
    "                                                 profile_batch=0)\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                metrics=METRICS)\n",
    "\n",
    "    history = model.fit(window.train(remove_target_column_from_input), epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.validation(remove_target_column_from_input),\n",
    "                      callbacks=[tensorboard, early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff8ff17-9b02-4b1e-9a79-ba4eb19b15f1",
   "metadata": {},
   "source": [
    "## Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be5422-8c49-47c7-876c-3ba93da4517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history, model, savefig=False):\n",
    "    FORMAT = 'pdf'\n",
    "    metrics = ['loss', 'balanced_accuracy', 'auc', 'prc', 'precision', 'recall']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(3,3,n+1)\n",
    "        plt.plot(history.epoch, history.history[metric], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric], label='Validation')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "          plt.ylim([0, plt.ylim()[1]])\n",
    "        # elif metric == 'auc':\n",
    "        #   plt.ylim([0.8,1])\n",
    "        else:\n",
    "          plt.ylim([0,1])\n",
    "        plt.legend();\n",
    "    if savefig:\n",
    "        plt.savefig(f'./results/metrics/{user}_learning_curve_{model.name}.{FORMAT}', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fpr, tpr, thresholds = roc_curve(labels, predictions)\n",
    "\n",
    "    plt.plot([0,1], [0,1], linestyle='--')\n",
    "    plt.plot(fpr, tpr, marker='.', label=name)\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate [%]')\n",
    "    plt.ylabel('True Positive Rate [%]')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_prc(name, labels, predictions, **kwargs):\n",
    "    precision, recall, thresholds = precision_recall_curve(labels, predictions)\n",
    "\n",
    "    no_skill = len(labels[labels==1]) / len(labels)\n",
    "    plt.plot([0,1], [no_skill,no_skill], linestyle='--')\n",
    "    plt.plot(recall, precision, marker='.', label=name)\n",
    "    # axis labels\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "\n",
    "def visualize_results(model, single_window, wide_window, history=None, override=False, savefig=False, remove_target_column_from_input=True):\n",
    "    FORMAT = 'pdf'\n",
    "    \n",
    "    # sample predictions\n",
    "    # sample predictions\n",
    "    font = {'size': 30}\n",
    "            # 'family' : 'normal',\n",
    "            # 'weight' : 'bold',\n",
    "    mpl.rc('font', **font)\n",
    "    \n",
    "    wide_window.plot(model, remove_target_column_from_input=remove_target_column_from_input)\n",
    "    plt.suptitle(f'Sample forecasting for Participant {user.replace(\"participant\", \"\")} using {model.name}')\n",
    "    if savefig:\n",
    "        plt.savefig(f'./results/sample_predictions/{user}_sample_prediction_{model.name}.{FORMAT}', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # learning curve\n",
    "    if history is not None:\n",
    "        plt.plot(history.history['loss'], label='Train')\n",
    "        plt.plot(history.history['val_loss'], label='Validation')\n",
    "        plt.title(f'Learning Curve Loss for Participant {user.replace(\"participant\", \"\")} using {model.name}')\n",
    "        plt.legend()\n",
    "        if savefig:\n",
    "            plt.savefig(f'./results/learning_curve/{user}_learning_curve_{model.name}.{FORMAT}', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        # metrics\n",
    "        plot_metrics(history, model=model, savefig=savefig)\n",
    "\n",
    "    # confusion matrix\n",
    "    font = {'size': 20}\n",
    "            # 'family' : 'normal',\n",
    "            # 'weight' : 'bold',\n",
    "    mpl.rc('font', **font)\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for input, label in single_window.test(remove_target_column_from_input=remove_target_column_from_input):\n",
    "        output = model(input).numpy()\n",
    "        predictions += list(output.reshape( output.shape[0] ))\n",
    "        \n",
    "        l = label.numpy()\n",
    "        labels += list(l.reshape( l.shape[0] ))\n",
    "    predictions = np.array(predictions)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    THRESHOLD = 0.5\n",
    "    cm = confusion_matrix(labels.reshape(labels.shape[0]),\n",
    "                          predictions.reshape(predictions.shape[0]) > THRESHOLD)\n",
    "    cm_normalized = confusion_matrix(labels.reshape(labels.shape[0]),\n",
    "                     predictions.reshape(predictions.shape[0]) > THRESHOLD,\n",
    "                     normalize='all') * 100\n",
    "\n",
    "    if 1.0 in labels:\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                      display_labels=['normal', 'wearing-off'])\n",
    "    else:\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    \n",
    "    disp.plot()\n",
    "    plt.title(f'Confusion matrix for Participant {user.replace(\"participant\", \"\")} using {model.name}')\n",
    "    if savefig:\n",
    "        plt.savefig(f'./results/confusion_matrix/{user}_confusion_matrix_{model.name}.{FORMAT}', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC\n",
    "    plot_roc(model.name, labels, predictions)\n",
    "    \n",
    "    plot_prc(model.name, labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd3f3d6-8ef6-4b7c-a842-c3ba3929f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    var_names = data.columns\n",
    "    n_vars = len(var_names)\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()    # new column values, new columne names\n",
    "    \n",
    "    # input sequence (t-i, ... t-1)\n",
    "    # timesteps before (e.g., n_in = 3, t-3, t-2, t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += list(\n",
    "            map(lambda var_name: f'{var_name}(t-{i})', var_names)\n",
    "        )\n",
    "        \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    # timesteps after (e.g., n_out = 3, t, t+1, t+2)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += list( map(lambda var_name: f'{var_name}(t)', var_names) )\n",
    "        else:\n",
    "            names += list( map(lambda var_name: f'{var_name}(t+{i})', var_names) )\n",
    "\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a4665-139d-48f3-acb1-923905aa89d5",
   "metadata": {},
   "source": [
    "# Load & process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11879e6b-b6a4-4a7b-8679-68fda09ac128",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(f'./data/4-combined_data_{user}_{interval}.xlsx',\n",
    "                              index_col=\"timestamp\",\n",
    "                              usecols=columns,\n",
    "                              engine='openpyxl')\n",
    "# Fill missing data with 0\n",
    "dataset.fillna(0, inplace=True)\n",
    "\n",
    "# Filter data based on participants' dictionary\n",
    "dataset = dataset.loc[\n",
    "    (dataset.index >= participant_dictionary[user]['start_date']) &\n",
    "    (dataset.index < participant_dictionary[user]['end_date_plus_two'])\n",
    "]\n",
    "\n",
    "column_indices = { name: i for i, name in enumerate(dataset.columns) }\n",
    "df = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7505c3ed-33dd-4e9a-b131-37a8aab0b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(df[target_column])\n",
    "total = neg + pos\n",
    "initial_bias = np.log([pos/neg])\n",
    "output_bias = tf.keras.initializers.Constant(initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb7aa9-fe0d-4ca3-9e4e-5a68240c2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec55fcda-6b33-493b-9783-2787bf2e83e4",
   "metadata": {},
   "source": [
    "## Slice to get hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f02d783-965f-4a21-add0-028e5067c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_HOURLY:\n",
    "    # Slice [start:stop:step], starting from index 0, take every 4 record\n",
    "    # Take every hour record only\n",
    "    df = dataset[::SHIFT].copy() \n",
    "\n",
    "    # Fix columns arrangement\n",
    "    dataset = dataset.reindex(columns=columns[1:])\n",
    "\n",
    "    record_size_per_day = 24\n",
    "    SHIFT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc0676-cbaf-41d3-b58c-143eb9a52fe5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03aa566-5e99-4bef-a45c-e244eaae3de8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3690a4f-9276-49b4-8217-21fd421a77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data 60% \n",
    "TRAINING_PERCENTAGE = 0.6\n",
    "# validation data 20%\n",
    "VALIDATION_PERCENTAGE = 0.2\n",
    "\n",
    "column_indices = { name: i for i, name in enumerate(df.columns) }\n",
    "total_rows = len(df)\n",
    "num_features = len(df.columns)\n",
    "\n",
    "training_end_index = int(total_rows * TRAINING_PERCENTAGE)\n",
    "validation_end_index = int(total_rows * (TRAINING_PERCENTAGE + VALIDATION_PERCENTAGE))\n",
    "\n",
    "train_df = df[0:training_end_index].copy()\n",
    "validation_df = df[training_end_index:validation_end_index].copy()\n",
    "test_df = df[validation_end_index:].copy()\n",
    "\n",
    "print(f\"Training data: {round(len(train_df)/record_size_per_day, 3)} days\")\n",
    "print(f\"Validation data: {round(len(validation_df)/record_size_per_day, 3)} days\")\n",
    "print(f\"Test data: {round(len(test_df)/record_size_per_day, 3)} days\")\n",
    "print(f\"Total data: {round(len(df)/record_size_per_day, 3)} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d3406-8ffb-47a9-9cb1-408d4dab37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, validation_df, test_df = split_train_validation_test_set(df, \n",
    "#                                                                    test_set_size=1, \n",
    "#                                                                    validation_percentage=0.2)\n",
    "\n",
    "# print(f\"Training data: {round(len(train_df)/record_size_per_day * 1, 3)} days\")\n",
    "# print(f\"Validation data: {round(len(validation_df)/record_size_per_day * 1, 3)} days\")\n",
    "# print(f\"Test data: {round(len(test_df)/record_size_per_day * 1, 3)} days\")\n",
    "# print(f\"Total data: {round(len(df)/record_size_per_day * 1, 3)} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92386aa-6163-47f8-a57b-b424f99b7d20",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f712264-8add-42d4-9cbf-c0d5a2b59b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = train_df.loc[:, normalize_features].mean()\n",
    "train_std = train_df.loc[:, normalize_features].std()\n",
    "\n",
    "train_df = normalize_data(train_df, train_mean, train_std)\n",
    "validation_df = normalize_data(validation_df, train_mean, train_std)\n",
    "test_df = normalize_data(test_df, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d9a40a-4808-4f14-9f76-98dd8fc26de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_standardized = (df.loc[:, normalize_features] - train_mean) / train_std\n",
    "df_standardized = pd.merge(df_standardized, df.iloc[:, -2:], left_index=True,right_index=True)\n",
    "df_standardized = df_standardized.melt(var_name='Columns', value_name='Normalized')\n",
    "plt.figure()\n",
    "ax = sns.violinplot(x='Columns', y='Normalized', data=df_standardized)\n",
    "_ = ax.set_xticklabels(df.keys(), rotation=45)\n",
    "plt.title(\"Distribution of normalized features\")\n",
    "if SAVEFIG:\n",
    "    plt.savefig(f'./results/{user}_distribution_normalized_data.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f8efb-ec1f-440d-ae75-b903116e7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size': 30}\n",
    "        # 'family' : 'normal',\n",
    "        # 'weight' : 'bold',\n",
    "\n",
    "mpl.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194828ce-1b64-4b9a-b88f-a60c5f27af50",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c842b6c-a62a-43d2-ae21-22deec455d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance = {}\n",
    "test_performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566870f-183d-4ca1-86c9-6d86f120886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_window = WindowGenerator(input_width=1, label_width=1, shift=SHIFT,\n",
    "                                     train_df=train_df, test_df=test_df, validation_df=validation_df,\n",
    "                                     label_columns=['wearing_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e60ffa-603c-4198-bde4-cb2cca2d8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_single_step_window = WindowGenerator(input_width=MULTI_STEP_WIDTH, label_width=MULTI_STEP_WIDTH, shift=SHIFT,\n",
    "                              train_df=train_df, validation_df=validation_df, test_df=test_df,\n",
    "                              label_columns=['wearing_off'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4605131b-eee6-4adc-b681-af8341cc0af4",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e31d52-8c9f-4972-b1f5-1d4f241bd267",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb161d0-55e9-4615-88d0-803b0ffb1e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Baseline(label_index=column_indices['wearing_off'], name='Baseline')\n",
    "baseline.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47214425-a868-42b6-a50d-3e5926ac3ce3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_performance[baseline.name] = baseline.evaluate(single_step_window.validation(remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP))\n",
    "test_performance[baseline.name] = baseline.evaluate(single_step_window.test(remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860872f-65cd-41e0-b87e-035a1a79cdd0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_results(baseline, single_step_window, wide_single_step_window, \n",
    "                  history=None, savefig=SAVEFIG,\n",
    "                  override=True,\n",
    "                  remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608be484-bc06-498a-87b5-88ae803d96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(baseline.metrics_names, test_performance[baseline.name]):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b328446-4e9b-41a7-bcdc-e649ca810e04",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aaf04c-0c3b-405c-89d4-a227308bb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\", name=\"output\")\n",
    "], name = \"Linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b21a0-5a19-49ee-942d-8ba5d5424ecd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(linear, single_step_window,\n",
    "                          remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9566aa74-02fa-4ba5-97bc-8366e99a55e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_performance[linear.name] = linear.evaluate(\n",
    "    single_step_window.validation(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP))\n",
    "test_performance[linear.name] = linear.evaluate(\n",
    "    single_step_window.test(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a365dbe-1a23-45e5-938c-e0d6c9fbc8b0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_results(linear, single_step_window, wide_single_step_window, \n",
    "                  history=history, savefig=SAVEFIG,\n",
    "                  override=False,\n",
    "                  remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b965576-e54f-430d-8f6a-ac16da03ba46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, value in zip(linear.metrics_names, test_performance[linear.name]):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133a921d-cfa3-4036-9445-8092b028d484",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846fd503-238e-4f2e-980b-408f16daa1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, layer=None, width=None):\n",
    "    # if REMOVE_WEARING_OFF_IN_PREVIOUS_STEP:\n",
    "    #     NUM_FEATURES = 14\n",
    "    # else:\n",
    "    NUM_FEATURES = 15\n",
    "    \n",
    "#     # use Kernel SHAP to explain test set predictions\n",
    "#     explainer = shap.KernelExplainer(model, train_df.values)\n",
    "#     shap_values = explainer.shap_values(test_df.values, nsamples=15)\n",
    "\n",
    "#     # plot the SHAP values for the the first instance\n",
    "#     shap.force_plot(explainer.expected_value[0], shap_values[0][0,:], test_df.iloc[0,:NUM_FEATURES], show=False, matplotlib=True)\n",
    "#     plt.savefig(f'./results/feature_importance/{user}_shap_one_sample_{model.name}.pdf', bbox_inches='tight')\n",
    "#     plt.show()\n",
    "\n",
    "#     # TODO: OUTPUT OVERLAPPING\n",
    "#     # shap.plots._waterfall.waterfall_legacy(explainer.expected_value[0], shap_values[0][0], test_df.iloc[0,:NUM_FEATURES], show=False)\n",
    "#     # plt.savefig(f'./results/{user}_shap_one_sample_{model.name}.pdf', bbox_inches='tight')\n",
    "#     # plt.show()\n",
    "\n",
    "#     # TODO: Convert HTML to PDF\n",
    "#     f = shap.force_plot(explainer.expected_value[0], shap_values[0], test_df.iloc[:,:NUM_FEATURES], link=\"logit\", show=False)\n",
    "#     shap.save_html(f'./results/feature_importance/{user}_shap_stacked_samples_{model.name}.html', f)\n",
    "\n",
    "#     # Summary Plot\n",
    "#     f = plt.figure()\n",
    "#     feature_names = [\n",
    "#         a + \": \" + str(b) for a,b in zip(test_df.columns, shap_values[0].mean(0).round(2))\n",
    "#     ]\n",
    "#     shap.summary_plot(shap_values[0], test_df, feature_names=feature_names)\n",
    "#     f.savefig(f'./results/feature_importance/{user}_shap_summary_plot_{model.name}.pdf', bbox_inches='tight')\n",
    "\n",
    "    # Native feature importance\n",
    "    # plt.bar(x = range(len(train_df.columns)),\n",
    "    #         height=model.layers[0].kernel[:,0].numpy())\n",
    "    # axis = plt.gca()\n",
    "    # axis.set_xticks(range(len(train_df.columns)))\n",
    "    # _ = axis.set_xticklabels(train_df.columns, \n",
    "    #                          rotation=45, fontsize=18, ha='right')\n",
    "    # plt.title(f'Feature weights for Participant {user.replace(\"participant\", \"\")} using {model.name} model')\n",
    "    # plt.savefig(f'./results/feature_importance/{user}_native_feature_importance_{model.name}.pdf', bbox_inches='tight')\n",
    "    # plt.show()\n",
    "    \n",
    "    if layer is not None:\n",
    "        feature_weights = pd.DataFrame(layer).T\n",
    "        feature_weights.columns = list(series_to_supervised(train_df,\n",
    "                                                            n_in=width, n_out=1\n",
    "                                                           ).columns.drop([\n",
    "                                                            'heart_rate(t)', 'steps(t)', 'stress_score(t)',\n",
    "                                                            'awake(t)', 'deep(t)', 'light(t)', 'rem(t)',\n",
    "                                                            'nonrem_total(t)', 'total(t)', 'nonrem_percentage(t)',\n",
    "                                                            'sleep_efficiency(t)',\n",
    "                                                            'timestamp_hour_sin(t)', 'timestamp_hour_cos(t)', 'timestamp_dayofweek(t)',\n",
    "                                                            'wearing_off(t)']))\n",
    "\n",
    "        sorted_idx = feature_weights.values[0].argsort()\n",
    "        sorted_idx = np.concatenate([sorted_idx[0:10], sorted_idx[-10:]])\n",
    "        fig = plt.figure(figsize=(14, 7))\n",
    "        plt.barh(range(len(sorted_idx)), feature_weights.values[0][sorted_idx], align='center')\n",
    "        plt.yticks(range(len(sorted_idx)), np.array(feature_weights.columns)[sorted_idx])\n",
    "        plt.ylabel('Features')\n",
    "        plt.xlabel('Weights')\n",
    "        plt.title('Feature Importance for participant %i' % 1)\n",
    "        plt.savefig(f'./results/feature_importance/{user}_native_feature_importance_{model.name}.pdf', bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5292bbf5-2201-4eca-aa80-1da2d78f1ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_feature_importance(linear,\n",
    "                        layer=linear.layers[0].kernel[:,0].numpy(), width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc892223-20a4-425d-a079-0a7d4bed43af",
   "metadata": {},
   "source": [
    "## Single-time-step Dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad18574-d0e5-4dd7-815a-525a25f69745",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "single_time_step_dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid', name=\"output\")\n",
    "], name = \"Single_time_step_Dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e328f2-8b14-4d7f-b1ad-898cb68a2a37",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(single_time_step_dense, single_step_window,\n",
    "                          remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced8dc8-58a0-492d-9384-ee94fb62bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance[single_time_step_dense.name] = single_time_step_dense.evaluate(\n",
    "    single_step_window.validation(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP))\n",
    "test_performance[single_time_step_dense.name] = single_time_step_dense.evaluate(\n",
    "    single_step_window.test(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f2a3d-d333-4775-bbdd-f8737adfc2b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_results(single_time_step_dense, single_step_window, wide_single_step_window,\n",
    "                  history=history, savefig=SAVEFIG,\n",
    "                  override=False,\n",
    "                  remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0956e-aaf5-4cf3-ab11-43721a4a5d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(single_time_step_dense.metrics_names, test_performance[single_time_step_dense.name]):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a06bf4-b029-4525-9537-b2bbde73bf85",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f8f5a6-cabb-4e77-9960-44dcf4fb2347",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_feature_importance(single_time_step_dense,\n",
    "                        layer=single_time_step_dense.layers[0].kernel[:,0].numpy(), width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070b81c-3cf3-4484-9dd8-80da424ae36c",
   "metadata": {},
   "source": [
    "## Multi-time-step Dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ccb28-3d3e-4632-b839-db8fe8139b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_step_window = WindowGenerator(input_width=MULTI_STEP_WIDTH, label_width=1, shift=SHIFT,\n",
    "                                    train_df=train_df, validation_df=validation_df, test_df=test_df,\n",
    "                                    label_columns=['wearing_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dafe16-7bc7-4806-b74f-49c9109cd17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "multi_time_step_dense = tf.keras.Sequential([\n",
    "    # Shape: (time, features) => (time*features)\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid', name=\"output\"),\n",
    "    # Add back the time dimension.\n",
    "    # Shape: (outputs) => (1, outputs)\n",
    "    tf.keras.layers.Reshape([1, -1]),\n",
    "], name = \"Multi_time_step_Dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c8b3d-7588-4825-a348-d566808aee0d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(multi_time_step_dense, multi_step_window,\n",
    "                          remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca263d70-df90-4812-bcbb-5d32658470f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_performance[multi_time_step_dense.name] = multi_time_step_dense.evaluate(\n",
    "    multi_step_window.validation(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP))\n",
    "test_performance[multi_time_step_dense.name] = multi_time_step_dense.evaluate(\n",
    "    multi_step_window.test(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e52e1-7b4f-440b-bd25-a0fc0e276972",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_results(multi_time_step_dense, multi_step_window, multi_step_window,\n",
    "                  history=history, savefig=SAVEFIG,\n",
    "                  override=False,\n",
    "                  remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59300abe-199c-437d-bdc3-afa16f34349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(multi_time_step_dense.metrics_names, test_performance[multi_time_step_dense.name]):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affabe7d-6fce-4e80-8320-224d656ac74c",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d295c6-6c98-48e3-a111-c755e5eb7a69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_feature_importance(multi_time_step_dense,\n",
    "                        layer=multi_time_step_dense.layers[1].kernel[:,0].numpy(), width=MULTI_STEP_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d778846-30e2-4fa8-9612-bb155f11525d",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abe209-930e-40a0-b3e4-93dc71feabae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABEL_WIDTH = MULTI_STEP_WIDTH\n",
    "INPUT_WIDTH = LABEL_WIDTH + (MULTI_STEP_WIDTH - 1)\n",
    "wide_multi_step_window = WindowGenerator(input_width=INPUT_WIDTH, label_width=LABEL_WIDTH, shift=SHIFT,\n",
    "                                         train_df=train_df, validation_df=validation_df, test_df=test_df,\n",
    "                                         label_columns=['wearing_off'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe30c5-c1df-40fb-ba23-b6f0d35f4ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "cnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=64,\n",
    "                           kernel_size=(MULTI_STEP_WIDTH,),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid', name=\"output\"),\n",
    "], name = \"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1405b102-1257-4f50-b4a4-adc9a69fbff0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(cnn_model, multi_step_window,\n",
    "                         remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853f2b97-b50a-47d0-a9e3-583b46bb29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_performance[cnn_model.name] = cnn_model.evaluate(\n",
    "    multi_step_window.validation(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP))\n",
    "\n",
    "test_performance[cnn_model.name] = cnn_model.evaluate(\n",
    "    multi_step_window.test(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6617c2-8b08-4cdd-bcf1-0c68d3ad0aa0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ORIGINAL: visualize_results(cnn_model, multi_step_window, wide_multi_step_window,\n",
    "#  but not working\n",
    "visualize_results(cnn_model, multi_step_window, wide_multi_step_window,\n",
    "                  history=history, savefig=SAVEFIG,\n",
    "                  override=False,\n",
    "                  remove_target_column_from_input=REMOVE_WEARING_OFF_IN_PREVIOUS_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262fdb7-0e84-4a89-b7f8-136d35e4dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(cnn_model.metrics_names, test_performance[cnn_model.name]):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e7f47-ab35-44f1-855d-d2439c6ddb0a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "series_to_supervised(multi_step_window.test_df, n_in=record_size_per_day, n_out=4, dropnan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f54147-62d3-4749-a8e0-03a945fdd295",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_bin = tf.keras.metrics.BinaryAccuracy()\n",
    "m_bal = BalancedSparseCategoricalAccuracy()\n",
    "m_auc = tf.keras.metrics.AUC()\n",
    "m_sklearn_bal = BalancedAccuracy()\n",
    "\n",
    "y_trues = []\n",
    "y_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e38b2-ff49-4e17-b1b2-06d37ba67e55",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "counter = 1\n",
    "for input, label in multi_step_window.test(REMOVE_WEARING_OFF_IN_PREVIOUS_STEP):\n",
    "    print(counter)\n",
    "    counter += 1\n",
    "    \n",
    "    y_true = label\n",
    "    y_trues.append(y_true.numpy())\n",
    "    print(f'Label: { [y_t for y_t in y_true.numpy().reshape(y_true.numpy().shape[0]) ]}')\n",
    "    \n",
    "    y_pred = cnn_model(input)\n",
    "    y_preds.append(y_pred.numpy())\n",
    "    print(f'Predictions: {  [y_p for y_p in y_pred.numpy().reshape(y_pred.numpy().shape[0]) ]}')\n",
    "    \n",
    "    THRESHOLD = 0.5\n",
    "    cm = confusion_matrix(y_true.numpy().reshape(y_true.shape[0]),\n",
    "                          y_pred.numpy().reshape(y_pred.shape[0]) > THRESHOLD)\n",
    "    print(cm)\n",
    "    \n",
    "    m_bin.update_state(y_true, y_pred)\n",
    "    m_bal.update_state(y_true, y_pred)\n",
    "    m_auc.update_state(y_true, y_pred)\n",
    "    m_sklearn_bal.update_state(y_true, y_pred)\n",
    "    print(f'bin result: {m_bin.result().numpy()}')\n",
    "    print(f'bal result: {m_bal.result().numpy()}')\n",
    "    print(f'auc result: {m_auc.result().numpy()}')\n",
    "    print(f'sklearn bal result: {m_sklearn_bal.result().numpy()}')\n",
    "    print()\n",
    "    \n",
    "# y_trues = np.concatenate(y_trues)\n",
    "# y_preds = np.concatenate(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3be20-f426-4a4d-b7c8-a1c827926665",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_trues = [0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
    "Y_preds = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec04b3f-2c8b-4b3a-8224-b52af38f2f33",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_trues = [0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,1,0,0,0]\n",
    "Y_preds = [0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663227f-bce2-4387-9930-6a7f34a3caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Y_trues, Y_preds).ravel()\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e0979-dce8-42df-908d-72dbf27eae7f",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8fc014-a3aa-4437-b585-f518a4d2ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(cnn_model,\n",
    "                        layer=cnn_model.layers[0].kernel.numpy().reshape(36*15, 64),\n",
    "                        width=MULTI_STEP_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaea1cd-cf44-4f21-811f-e30a055e2146",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea45e6a4-7113-403d-a1b8-3c18b98969b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(16, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid', name=\"output\")\n",
    "], name = \"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc62ff2e-90ce-4bf9-b7e0-619081af130d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = compile_and_fit(lstm_model, wide_single_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb96f78-47ed-4dfb-ab15-eaea93a4e89d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_performance[lstm_model.name] = lstm_model.evaluate(\n",
    "    wide_single_step_window.validation(not REMOVE_WEARING_OFF_IN_PREVIOUS_STEP))\n",
    "test_performance[lstm_model.name] = lstm_model.evaluate(\n",
    "    wide_single_step_window.test(not REMOVE_WEARING_OFF_IN_PREVIOUS_STEP), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c67a2f-c56e-4302-ac8f-a47088c37da3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_results(lstm_model, single_step_window, wide_single_step_window, \n",
    "                  history=history, override=not REMOVE_WEARING_OFF_IN_PREVIOUS_STEP,\n",
    "                  savefig=SAVEFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69a1c4-938e-408f-bc94-562347f75db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(lstm_model.metrics_names, test_performance[lstm_model.name]):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75383335-8f27-4256-88ee-a355a036cf82",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c0d656-3634-4596-84a8-b882d2380a87",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "FORMAT = 'png'\n",
    "\n",
    "x = np.arange(len(test_performance))\n",
    "width = 0.3\n",
    "\n",
    "for metric_name in ['loss'] + list(map(lambda m: m.name, METRICS)):\n",
    "    # metric_name = 'auc'\n",
    "    metric_index = lstm_model.metrics_names.index(metric_name)\n",
    "    validation_accuracy = [v[metric_index] for v in validation_performance.values()]\n",
    "    test_accuracy = [v[metric_index] for v in test_performance.values()]\n",
    "\n",
    "    plt.ylabel(f'{metric_name} [wearing_off, normalized]')\n",
    "    plt.bar(x - 0.17, validation_accuracy, width, label='Validation')\n",
    "    plt.bar(x + 0.17, test_accuracy, width, label='Test')\n",
    "    plt.xticks(ticks=x, labels=test_performance.keys(),\n",
    "               rotation=45)\n",
    "    _ = plt.legend()\n",
    "    plt.title(f'Test Performance ({metric_name.upper()}) for Participant {user.replace(\"participant\", \"\")} on varying models')\n",
    "    plt.savefig(f'./results/performance/test_performance_{user}_{metric_name}.{FORMAT}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75351e8-118b-4d32-a531-7d9448807d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_perf = pd.DataFrame(validation_performance,\n",
    "             index = ['loss'] + list(map(lambda m: m.name, METRICS))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c05343-160b-494f-884a-b1aedfe7f10e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_perf = pd.DataFrame(test_performance,\n",
    "             index = ['loss'] + list(map(lambda m: m.name, METRICS))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96fe7b2-8a5f-48b4-93e8-6599dde89c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_perf['participant'] = user\n",
    "val_perf['set'] = 'validation'\n",
    "\n",
    "test_perf['participant'] = user\n",
    "test_perf['set'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2e115-3f91-439f-9d81-51855cf488e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_performance = pd.concat([val_perf, test_perf])\n",
    "if os.path.exists(f'./results/final_performance.xlsx'):\n",
    "    with pd.ExcelWriter(f'./results/final_performance.xlsx', engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "        final_performance.to_excel(writer, startrow=writer.sheets['Sheet1'].max_row, header=None)\n",
    "else:\n",
    "    with pd.ExcelWriter(f'./results/final_performance.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "        final_performance.to_excel(writer)\n",
    "final_performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
